<body>
            <h1>Characterization of Biological Motion Using Motion Sensing Superpixels</h1>
            <p><strong>Authors:</strong> Felix  Y. Zhou, Carlos  Ruiz-Puig, Richard P. Owen, Michael J. White, Jens  Rittscher, Xin  Lu</p>
            <h2>Abstract</h2>
            <p>Precise spatiotemporal regulation is the foundation for the healthy development and maintenance of living organisms. All cells must correctly execute their function in the right place at the right time. Cellular motion is thus an important dynamic readout of signaling in key disease-relevant molecular pathways. However despite the rapid advancement of imaging technology, a comprehensive quantitative description of motion imaged under different imaging modalities at all spatiotemporal scales; molecular, cellular and tissue-level is still lacking. Generally, cells move either âindividuallyâ or âcollectivelyâ as a group with nearby cells. Current computational tools specifically focus on one or the other regime, limiting their general applicability. To address this, we recently developed and reported a new computational framework, Motion Sensing Superpixels (MOSES). Incorporating the individual advantages of single cell trackers for individual cell and particle image velocimetry (PIV) for collective cell motion analyses, MOSES enables âmesoscaleâ analysis of both single-cell and collective motion over arbitrarily long times. At the same time, MOSES readily complements existing single-cell tracking workflows with additional characterization of global motion patterns and interaction analysis between cells and also operates directly on PIV extracted motion fields to yield rich motion trajectories analogous for single-cell tracks suitable for high-throughput motion phenotyping. This protocol provides a step-by-step practical guide for those interested in applying MOSES to their own datasets. The protocol highlights the salient features of a MOSES analysis and demonstrates the ease-of-use and wide applicability of MOSES to biological imaging through demo experimental analyses with ready-to-use code snippets of four datasets from different microscope modalities; phase-contrast, fluorescent, lightsheet and intra-vital microscopy. In addition we discuss critical points of consideration in the analysis. </p>
            <p><strong>Keywords:</strong> Biological motion, Cell tracking, Dynamic mesh, Superpixels, Motion map, High-throughput screening</p>
            <h2>Background</h2><p>In general, cells exhibit two types of movement; âsingle-cellâ or âindividualâ migration in which each cell migrates independently or âcollectiveâ migration where nearby cells migrate as a group in a coordinated fashion. Current computational tools focus on one or the other regime. To date numerous single-cell tracking methods have been developed that extract the movement trajectories of individual cells to build rich motion feature descriptors suitable for the unbiased analysis of high-throughput screens (Padfield <em>et al.</em>, 2011; Meijering<em>et al.</em>, 2012; MaÅ¡ka <em>et al.</em>, 2014; Schiegg <em>et al.</em>, 2015; Nketia <em>et al.</em>, 2017). However the performance of these algorithms requires accurate delineation or segmentation and subsequent temporal association of individual identified cells between video frames. This process is unfortunately difficult to generalize across applications, requires significant expertise and computationally scales poorly with increasing cell number. Single-cell tracking thus places an inherent upper limit to the time duration that can be imaged and tracked. In contrast, collective motion analysis tools such as Particle Image Velocimetry (PIV) exploit local correlation between image patch intensity values to derive velocities for all image pixels between all pairs of frames (SzabÃ³ <em>et al.</em>, 2006; Petitjean <em>et al.</em>, 2010; Milde <em>et al.</em>, 2012). Advantageously this avoids errors introduced by image segmentation, is much easier to use for non-experts and is computationally efficient, scaling only with the number of region of interests (ROI) the image is divided into. Unfortunately, despite attempts to extract more descriptive motion parameters aside from PIV velocity such as including appearance parameters (Neumann <em>et al.</em>, 2006; Zaritsky <em>et al.</em>, 2012; 2014; 2015 and 2017), systematic characterization of the PIV extracted velocity fields to derive similarly rich âsignaturesâ as afforded by single-cell track measurements over arbitrarily long times for clustering motion patterns within and across videos is lacking. Further investigation of how the pixel-based or ROI measurements relate to particular individual cells or cell groups in the moving collectives has also been underexplored. As such PIV based analyses have exhibited limited success when studying phenomena associated with complex cellular movement such as boundary formation and chemoattraction <em>in-vivo</em>. <br/><br/>Recently we developed Motion Sensing Superpixels (MOSES) (Zhou <em>et al.</em>, 2019), a computational framework that marries together the ability to generate rich motion features offered by single-cell tracking trajectories with the ease-of-use and computational efficiency of segmentation-free PIV methods. MOSES achieves this by firstly extending PIV-type methods to generate long-time motion trajectories analogous to single-cell tracks for user-defined ROIs called superpixels and secondly the construction of a mesh over the extracted motion trajectories to systematically capture the spatio-temporal interaction between neighboring ROIs. This protocol through ready-to-use code snippets details how to do this practically using the previously published MOSES code as a Python library.</p>
        </body>

<p class="pptt" id="biaoti29643">### Equipment</p><ol class="npwtwok"><li>Single-channel or multi-channel time-lapse microscope, for taking videos of any modality, <em>e.g.</em>, fluorescence, phase contrast <br/><em>Note: Videos should be in one of the standard bio-formats (TIFF, STK, LSM or FluoView) or a commonly used general video format (.mp4, .avi, .mov).</em> </li><li>Computer <br/>Recommended PC requirements:<br/>Processor (CPU): minimum Intel i5 2.4GHz <br/>RAM: minimum 8GB, recommended &gt; 16GB <br/>Hard disk: few MBs per multi-channel image<br/><em>Note: The recommended requirements are given for 1024 x 1344 RGB images. The use of smaller sized or downsampled images require less RAM and less powerful CPU specifications.</em><br/></li></ol><p class="pptt" id="biaoti29644">### Software</p><ol class="npwtwok"><li>Windows/MacOS/Linux Operating system (64-bit)</li><li>Python 2.7 or 3.6 Python Anaconda installation</li><li>Git (<a href="https://git-scm.com/" target="_blank">https://git-scm.com/</a>)</li><li>Motion Sensing Superpixels (MOSES, <a href="https://github.com/fyz11/MOSES" target="_blank">https://github.com/fyz11/MOSES</a>)</li><li>Fiji ImageJ for visualization (<a href="https://fiji.sc/" target="_blank">https://fiji.sc/</a>)<br/></li></ol><p class="pptt" id="biaoti29645">### Procedure</p><p class="ppzz">We describe the general protocol to extract superpixel long-time trajectories and motion measurements as described in our original publication (Zhou <em>et al.</em>, 2019). The presented code snippets in this section are also provided in the <a href="https://os.bio-protocol.org/attached/file/20190616/Supplementary Script Files.zip" target="_blank">supplementary Python script file (âgeneral_analysis_protocol.pyâ)</a> to aid re-implementation. Adaptation of the basic procedure for the analysis of different datasets acquired by different microscope modalities is detailed in the Data Analysis section. The code and protocols should work for both Python 2 and 3 installations. They were originally developed using Python 2.7 under a Linux Mint Cinnamon 17 operating system. We assume throughout basic familiarity with working with command line prompts and terminals such as folder navigation using the cd or dir commands and basic Python usage including the importing of Python modules using import, array indexing using NumPy and plotting using Matplotlib libraries.</p><br/><ol class="npwone"><li>Protocol Nomenclature<ol class="npwtwo"><li>âOpen a terminalâ: refers to the launching of an appropriate terminal window on your operating system (OS) to issue command-line commands. On Windows the terminal is the command prompt or Git bash program. On Windows systems a command prompt can be launched by opening the Start Menu, typing in the search bar <em>cmd</em> and clicking on the command prompt logo, usually the first search result. On MacOS one can execute the shortcut key combination (â + Ctrl T). On Linux systems one can execute the shortcut key combination (Ctrl-Alt T).</li><li>Commands to be executed in a terminal are distinguished from regular text by use of the true typewriter font <span style="font-family:Courier New;">Courier</span> <span style="font-family:Courier New;">New</span> for example <span style="font-family:Courier New;">python script.py</span>.</li><li><span style="font-family:Courier New;">&lt;input folder&gt;</span>: angular brackets denote text placeholders. The user should replace the placeholder with an appropriate text string (enclosed by speech marks or without spaces) according to the prompt text written in true typewriter font within the brackets. Usually, this is the path to a particular input/output file or folder.<br/><br/></li></ol></li><li>Installing Python and MOSES<ol class="npwtwo"><li><a href="https://www.anaconda.com/distribution/#download-section" target="_blank">Download</a> the appropriate Python Anaconda installer for your operating system. </li><li>Install Python Anaconda following the on-screen instruction prompts of the graphical installer to install for macOS and Windows. For Linux distributions open a terminal, execute <span style="font-family:Courier New;">bash &lt;path to installer file&gt;</span> and proceed to follow the instructions in the terminal.</li><li>(Optional) Create a new anaconda environment just for MOSES. Open a terminal and execute <span style="font-family:Courier New;">conda create --name &lt;myenv&gt; pip</span>. This will create a new virtual environment with the name myenv and pip, a package manager for Python. Check the environment was successfully created by executing <span style="font-family:Courier New;">conda info --envs</span>. We can now install Python software libraries only to this environment without affecting previous Python installations using conda by executing conda install <span style="font-family:Courier New;">&lt;package_name&gt; --name &lt;myenv&gt;</span>. To load and use this environment execute <span style="font-family:Courier New;">conda activate &lt;myenv&gt; or source activate &lt;myenv&gt;</span> in MacOS and Linux or <span style="font-family:Courier New;">activate myenv</span> in Windows. For more information regarding the management of virtual environments see <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html" target="_blank">https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html.</a> <br/><em>Note: This optional step helps to keep all software dependencies for MOSES isolated from the rest of your Python installations. </em> </li><li>Download the MOSES scripts from <a href="https://github.com/fyz11/MOSES" target="_blank">https://github.com/fyz11/MOSES.</a> Either:<ol class="npwthree"><li>Clone the github repository, <span style="font-family:Courier New;">git clone</span> <a href="https://github.com/fyz11/MOSES.git" target="_blank">https://github.com/fyz11/MOSES.git</a>.</li><li>Click the green âClone or downloadâ button. Then click âDownload ZIPâ and extract the .zip contents.</li></ol></li><li>Install MOSES. Either:<ol class="npwthree"><li>Install to your Python installation to make it available system wide. This can be done by executing python setup.py install in the downloaded Github folder. Installation in this manner enables the scripts to be imported and used no matter the location of your analysis scripts. If you have set up a virtual environment previously for MOSES, load the environment before executing the command.</li><li>Copy and paste the entire contents of the âMOSESâ folder in the Github repository into your top-level or root project folder such that âMOSESâ is co-located in the same subfolder used to store the analysis scripts (Figure 1). <br/><em>Note: Option a) minimizes code replication across projects whilst, option b) offers the greatest ease for prototyping and customizing the MOSES scripts.</em><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201045_8817.jpg" width="327"/><br/><strong>Figure 1. Assumed folder structure if copy and pasting MOSES code for installation</strong><br/><br/></li></ol></li><li>Install MOSES dependencies. MOSES depends on the number of externally managed Python code libraries that needs to be installed. Using option a) (Step B5b) above automates these steps. If using option b) (Step B5b) execute pip install âr requirements.txt in the terminal loading the virtual environment before execution if required. Please note MoviePy, one of the external Python dependencies required for reading and writing general video formats depends on the FFMPEG library (<a href="https://ffmpeg.org/" target="_blank">https://ffmpeg.org/</a>). This library should be automatically installed when MoviePy is installed. If this is not the case, please install manually.<br/><em>Note: <span style="font-family:Courier New;">requirements.txt</span> is a file in the downloaded MOSES Github repository which contains the names of all the required Python dependencies.</em><br/><br/></li></ol></li><li>Structure of the MOSES Library <br/>The MOSES library is organized according to Figure 2. Scripts are in general organized by function. For example âMotion_Analysisâ contains all scripts related to the analysis of motion such as the computation of motion metrics, âOptical_Flow_Trackingâ contains scripts related to the computation of the motion field and the tracking of superpixels to generate superpixel tracks and âUtility_Functionsâ contains useful scripts for file manipulation such as the reading and writing of videos. Importing of MOSES functions follow standard Python practice. <br/><em>Note: Detailed documentation of each implemented function can also be browsed viewed offline by navigating to and opening the <span style="font-family:Courier New;">index.html</span> file with any web browser. Within Python the normal <span style="font-family:Courier New;">help(&lt;function&gt;)</span>can be used to read the corresponding documentation for a given function.</em><br/>For the remaining sections of the protocol, we assume the exemplar folder structure in Figure 1 placing the analysis script and video data in separate folders. <br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201142_7776.jpg" width="218"/><br/><strong>Figure 2. Folder and file structure of the MOSES Github code repository</strong><br/><br/></li><li>Running Python <br/>Several ways exist to run Python. We recommend for scientific computing the use of Spyder as an integrated development environment for scientific analysis. If not available under the current environment it can be installed using <span style="font-family:Courier New;">conda install âc conda-forge spyder --name &lt;myenv&gt;</span>.<ol class="npwtwo"><li>Launch Spyder using the terminal <span style="font-family:Courier New;">spyder &amp;</span>. The interface is similar to that of RStudio for R users (Figure 3).</li><li>Copy and paste code snippets into the editor and save the script. </li><li>Run the entire script using the keyboard shortcut F5 or by clicking the green âplayâ button. Run selected lines of code using the keyboard shortcut F9.<br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201213_9463.jpg" width="155"/><br/><strong>Figure 3. Graphical user interface (GUI) of Spyder for scientific programming</strong><br/><br/></li></ol></li><li>Compute MOSES Superpixel Tracks<ol class="npwtwo"><li>Download the âc_EPC2(G)_CP-A(R)_KSFM+RPMI_5_Fast GFP.tif_R-G.tifâ video file to use as an example red-green fluorescent .tif timelapse video from the following Google Drive <a href="https://drive.google.com/drive/folders/0BwFVL6r9ww5BaTUtaUdYM3YyaEk" target="_blank">link</a> and save this to a âVideosâ subfolder underneath the âDataâ folder as in Figure 1. </li><li>Read in the video as a numpy array object by importing and using the function <span style="font-family:Courier New;">read_multiimg_PIL</span>. For multi-channel videos, this gives a 4-dimensional matrix, for single-channel videos this gives a 3-dimensional matrix. <br/><em>Note: More generally one can use the function <span style="font-family:Courier New;">read_multiimg_stack</span> instead to read in a general bio-format image with additional z-slices.<br/></em><br/><span style="font-family:Courier New;"><span style="font-family:Courier New;color:#EE33EE;">from</span> MOSES.Utility_Functions.file_io <span style="font-family:Courier New;color:#EE33EE;">import</span> read_multiimg_PIL</span><br/><br/><span style="font-family:Courier New;"> infile = <span style="font-family:Courier New;color:#E56600;">â../Data/Videos/c_EPC2(G)_CP-A(R)_KSFM+RPMI_5_Fast_GFP.tif_R-G.tifâ</span></span><br/><span style="font-family:Courier New;"> vidstack = read_multiimg_PIL(infile)</span><br/><br/><span style="font-family:Courier New;"><span style="font-family:Courier New;color:#60D978;"> # Check the read size was expected.</span></span><br/>n_frame, n_rows, n_cols, n_channels = vidstack.shape<br/><span style="font-family:Courier New;color:#FFE500;">print</span>(<span style="font-family:Courier New;color:#E56600;">â</span><span style="font-family:Courier New;color:#E56600;">Size of video: (</span><span style="font-family:Courier New;color:#337FE5;">%d</span><span style="font-family:Courier New;color:#E56600;">,</span><span style="font-family:Courier New;color:#337FE5;">%d</span><span style="font-family:Courier New;color:#E56600;">,</span><span style="font-family:Courier New;color:#337FE5;">%d</span><span style="font-family:Courier New;color:#E56600;">,</span><span style="font-family:Courier New;color:#337FE5;">%d</span><span style="font-family:Courier New;color:#E56600;">)</span><span style="font-family:Courier New;color:#E56600;">â </span>%(n_frame, n_rows, n_cols, n_channels))<br/><br/></li><li>Define the optical flow parameter settings used for superpixel tracking. For more details of the used FarnebÃ¤ck flow computation to compute pixel velocities refer to the <a href="https://docs.opencv.org/3.0-beta/modules/video/doc/motion_analysis_and_object_tracking.html" target="_blank">OpenCV documentation</a> and the original paper (FarnebÃ¤ck, 2003). The parameters determine the accuracy of the motion field computation (see Notes). <br/><em>Note: Use more levels, </em><em>e.g.</em><em>, 5, increase the winsize, </em><em>e.g.</em><em>, 21 and increase iterations </em><em>e.g.</em><em>, 5 to capture discontinuous movement over larger distances (with respect to input image size as measured in pixels), see also notes section of this protocol. <br/></em><br/><span style="font-family:Courier New;">optical_flow_p</span><span style="font-family:Courier New;">arams = </span><span style="font-family:Courier New;color:#009900;">dict</span><span style="font-family:Courier New;">(</span><span style="font-family:Courier New;color:#00D5FF;">pyr_scale</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">0.5</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">levels</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">3</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">w</span><span style="font-family:Courier New;color:#00D5FF;">insize</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">15</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">iteratons</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">3</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">poly_n</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">5</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">poly_sigma</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1.2</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">flags</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">)</span><br/><br/></li><li>Specify the target number of superpixels or square region of interests (ROI) to subdivide the video frame. For an image size of <em><span style="font-family:Courier New;">n Ã m</span></em> pixels, a specification of <em><span style="font-family:Courier New;">N</span></em> superpixels would yield individual superpixels with an approximate size of <img alt="" class="layerphoto" height="25" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190920/20190920004434_1358.jpg" style="margin-top:5px;"/> pixels. For <em>n</em>=512,<em>m</em>=512,<em>N</em>=1000, each superpixel will be of size <em>â16Ã16</em> pixels.<br/><br/><span style="font-family:Courier New;color:#60D978;"># number of superpixels</span><br/><span style="font-family:Courier New;"> n_spixels = </span><span style="font-family:Courier New;color:#B8D100;">1000</span><br/><br/></li><li>For each image channel, extract the superpixel tracks and the computed motion field noting the 0-indexing.<br/><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Optical_Flow_Tracking.superpixel_track </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> compute_grayscale_vid_superpixel_tracks</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># extract superpixel tracks for the 1st or âredâ channel</span><br/><span style="font-family:Courier New;"> optflow_r, meantracks_r = compute_grayscale_vid_superpixel_tracks(vidstack[:,:,:,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">], optical_flow_params, n_spixels)</span><br/><span style="font-family:Courier New;color:#60D978;"># extract superpixel tracks for the 2nd or âgreenâ channel</span><br/><span style="font-family:Courier New;"> optflow_g, meantracks_g = compute_grayscale_vid_superpixel_tracks(vidstack[:,:,:,</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">], optical_flow_params, n_spixels)</span><br/><br/></li><li>Save the computed tracks in .mat MATLAB format. Alternative formats that support Python array saving can be used such as Python pickle or HDF.<br/><br/><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> scipy.io <span style="font-family:Courier New;color:#CC00CC;">as</span> spio</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> os</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">fname = os.path.split(infile)[-1]</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">savetracksmat = (<span style="font-family:Courier New;color:#E36C0A;">âmeantracks_â</span> + fname).replace(<span style="font-family:Courier New;color:#E36C0A;">â.tifâ</span>, <span style="font-family:Courier New;color:#E36C0A;">â.matâ</span>)</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">spio.savemat(savetracksmat, {<span style="font-family:Courier New;color:#E36C0A;">âmeantracks_râ</span>:meantracks_r, <span style="font-family:Courier New;color:#E36C0A;">âmeantracks_gâ</span>: meantracks_g})</span> </p><br/></li><li>(Optional) Visualize the motion field for select frames to check the computation (Figure 4) and optionally save the computed motion field. <br/><em>Note: For large images saving the motion field takes up a lot of hard disk space. It is therefore not recommended to do so. The motion field is summarized by the superpixel tracks.</em> <br/><br/><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> pylab </span><span style="font-family:Courier New;color:#EE33EE;">as</span><span style="font-family:Courier New;"> plt </span><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Visualisation_Tools.motion_field_visualisation </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> view_ang_flow</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># visualize first frame of red and green motion fields</span><br/><span style="font-family:Courier New;"> fig, ax = plt.subplots(nrows=1, ncols=2)</span><br/><span style="font-family:Courier New;"> ax[0].imshow(view_ang_flow(optflow_g[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">]))</span><br/><span style="font-family:Courier New;"> ax[1].imshow(view_ang_flow(optflow_r[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">]))</span><br/><span style="font-family:Courier New;"> ax[0].grid(</span><span style="font-family:Courier New;color:#E56600;">âoffâ</span><span style="font-family:Courier New;">); ax[1].grid(</span><span style="font-family:Courier New;color:#FF9900;">âoffâ</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> plt.show()</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># save the flow</span><br/><span style="font-family:Courier New;"> save_optflow_mat = (</span><span style="font-family:Courier New;color:#E56600;">âoptflow_â</span><span style="font-family:Courier New;">+fname).replace(</span><span style="font-family:Courier New;color:#E56600;">â.tifâ</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#E56600;">â.matâ</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> spio.savemat(save_optflow_mat, {</span><span style="font-family:Courier New;color:#E56600;">âoptflow_râ</span><span style="font-family:Courier New;">: optflow_r, </span><span style="font-family:Courier New;color:#E56600;">âoptflow_gâ</span><span style="font-family:Courier New;">: optflow_g})</span><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201339_4274.jpg" width="302"/><br/><strong>Figure 4. Visualization of the computed first frame motion field using optical flow for red and green channel images.</strong> The individual pixel velocities are colored by their angular direction using the color wheel with the color intensity encoding the pixel speed. Scale bars: 200 Âµm.<br/><br/></li><li>(Optional) Plot the superpixel tracks as a second sanity check. The shape of the tracks should capture the dynamic range of the moving entities in the video. For epithelial sheets, this is the shape of the leading edge of the sheet (Figure 5).<br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201403_6225.jpg" width="131"/><br/><strong>Figure 5. Plot of the red and green channel superpixel tracks.</strong> The green EPC2 tracks end on the right where it met the red CP-A tracks and was pushed back to the left. The red CP-A tracks end on the left at the final position where it has pushed the green EPC2 cells to. <br/><br/></li><li>(Optional for debugging) Produce a video of the superpixel tracks overlaid on the video, plotting each track in temporal segments of 5 frames to avoid clutter. Frames are generated sequentially. Subsequently, import the saved frames using Fiji ImageJ in temporal order, <em>File â Import â </em> <em> Image Sequence... </em>and save as a multipage .tif video (<em>File â Save As â Tiff...</em>) or .avi video, (<em>File â Save As â AVI...</em>).<br/><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Utility_Functions.file_io </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> mkdir</span><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Visualisation_Tools.track_plotting </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> plot_tracks</span><br/><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> os </span><br/><span style="font-family:Courier New;"> fname = os.path.split(infile)[-1]</span><br/><span style="font-family:Courier New;color:#60D978;"># specify the save folder and create this automatically.</span><br/><span style="font-family:Courier New;"> save_frame_folder = </span><span style="font-family:Courier New;color:#E56600;">âtrack_videoâ</span><br/><span style="font-family:Courier New;"> mkdir(save_frame_folder)</span><br/><br/><span style="font-family:Courier New;"> len_segment = </span><span style="font-family:Courier New;color:#B8D100;">5</span><br/><br/><span style="font-family:Courier New;color:#EE33EE;">for</span><span style="font-family:Courier New;"> frame </span><span style="font-family:Courier New;color:#337FE5;">in</span> <span style="font-family:Courier New;color:#FFE500;">range</span><span style="font-family:Courier New;">(len_segment, n_frame, 1):</span><br/><span style="font-family:Courier New;"> frame_img = vidstack[frame]</span><br/><br/><span style="font-family:Courier New;"> fig = plt.figure()</span><br/><span style="font-family:Courier New;"> fig.set_size_inches(</span><span style="font-family:Courier New;color:#009900;">float</span><span style="font-family:Courier New;">(n_cols)/n_rows, </span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">forward=False</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax=plt.Axes(fig, [</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">.,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">.,</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">.,</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">.]); ax.set_axis_off(); fig.add_axes(ax)</span><br/><span style="font-family:Courier New;"> ax.imshow(frame_img, </span><span style="font-family:Courier New;color:#00D5FF;">alpha</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">0.6</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;color:#60D978;"># visualize only a short segment</span><br/><span style="font-family:Courier New;"> plot_tracks(meantracks_r[:,frame-len_segment:frame+1],ax, </span><span style="font-family:Courier New;color:#00D5FF;">color</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'r'</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#00D5FF;"> lw</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> plot_tracks(meantracks_g[:,frame-len_segment:frame+1],ax, </span><span style="font-family:Courier New;color:#00D5FF;">color</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'g'</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">lw</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax.set_xlim([0, n_cols]); ax.set_ylim([n_rows, 0])</span><br/><span style="font-family:Courier New;"> ax.grid(</span><span style="font-family:Courier New;color:#E56600;">'off'</span><span style="font-family:Courier New;">); ax.axis(</span><span style="font-family:Courier New;color:#E56600;">'off'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;color:#60D978;"># tip: use multiples of n_rows to increase image resolution</span><br/><span style="font-family:Courier New;"> fig.savefig(os.path.join(save_frame_folder, </span><span style="font-family:Courier New;color:#E56600;">'tracksimg-</span><span style="font-family:Courier New;color:#337FE5;">%s</span><span style="font-family:Courier New;">_' %(</span><span style="font-family:Courier New;color:#009900;">str</span><span style="font-family:Courier New;">(frame+1).zfill(</span><span style="font-family:Courier New;color:#B8D100;">3</span><span style="font-family:Courier New;">))+fname.replace(</span><span style="font-family:Courier New;color:#E56600;">'.tif'</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#E56600;">'.png'</span><span style="font-family:Courier New;">)), </span><span style="font-family:Courier New;color:#00D5FF;">dpi</span><span style="font-family:Courier New;">=n_rows) </span><br/><span style="font-family:Courier New;"> plt.show()</span><br/><br/></li></ol></li><li>Construct Mesh from Superpixel Tracks<br/>Any individual moving entity inevitably affects the motion of surrounding entities. Considering superpixels as individual moving elements, it becomes natural to capture the interaction between each superpixel and its neighbors. Computationally this interaction can be captured in a mesh or graph with mesh edges representing the presence of an interaction. This mesh construction critically depends on what one considers evidence of interaction or motion similarity. As such different meshes can be constructed to better highlight different aspects of the cellular motion. We direct the interested reader to the supplementary information of Zhou <em>et al.</em>, 2019 for an extended discussion. Below we describe the construction steps for three meshes which connect together superpixel tracks based on different notions of spatial proximity. <ol class="npwtwo"><li>Construct the MOSES mesh for individual image channels by connecting each superpixel track to all superpixel tracks separated by at most a pixel distance less than a multiple (<span style="font-family:Courier New;">dist_thresh</span>) of the average superpixel width (<span style="font-family:Courier New;">spixel_size</span>) based on the initial (<em>x,y</em>) position of superpixels. <br/><em>Note: The MOSES mesh captures how superpixels move with respect to their initial neighbors.<br/><br/></em><span style="font-family:Courier New;"><span style="font-family:Courier New;color:#EE33EE;">from</span> MOSES.Motion_Analysis.mesh_statistics_tools <span style="font-family:Courier New;color:#EE33EE;">import</span> construct_MOSES_mesh</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># specify the average superpixel size. This is roughly the width for squares</span><br/><span style="font-family:Courier New;">spixel_size = meantracks_r[1,0,1] - meantracks_r[1,0,0]</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># compute the MOSES mesh, linking together all superpixels located a distance dist_thresh*spixel_size for each colour channel</span><br/><span style="font-family:Courier New;">MOSES_mesh_strain_time_r, MOSES_mesh_neighborlist_r = construct_MOSES_mesh(meantracks_r, <span style="font-family:Courier New;color:#00D5FF;">dist_thresh</span>=<span style="font-family:Courier New;color:#B8D100;">1.2</span>, <span style="font-family:Courier New;color:#00D5FF;">spixel_size</span>=spixel_size)</span><br/><span style="font-family:Courier New;">MOSES_mesh_strain_time_g, MOSES_mesh_neighborlist_g = construct_MOSES_mesh(meantracks_g, <span style="font-family:Courier New;color:#00D5FF;">dist_thresh</span>=<span style="font-family:Courier New;color:#B8D100;">1.2</span>, <span style="font-family:Courier New;color:#00D5FF;">spixel_size</span>=spixel_size)</span><br/><br/></li><li>Construct the radial neighbors mesh for individual image channels by connecting each superpixel track to all superpixel tracks at time <em>t</em> separated by at most a pixel distance less than a multiple (dist_thresh) of the average superpixel width (spixel_size) based on the (<em>x,y</em>) position of the superpixels at time <em>t</em>. <br/><em>Note: Unlike the MOSES mesh, the connections between neighbors in the radial neighbor mesh dynamically changes over time. <br/></em><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> construct_radial_neighbour_mesh</span><br/><br/><span style="font-family:Courier New;"> radial_mesh_strain_time_r, radial_neighbourlist_time_r = construct_radial_neighbour_mesh(meantracks_r, <span style="font-family:Courier New;color:#00D5FF;">dist_thresh</span>=<span style="font-family:Courier New;color:#B8D100;">1.2</span>, <span style="font-family:Courier New;color:#00D5FF;">spixel_size</span>=spixel_size, <span style="font-family:Courier New;color:#00D5FF;">use_counts=False</span>)</span><br/><span style="font-family:Courier New;"> radial_mesh_strain_time_g, radial_neighbourlist_time_g = construct_radial_neighbour_mesh(meantracks_g, <span style="font-family:Courier New;color:#00D5FF;">dist_thresh</span>=<span style="font-family:Courier New;color:#B8D100;">1.2</span>, <span style="font-family:Courier New;color:#00D5FF;">spixel_size</span>=spixel_size, <span style="font-family:Courier New;color:#00D5FF;">use_counts=False</span>)</span><br/><br/></li><li>Construct the <em>K</em> nearest neighbor mesh for individual image channels by connecting each superpixel track to the <em>K</em> superpixel tracks at time <em>t</em> that is spatially closest based on the (<em>x,y</em>) position of the superpixels at time <em>t</em>. <br/><em>Note: This mesh is constructed based on topological distance and is suitable when the physical spatial separation is not a significant factor. <br/></em><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> construct_knn_neighbour_mesh</span><br/><br/><span style="font-family:Courier New;"> knn_mesh_strain_time_r, knn_neighbourlist_time_r = construct_knn_neighbour_mesh(meantracks_r, </span><span style="font-family:Courier New;color:#00D5FF;">k</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">4</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> knn_mesh_strain_time_g, knn_neighbourlist_time_g = construct_knn_neighbour_mesh(meantracks_g, </span><span style="font-family:Courier New;color:#00D5FF;">k</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">4</span><span style="font-family:Courier New;">)</span><br/><br/></li><li>(Optional) Visualize the constructed mesh at select frames (here for example frame 20) to check construction (Figure 6). The example code visualizes the MOSES mesh from Step F1. Any mesh specified either as a networkx graph object or as a list specifying the array index of superpixels connected to each superpixel <em>i</em> can similarly be visualized. <br/><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Visualisation_Tools.mesh_visualisation </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> visualize_mesh</span><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> from_neighbor_list_to_graph</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># use networkx to visualize the mesh at frame 20. To do so need to first convert the neighborlist into a networkx graph object.</span><br/><span style="font-family:Courier New;"> mesh_frame20_networkx_G_red = from_neighbor_list_to_graph(meantracks_r, MOSES_mesh_neighborlist_r, </span><span style="font-family:Courier New;color:#B8D100;">20</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> mesh_frame20_networkx_G_green = from_neighbor_list_to_graph(meantracks_g, MOSES_mesh_neighborlist_g, </span><span style="font-family:Courier New;color:#B8D100;">20</span><span style="font-family:Courier New;">)</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># set up a 1 x 2 plotting canvas.</span><br/><span style="font-family:Courier New;"> fig, ax = plt.subplots(</span><span style="font-family:Courier New;color:#00D5FF;">nrows</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;"></span><span style="font-family:Courier New;color:#00D5FF;">ncols</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">2</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">figsize</span><span style="font-family:Courier New;">=(</span><span style="font-family:Courier New;color:#B8D100;">15</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#B8D100;">15</span><span style="font-family:Courier New;">))</span><br/><span style="font-family:Courier New;color:#60D978;"># plot the red mesh in left panel.</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">].imshow(vidstack[</span><span style="font-family:Courier New;color:#B8D100;">20</span><span style="font-family:Courier New;">], </span><span style="font-family:Courier New;color:#00D5FF;">alpha</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">0.7</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> visualise_mesh(mesh_frame20_networkx_G_red, meantracks_r[:,</span><span style="font-family:Courier New;color:#B8D100;">20</span><span style="font-family:Courier New;">,[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">]], ax[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">], </span><span style="font-family:Courier New;color:#00D5FF;">node_size</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">20</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">linewidths</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">width</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">node_color</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">ârâ</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">].set_ylim([n_rows,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">])</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">].set_xlim([</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">,n_cols])</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">].grid(</span><span style="font-family:Courier New;color:#E56600;">âoffâ</span><span style="font-family:Courier New;">); ax[0].axis(</span><span style="font-family:Courier New;color:#E56600;">âoffâ</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;color:#60D978;"># plot the green mesh in right panel.</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].imshow(vidstack[</span><span style="font-family:Courier New;color:#B8D100;">20</span><span style="font-family:Courier New;">], </span><span style="font-family:Courier New;color:#00D5FF;">alpha</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">0.7</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> visualise_mesh(mesh_frame20_networkx_G_green, meantracks_g[:,</span><span style="font-family:Courier New;color:#B8D100;">20</span><span style="font-family:Courier New;">,[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">]], ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">], </span><span style="font-family:Courier New;color:#00D5FF;">node_size</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">20</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">linewidths</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">width</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">node_color</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">âgâ</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].set_ylim([n_rows,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">])</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].set_xlim([</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">,n_cols])</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].grid(</span><span style="font-family:Courier New;color:#E56600;">âoffâ</span><span style="font-family:Courier New;">); ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].axis(</span><span style="font-family:Courier New;color:#E56600;">âoffâ</span><span style="font-family:Courier New;">)</span><br/><br/></li></ol></li><li>Extracting MOSES motion measurements<br/>Several motion metrics were proposed in the original paper (Zhou <em>et al.</em>, 2019). Here we show how to compute the main proposed metrics using the provided functions in MOSES. <ol class="npwtwo"><li>Construct the motion saliency map for each color. The motion saliency map reveals spatial regions of significant motion concentration. It is computed by accumulating the mesh deformation strain in local spatial regions across time. <br/><br/><span style="font-family:Courier New;color:#EE33EE;">f</span><span style="font-family:Courier New;color:#EE33EE;">rom</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> compute_motion_saliency_map</span><br/><br/><span style="font-family:Courier New;"> final_saliency_map_r, spatial_time_saliency_map_r = compute_motion_saliency_map(meantracks_r, </span><span style="font-family:Courier New;color:#00D5FF;">dist_thresh</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">5</span><span style="font-family:Courier New;">.*spixel_size, </span><span style="font-family:Courier New;color:#00D5FF;">shape</span><span style="font-family:Courier New;">=(n_rows, n_cols), </span><span style="font-family:Courier New;color:#00D5FF;">filt</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">filt_size</span><span style="font-family:Courier New;">=spixel_size)</span><br/><span style="font-family:Courier New;"> final_saliency_map_g, spatial_time_saliency_map_g = compute_motion_saliency_map(meantracks_g,</span><span style="font-family:Courier New;color:#00D5FF;"> dist_thresh</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">5</span><span style="font-family:Courier New;">.*spixel_size, </span><span style="font-family:Courier New;color:#00D5FF;">shape</span><span style="font-family:Courier New;">=(n_rows, n_cols), </span><span style="font-family:Courier New;color:#00D5FF;">filt</span><span style="font-family:Courier New;">=<span style="font-family:Courier New;color:#B8D100;">1</span>, </span><span style="font-family:Courier New;color:#00D5FF;">filt_size</span><span style="font-family:Courier New;">=spixel_size)<br/><br/></span> </li><li>Compute the boundary formation index from the motion saliency map. The boundary formation index is defined as the normalized ratio of the mean motion saliency map intensity values, I in high intensity image regions over low intensity image regions (âredâ and âblueâ areas in Figure 7A). The intensity cut-off is automatically determined via Otsu thresholding so that a pixel with image coordinate (<em>i,j</em>) is in the âhighâ region if <em>I(</em><em>i,j</em><em>)â¥I_thresh</em> or else is âlowâ. The boundary formation index takes values between 0 and 1. The higher the value, the greater the propensity of motion to be concentrated within a particular spatial region. <br/><br/><img alt="" class="layerphoto" height="50" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918210840_2510.jpg" width="294"/><br/><br/><em>Note: Cells moving out of the field of view of the video cause superpixels to concentrate at the boundary of the videos. This causes an artefactual increase in motion density at image edges. To minimize this effect, the boundary formation index is computed in the region at least a <span style="font-family:Courier New;">pad_multiple</span> times <span style="font-family:Courier New;">spixel_size</span> away from the image boundary.<br/></em><br/><span style="font-family:Courier New;"><span style="font-family:Courier New;color:#EE33EE;">from</span> MOSES.Motion_Analysis.mesh_statistics_tools <span style="font-family:Courier New;color:#EE33EE;">import</span> compute_boundary_formation_index</span><br/><br/><span style="font-family:Courier New;"> boundary_formation_index, av_saliency_map = compute_boundary_formation_index(final_saliency_map_r, final_saliency_map_g, spixel_size, <span style="font-family:Courier New;color:#00D5FF;">pad_multiple</span>=<span style="font-family:Courier New;color:#99BB00;">3</span>)</span><br/><br/><span style="font-family:Courier New;"> fig = plt.figure()</span><br/><span style="font-family:Courier New;"> plt.title(<span style="font-family:Courier New;color:#E56600;">'Boundary Formation Index</span> <span style="font-family:Courier New;color:#337FE5;">%.3f</span><span style="font-family:Courier New;color:#000000;"><span style="font-family:Courier New;color:#E56600;">'</span> %(boundary_formation_index))</span></span><br/><span style="font-family:Courier New;"> plt.imshow(av_saliency_map, <span style="font-family:Courier New;color:#00D5FF;">cmap</span>=<span style="font-family:Courier New;color:#E56600;">'coolwarm'</span>)</span><br/><span style="font-family:Courier New;"> plt.axis(<span style="font-family:Courier New;color:#E56600;">'off'</span>); plt.grid(<span style="font-family:Courier New;color:#E56600;">'off'</span>)</span><br/><span style="font-family:Courier New;"> plt.show()</span><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201526_6098.jpg" width="240"/><br/><strong>Figure 6. Visualization of the constructed MOSES mesh linking individual superpixels </strong><strong>with centroids represented by dots</strong><br/><br/></li><li>Compute the MOSES mesh strain curve of the video, the mean of curves of the individual red and green channel curves (Figure 7B). The mesh strain curve measures the mean change in the relative spatial arrangement (topology) between neighboring superpixels over time.<br/><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools <span style="font-family:Courier New;color:#EE33EE;">import</span> compute_MOSES_mesh_strain_curve</span><br/><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> numpy </span><span style="font-family:Courier New;color:#EE33EE;">as</span><span style="font-family:Courier New;"> np</span><br/><span style="font-family:Courier New;color:#60D978;"># set normalise=True to obtain normalised curves between 0-1. </span><br/><span style="font-family:Courier New;"> mesh_strain_r=compute_MOSES_mesh_strain_curve(MOSES_mesh_strain_time_r, </span><span style="font-family:Courier New;color:#00D5FF;">normalise</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#337FE5;">False</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> mesh_strain_g=compute_MOSES_mesh_strain_curve(MOSES_mesh_strain_time_g, </span><span style="font-family:Courier New;color:#00D5FF;">normalise</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#337FE5;">False</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;color:#60D978;"># average the channel curves to get one curve for the video.</span><br/><span style="font-family:Courier New;"> mesh_strain_curve_video = .5*(mesh_strain_r+mesh_strain_g)</span><br/><span style="font-family:Courier New;color:#60D978;"># normalise the curves, this is equivalent to normalise=True above for a single channel.</span><br/><span style="font-family:Courier New;"> normalised_mesh_strain_curve_video = mesh_strain_curve_video/ np.max(mesh_strain_curve_video)</span><br/><br/></li><li>Compute the mesh stability index defined as 1 minus the normalized gradient of the mesh strain curve, <em>y</em> over a small time window, Î<em>T</em> at the end of the video motion (in the interval [<em>T,T+</em>Î<em>T</em>]). Here the time window is Î<em>T</em><em>=5</em> frames (Figure 7B). <br/><br/><img alt="" class="layerphoto" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918210921_6077.jpg" width="420"/><br/><br/><span style="font-family:Arial;">where </span><em><span style="font-family:Arial;">y</span><sub><span style="font-family:Arial;">max</span></sub></em><span style="font-family:Arial;"> is the maximum value of the mesh strain curve and </span><em><span style="font-family:Arial;">T</span><sub><span style="font-family:Arial;">0</span></sub></em><span style="font-family:Arial;"> is the total number of video frames. The mesh stability index is upper bounded by 1. For the example video, you should get a value of 0.892.<br/></span><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> compute_MOSES_mesh_stability_index</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># the mesh stability index uses an average over the last number of frame specified by the flag, last_frames. One should set this to approximately cover the plateau region of the strain curve. </span><br/><span style="font-family:Courier New;"> mesh_stability_index, normalised_mesh_strain_curve = compute_MOSES_mesh_stability_index(MOSES_mesh_strain_time_r, MOSES_mesh_strain_time_g, </span><span style="font-family:Courier New;color:#00D5FF;">last_frames</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">5</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;color:#FFE500;">print</span><span style="font-family:Courier New;">(</span><span style="font-family:Courier New;color:#E56600;">'mesh stability index:</span> <span style="font-family:Courier New;color:#337FE5;">%</span><span style="font-family:Courier New;color:#337FE5;">.3f</span><span style="font-family:Courier New;color:#E56600;">'</span><span style="font-family:Courier New;"> %(mesh_stability_index))</span><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201559_4776.jpg" width="241"/><br/><strong>Figure 7. Motion saliency map, boundary formation index and mesh stability metrics.</strong> A. Computed motion saliency map and associated boundary formation index. B. Non-normalized MOSES mesh strain curve for red and green cell populations together with the average of the two curves (black line). Shaded blue region shows the 5 frame window used to compute the mesh stability index. <br/><br/></li><li>Compute the mesh strain vector. The mesh strain vector of each superpixel <em>i</em> is the vector sum of the displacements of neighboring superpixels <em>j</em> relative to the superpixel <em>i</em> in the mesh.<br/><br/><img alt="" class="layerphoto" height="50" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918211001_7397.jpg" width="248"/><br/><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> construct_mesh_strain_vector</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># given a mesh as a list of neighbours (also known as a region adjacency list), find the mesh strain vector</span><br/><span style="font-family:Courier New;"> mesh_strain_vector_r = construct_mesh_strain_vector(meantracks_r, [MOSES_mesh_neighborlist_r])</span><br/><span style="font-family:Courier New;"> mesh_strain_vector_g = construct_mesh_strain_vector(meantracks_g, [MOSES_mesh_neighborlist_r])</span><br/><br/></li><li>Compute the mesh order. The mesh order is the mean normalized mesh strain vector over all superpixels <em>i</em>, (Figure 8A). If all mesh strain vectors were aligned in the same direction, this value is 1. If there is no alignment it is 0. For the example video you should get 0.00325 (Figure 8B).<br/><br/><img alt="" class="layerphoto" height="50" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918211343_4092.jpg" width="164"/><br/><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> compute_mesh_order</span><br/><br/><span style="font-family:Courier New;"> mesh_order_curve_r = compute_mesh_order(mesh_strain_vector_r, </span><span style="font-family:Courier New;color:#00D5FF;">remove_mean</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#337FE5;">False</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> mesh_order_curve_g = compute_mesh_order(mesh_strain_vector_g, </span><span style="font-family:Courier New;color:#00D5FF;">remove_mean</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#337FE5;">False</span><span style="font-family:Courier New;">)</span><br/><br/><span style="font-family:Courier New;"> av_mesh_order = </span><span style="font-family:Courier New;color:#B8D100;">.5</span><span style="font-family:Courier New;">*(mesh_order_curve_r + mesh_order_curve_g)</span><br/><span style="font-family:Courier New;color:#FFE500;">print</span><span style="font-family:Courier New;">(</span><span style="font-family:Courier New;color:#E56600;">'average mesh order:</span> <span style="font-family:Courier New;color:#337FE5;">%.5f</span><span style="font-family:Courier New;color:#E56600;">' </span><span style="font-family:Courier New;">%(np.nanmean(av_mesh_order)))</span><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201632_3329.jpg" width="339"/><br/><strong>Figure 8. Visualization of the mesh order and mesh order curve.</strong> A. Mesh strain vector (colored arrows) of individual superpixels (mesh vertices) for each colored cell population overlaid on top of the MOSES mesh for frame 20. B. Evolution of the mesh order over time for individual colored populations and the average of the two colored curves (black line). Dashed black line is the mean value of all temporal values reported as the mean mesh order for the video. </li></ol></li></ol><p class="pptt" id="biaoti29646">### Data analysis</p><p class="ppzz"><br/>The demo analyses presented in this section expands upon the general protocol detailed above by walking through the standard steps of motion analysis using MOSES on various different biological imaging datasets. The steps below illustrate how to adapt and work with MOSES to handle a breadth of different datasets. The analyses are additionally provided as <a href="https://os.bio-protocol.org/attached/file/20190616/Supplementary Script Files.zip" target="_blank">supplementary Python script files (.py)</a>.<br/><br/><strong>Analysis 1: Single Cell Tracking</strong> (Phase Contrast Microscopy) (<a href="https://os.bio-protocol.org/attached/file/20190616/Supplementary Script Files.zip" target="_blank">Supplementary files</a>)<br/>We use the data from the Cell Tracking Challenge (<a href="http://celltrackingchallenge.net/" target="_blank">http://celltrackingchallenge.net/</a>) to illustrate how to use MOSES for single cell tracking analysis. As cell division is not currently explicitly modeled within the motion extraction in MOSES, this analysis is most effective for videos where cell proliferation is minimal or when extraction of the global âmotionâ pattern is more important.</p><ol class="npwtwo"><li>Register for a free account at <a href="http://celltrackingchallenge.net/registration/" target="_blank">http://celltrackingchallenge.net/registration/</a>, the official challenge website to download the datasets. </li><li>Download the U373 cell training dataset from <a href="http://celltrackingchallenge.net/2d-datasets/" target="_blank">http://celltrackingchallenge.net/2d-datasets/</a>.</li><li>Unzip the downloaded âPhC-C2DH-U373.zip folderâ. You should find 4 folders, â01â, â01_GTâ, â02â and â02_GTâ which specify two image sequences and their associated annotated ground truth (GT). We will only use the image sequence in â01â as an example. </li><li>Load and concatenate the image frames of â01â in Python into a numpy array. The result should be a (115, 520, 696) size NumPy array. <br/><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> skimage.exposure </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> rescale_intensity</span><br/><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> numpy </span><span style="font-family:Courier New;color:#EE33EE;">as</span><span style="font-family:Courier New;"> np </span><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Utility_Functions.file_io </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> detect_files</span><br/><span style="font-family:Courier New;color:#EE33EE;"> from</span> <span style="font-family:Courier New;">skimage.io</span> <span style="font-family:Courier New;color:#EE33EE;">import<span> <span style="font-family:Courier New;">imread</span><br/><br/><span style="font-family:Courier New;"> vid_folder = </span><span style="font-family:Courier New;color:#E56600;">'../Data/Videos/PhC-C2DH-U373/01'</span><br/><span style="font-family:Courier New;color:#60D978;"># load individal video frames saved as .tif files.</span> <br/><span style="font-family:Courier New;"> video_files, video_fnames = detect_files(vid_folder, </span><span style="font-family:Courier New;color:#00D5FF;">ext</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'.tif'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;color:#60D978;"># read individual frames and concatenate frames after rescaling intensity </span><br/><span style="font-family:Courier New;"> vidstack = np.concatenate([rescale_intensity(imread(f))[</span><span style="font-family:Courier New;color:#337FE5;">None</span><span style="font-family:Courier New;">,:] </span><span style="font-family:Courier New;color:#EE33EE;">for</span><span style="font-family:Courier New;"> f </span><span style="font-family:Courier New;color:#337FE5;">in</span><span style="font-family:Courier New;"> video_files], </span><span style="font-family:Courier New;color:#00D5FF;">axis</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">)</span><br/><br/></span></span> </li><li>Compute the superpixel tracks using <span style="font-family:Courier New;">n_spixels = 1000</span>, (Figure 9A). Here we use <span style="font-family:Courier New;">compute_grayscale_vid_superpixel_tracks_FB</span> to extract additional âbackwardâ tracks as a result of applying tracking running the video backward in time. Forward tracking reveals where motion flows towards (sinks) whilst backward tracking reveals spatial origins (sources) of motion, see advanced analysis section below. <br/><em>Note: How will the superpixel tracks change when we increase or decrease n_spixels?<br/></em><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Optical_Flow_Tracking.superpixel_track </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> compute_grayscale_vid_superpixel_tracks_FB</span><br/><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> scipy.io </span><span style="font-family:Courier New;color:#EE33EE;">as</span><span style="font-family:Courier New;"> spio</span><br/><br/><span style="font-family:Courier New;"> n_spixels = </span><span style="font-family:Courier New;color:#B8D100;">1000</span><br/><span style="font-family:Courier New;color:#60D978;"># set the motion extraction parameters</span><br/><span style="font-family:Courier New;"> opt_flow_params = {</span><span style="font-family:Courier New;color:#E56600;">'pyr_scale'</span><span style="font-family:Courier New;">:</span><span style="font-family:Courier New;color:#B8D100;">0.5</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#E56600;">'levels'</span><span style="font-family:Courier New;">:</span><span style="font-family:Courier New;color:#B8D100;">7</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#E56600;">'winsize'</span><span style="font-family:Courier New;">:</span><span style="font-family:Courier New;color:#B8D100;">25</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#E56600;">'iterations'</span><span style="font-family:Courier New;">:</span><span style="font-family:Courier New;color:#B8D100;">3</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#E56600;">'poly_n</span><span style="font-family:Courier New;color:#E56600;">'</span><span style="font-family:Courier New;">:</span><span style="font-family:Courier New;color:#B8D100;">5</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#E56600;">'poly_sigma'</span><span style="font-family:Courier New;">:</span><span style="font-family:Courier New;color:#B8D100;">1.2</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#E56600;">'flags'</span><span style="font-family:Courier New;">:</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">}</span><br/><span style="font-family:Courier New;color:#60D978;"># compute superpixel tracks</span><br/><span style="font-family:Courier New;"> optflow, tracks_F, tracks_B = compute_grayscale_vid_superpixel_tracks_FB(vidstack, opt_flow_params, </span><span style="font-family:Courier New;color:#00D5FF;">n_spixels</span><span style="font-family:Courier New;">=n_spixels)</span><br/><span style="font-family:Courier New;color:#60D978;"># save the tracks </span><br/><span style="font-family:Courier New;"> spio.savemat(</span><span style="font-family:Courier New;color:#E56600;">'vid01_</span><span style="font-family:Courier New;color:#337FE5;">%d</span><span style="font-family:Courier New;color:#E56600;">_spixels.mat'</span><span style="font-family:Courier New;"> %(n_spixels), {</span><span style="font-family:Courier New;color:#E56600;">'tracks_F'</span><span style="font-family:Courier New;">: tracks_F, </span><span style="font-family:Courier New;color:#E56600;">'tracks_B'</span><span style="font-family:Courier New;">: tracks_B})</span><br/><br/></li><li>To track cells present in the initial frame over time segment the individual cells automatically using image thresholding and connected component analysis or by manual annotation. In the paper (Zhou <em>et al.</em>, 2019) manual annotation was used, here we use automated image thresholding (Figure 9B). <br/><em>Note: Exact segmentation is not required although the more accurate the segmentation, generally the better the specificity of tracking. Results are nevertheless stable for less optimal segmentations. How are the results if bounding boxes were used? <br/></em><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> skimage.filters </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> threshold_otsu, threshold_triangle</span><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> skimage.measure </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> label</span><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> skimage.morphology </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> remove_small_objects, binary_closing, disk</span><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> scipy.ndimage.morphology </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> binary_fill_holes</span><br/><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> pylab </span><span style="font-family:Courier New;color:#EE33EE;">as</span><span style="font-family:Courier New;"> plt </span><br/><br/><span style="font-family:Courier New;color:#60D978;"># first frame of video</span><br/><span style="font-family:Courier New;"> frame0 = vidstack[<span style="font-family:Courier New;color:#B8D100;">0</span>]</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># basic quick cell segmentation by thresholding intensities</span><br/><span style="font-family:Courier New;color:#60D978;"> # a) determine intensity threshold</span><br/><span style="font-family:Courier New;"> thresh = np.mean(frame0) + .5*np.std(frame0)</span><br/><span style="font-family:Courier New;"> binary = frame0 &gt;= thresh</span><br/><span style="font-family:Courier New;color:#60D978;"># b) steps to refine the basic thresholding of a)</span><br/><span style="font-family:Courier New;"> binary = remove_small_objects(binary, </span><span style="font-family:Courier New;color:#B8D100;">200</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> binary = binary_closing(binary, disk(</span><span style="font-family:Courier New;color:#B8D100;">5</span><span style="font-family:Courier New;">))</span><br/><span style="font-family:Courier New;"> binary = binary_fill_holes(binary)</span><br/><span style="font-family:Courier New;"> binary = remove_small_objects(binary, </span><span style="font-family:Courier New;color:#B8D100;">1000</span><span style="font-family:Courier New;">)</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># c) connected component analysis to label binary cell segmentation with integers</span><br/><span style="font-family:Courier New;"> cells_frame0 = label(binary)</span><br/><br/></li><li>Use the segmentation mask to assign superpixel tracks to each segmented cell (Figure 9). <br/><br/><span style="font-family:Courier New;color:#60D978;"># define a function 'assign_spixels' that can be called to assign superpixel tracks using an integer labelled mask</span><br/><span style="font-family:Courier New;color:#337FE5;">def</span> <span style="font-family:Courier New;color:#FFE500;">assign_spixels</span><span style="font-family:Courier New;">(</span><span style="font-family:Courier New;color:#00D5FF;">spixeltracks, mask</span><span style="font-family:Courier New;">): </span><br/><br/><span style="font-family:Courier New;"> uniq_regions = np.unique(mask)</span><br/><span style="font-family:Courier New;"> initial_pos = spixeltracks[:,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">,:]</span><br/><br/><span style="font-family:Courier New;"> bool_mask = []</span><br/><span style="font-family:Courier New;color:#60D978;"># starts from 1-index not 0-index as the first is assigned to the </span><span style="font-family:Courier New;color:#60D978;">background.</span><br/><span style="font-family:Courier New;color:#EE33EE;">for</span><span style="font-family:Courier New;"> uniq_region </span><span style="font-family:Courier New;color:#337FE5;">in</span><span style="font-family:Courier New;"> uniq_regions[1:]:</span><br/><span style="font-family:Courier New;"> mask_region = mask == uniq_region</span><br/><span style="font-family:Courier New;"> bool_mask.append(mask_region[initial_pos[:,0], initial_pos[:,1]])</span><br/><br/><span style="font-family:Courier New;"> bool_mask = np.vstack(bool_mask) </span><br/><span style="font-family:Courier New;color:#EE33EE;">return</span><span style="font-family:Courier New;"> bool_mask </span><br/><br/><span style="font-family:Courier New;"> cell_spixels = assign_spixels(tracks_F, cells_frame0)</span><br/><br/></li><li>Select the longest track as summary of the cellâs motion for each segmented cell region (Figure 9C). <br/><em>Note: Experiment with other ways to summarize the collection of tracks into one track such as taking the mean or median of the tracks.<br/></em><br/><span style="font-family:Courier New;color:#337FE5;">def</span> <span style="font-family:Courier New;color:#FFE500;">find_characteristic_motion</span><span style="font-family:Courier New;">(</span><span style="font-family:Courier New;color:#00D5FF;">tracks</span><span style="font-family:Courier New;">):</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># This function chooses the single longest superpixel track to summarise the single cell motion.</span><br/><span style="font-family:Courier New;"> disps_tracks = tracks[:, </span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">:, :] - tracks[:, :</span><span style="font-family:Courier New;color:#B8D100;">-1</span><span style="font-family:Courier New;">, :]</span><br/><span style="font-family:Courier New;"> disps_mag = np.sum(np.sqrt(disps_tracks[:,:,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">]**</span><span style="font-family:Courier New;color:#B8D100;">2 </span><span style="font-family:Courier New;">+ disps_tracks[:,:,</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">]**</span><span style="font-family:Courier New;color:#B8D100;"></span><span style="font-family:Courier New;color:#B8D100;">2</span><span style="font-family:Courier New;">), </span><span style="font-family:Courier New;color:#00D5FF;">axis</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#99BB00;">1</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> rank = np.argsort(disps_mag)[::</span><span style="font-family:Courier New;color:#B8D100;">-1</span><span style="font-family:Courier New;">]</span><br/><br/><span style="font-family:Courier New;color:#EE33EE;">return</span><span style="font-family:Courier New;"> tracks[rank[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">]]</span><br/><br/><span style="font-family:Courier New;"> single_cell_tracks = []</span><br/><span style="font-family:Courier New;color:#60D978;"># iterate through each segmentation and store the single track</span><br/><span style="font-family:Courier New;color:#EE33EE;">for</span> <span style="font-family:Courier New;">i</span> <span style="font-family:Courier New;color:#337FE5;">in</span> <span style="font-family:Courier New;color:#FFE500;">range</span><span style="font-family:Courier New;">(</span><span style="font-family:Courier New;color:#FFE500;">len</span><span style="font-family:Courier New;">(cell_spixels)):</span><br/><span style="font-family:Courier New;color:#60D978;"># for cell i which superpixel ids belong capture it</span><br/><span style="font-family:Courier New;"> cell_spixel = cell_spixels[i]</span><br/><span style="font-family:Courier New;color:#60D978;"># for cell i retrieve the corresponding tracks </span><br/><span style="font-family:Courier New;"> cell_tracks = tracks_F[cell_spixel]</span><br/><span style="font-family:Courier New;color:#60D978;"># find the single track that summarise the motion of all associated superpixel tracks</span><br/><span style="font-family:Courier New;"> single_cell_track = find_characteristic_motion(cell_tracks)</span><br/><span style="font-family:Courier New;"> single_cell_tracks.append(single_cell_track[</span><span style="font-family:Courier New;color:#337FE5;">None</span><span style="font-family:Courier New;">,:])</span><br/><br/><span style="font-family:Courier New;"> single_cell_tracks = np.vstack(single_cell_tracks)</span><br/><br/></li><li>Visualize the inferred cell tracks, plotting each cell track with a unique color (Figure 9C).<br/><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Visualisation_Tools.track_plotting </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> plot_tracks</span><br/><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> seaborn </span><span style="font-family:Courier New;color:#EE33EE;">as</span><span style="font-family:Courier New;"> sns </span><br/><br/><span style="font-family:Courier New;"> cell_colors = sns.color_palette(</span><span style="font-family:Courier New;color:#E56600;">'Set1'</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#00D5FF;">n_colors</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#FFE500;">len</span><span style="font-family:Courier New;">(single_cell_tracks))</span><br/><br/><span style="font-family:Courier New;"> fig, ax = plt.subplots()</span><br/><span style="font-family:Courier New;"> plt.title(</span><span style="font-family:Courier New;color:#E56600;">'Single Cell Tracks'</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">fontsize</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">16</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax.imshow(vidstack[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">], </span><span style="font-family:Courier New;color:#00D5FF;">cmap</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'gray'</span><span style="font-family:Courier New;">)</span><br/><br/><span style="font-family:Courier New;color:#EE33EE;">for</span><span style="font-family:Courier New;"> ii </span><span style="font-family:Courier New;color:#337FE5;">in</span> <span style="font-family:Courier New;color:#FFE500;">range</span><span style="font-family:Courier New;">(</span><span style="font-family:Courier New;color:#FFE500;">len</span><span style="font-family:Courier New;">(single_cell_tracks)):</span><br/><span style="font-family:Courier New;"> single_cell_track = single_cell_tracks[ii]</span><br/><span style="font-family:Courier New;"> plot_tracks(single_cell_track[</span><span style="font-family:Courier New;color:#337FE5;">None</span><span style="font-family:Courier New;">,:], ax, </span><span style="font-family:Courier New;color:#00D5FF;">color</span><span style="font-family:Courier New;">=cell_colors[ii], </span><span style="font-family:Courier New;color:#00D5FF;">lw</span><span style="font-family:Courier New;">=3)</span><br/><br/><span style="font-family:Courier New;"> plt.grid(</span><span style="font-family:Courier New;color:#E56600;">'off'</span><span style="font-family:Courier New;">); plt.axis(</span><span style="font-family:Courier New;color:#E56600;">'off'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> plt.show()</span><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918201915_4242.jpg" width="417"/><br/><strong>Figure 9. Single-cell tracking using MOSES superpixel tracks.</strong> A. Extracted superpixel tracks using a target number of 1,000 superpixels overlaid on the first video frame. B. Automatically segmented cells from the initial frame. C. Predicted single cell tracks selecting the longest superpixel track for each segmented cell region.<br/><br/><p class="ppzz" style="margin-left:-30px;"><strong><em>Advanced analysis:</em></strong> </p></li><li>Compute the motion saliency map using the forward and backward tracks to visualize where the cells move to and from where (Figure 10). <br/><em>Note: Try changing the dist_thresh used to see how this affects the computed motion saliency map.<br/></em><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> compute_motion_saliency_map</span><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> skimage.filters </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> Gaussian</span><br/><br/><span style="font-family:Courier New;"> dist_thresh = </span><span style="font-family:Courier New;color:#B8D100;">30</span><br/><span style="font-family:Courier New;"> spixel_size = tracks_B[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">]-tracks_B[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">]</span><br/><br/><span style="font-family:Courier New;"> saliency_F, saliency_spatial_time_F = compute_motion_saliency_map(tracks_F, </span><span style="font-family:Courier New;color:#00D5FF;">dist_thresh</span><span style="font-family:Courier New;">=dist_thresh, </span><span style="font-family:Courier New;color:#00D5FF;">shape</span><span style="font-family:Courier New;">=frame0.shape, </span><span style="font-family:Courier New;color:#00D5FF;">max_frame</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#337FE5;">None</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">filt</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">filt_size</span><span style="font-family:Courier New;">=spixel_size)</span><br/><span style="font-family:Courier New;"> saliency_B, saliency_spatial_time_B = compute_motion_saliency_map(tracks_B, </span><span style="font-family:Courier New;color:#00D5FF;">dist_thresh</span><span style="font-family:Courier New;">=dist_thresh, </span><span style="font-family:Courier New;color:#00D5FF;">shape</span><span style="font-family:Courier New;">=frame0.shape, </span><span style="font-family:Courier New;color:#00D5FF;">max_frame</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#337FE5;">None</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">filt</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">filt_size</span><span style="font-family:Courier New;">=spixel_size)</span><br/><span style="font-family:Courier New;color:#60D978;"># Use Gaussian smoothing to create a more continuous heatmap</span><br/><span style="font-family:Courier New;"> saliency_F_smooth = gaussian(saliency_F, spixel_size/2)</span><br/><span style="font-family:Courier New;"> saliency_B_smooth = gaussian(saliency_B, spixel_size/2)</span><br/><br/><span style="font-family:Courier New;"> fig, ax = plt.subplots(</span><span style="font-family:Courier New;color:#00D5FF;">nrows</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">ncols</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">3</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">figsize</span><span style="font-family:Courier New;">=(</span><span style="font-family:Courier New;color:#B8D100;">15</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#B8D100;">15</span><span style="font-family:Courier New;">))</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#99BB00;">0</span><span style="font-family:Courier New;">].set_title(</span><span style="font-family:Courier New;color:#E56600;">'Superpixel Tracks'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">].imshow(frame0, </span><span style="font-family:Courier New;color:#00D5FF;">cmap</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'gray'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> plot_tracks(tracks_F, </span><span style="font-family:Courier New;color:#00D5FF;">ax</span><span style="font-family:Courier New;">=ax[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">], </span><span style="font-family:Courier New;color:#00D5FF;">color</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'r'</span><span style="font-family:Courier New;">); ax[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">].axis(</span><span style="font-family:Courier New;color:#E56600;">'off'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].set_title(</span><span style="font-family:Courier New;color:#E56600;">'Motion Saliency (Forward)'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].imshow(vidstack[</span><span style="font-family:Courier New;color:#B8D100;">-1</span><span style="font-family:Courier New;">], </span><span style="font-family:Courier New;color:#00D5FF;">cmap</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'gray'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].imshow(saliency_F_smooth, </span><span style="font-family:Courier New;color:#00D5FF;">cmap</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'coolwarm'</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">alpha</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">0.7</span><span style="font-family:Courier New;">); ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].axis(</span><span style="font-family:Courier New;color:#E56600;">'off'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">2</span><span style="font-family:Courier New;">].set_title(</span><span style="font-family:Courier New;color:#E56600;">'Motion Saliency (Backward)'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">2</span><span style="font-family:Courier New;">].imshow(frame0, </span><span style="font-family:Courier New;color:#00D5FF;">cmap</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'gray'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">2</span><span style="font-family:Courier New;">].imshow(saliency_B_smooth, </span><span style="font-family:Courier New;color:#00D5FF;">cmap</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'coolwarm'</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">alpha</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">0.7</span><span style="font-family:Courier New;">); ax[</span><span style="font-family:Courier New;color:#B8D100;">2</span><span style="font-family:Courier New;">].axis(</span><span style="font-family:Courier New;color:#E56600;">'off'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> plt.show()</span><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918202003_1669.jpg" width="411"/><br/><strong>Figure 10. Motion saliency maps computed using forward and backward tracks visually uncover motion sinks and sources respectively in cellular videos.</strong> A. Extracted forward superpixel tracks using a target number of 1,000 superpixels overlaid on the first video frame. B. Forward motion saliency map computed using the forward tracks on the left reveals motion highlights the highly dynamic movement of individual cell boundaries which behave akin to motion âsinksâ. C. Backward motion saliency map computed using the backward tracks produced tracking the video in reverse reveals motion origin or âsourcesâ. </li></ol><br/><p class="ppzz"><strong>Analysis 2: Two Cell Epithelial Sheet Analysis</strong> (Fluorescence Microscopy) (<a href="https://os.bio-protocol.org/attached/file/20190616/Supplementary Script Files.zip" target="_blank">Supplementary files</a>) The main analysis steps for the migration pattern of two color epithelial sheets acquired as presented in our previous work (Zhou <em>et al.</em>, 2019) were documented in the main protocol section. Here we present extended procedures more specifically targeted for the analysis of two-color epithelial sheets.</p><ol class="npwone"><li>Analysis of the interface between two cell populations<ol class="npwtwo"><li>Visualize the interface appearance using video kymographs. A kymograph is a projection of the 2D temporal dataset that collapses one of the spatial dimensions to allow the movement to be visualized as an image. Here the maximum along of each image pixel column was taken to summarise the motion along the image rows (Figure 11). The maximum was used to get the strongest possible signal for the interface. <br/><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Visualisation_Tools.kymographs</span><span style="font-family:Courier New;color:#EE33EE;"> import</span><span style="font-family:Courier New;"> kymograph_img</span><br/><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> numpy </span><span style="font-family:Courier New;color:#EE33EE;">as</span><span style="font-family:Courier New;"> np </span><br/><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> pylab </span><span style="font-family:Courier New;color:#EE33EE;">as</span><span style="font-family:Courier New;"> plt </span><br/><br/><span style="font-family:Courier New;color:#60D978;"># project and collapse in the 'y' direction (rows)</span><br/><span style="font-family:Courier New;"> vid_max_slice = kymograph_img(vidstack, </span><span style="font-family:Courier New;color:#00D5FF;">axis</span><span style="font-family:Courier New;">=1, </span><span style="font-family:Courier New;color:#00D5FF;">proj_fn</span><span style="font-family:Courier New;">=np.max)</span><br/><br/><span style="font-family:Courier New;"> fig, ax = plt.subplots()</span><br/><span style="font-family:Courier New;"> ax.imshow(vid_max_slice)</span><br/><span style="font-family:Courier New;"> ax.set_aspect(</span><span style="font-family:Courier New;color:#E56600;">'auto'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> plt.show()</span><br/><br/></li><li>Visualize the interface movement between the two cell populations using velocity kymographs. Analogous to video kymographs above, velocity kymographs compress the 2D temporal motion field in one dimension to visualize the information as a single image. Here we take the median <em>x</em>-direction velocity value along each image pixel column to summarize the velocity variation across the rows. The median was used for projecting the information as it is an average statistic that is well-known to be robust to outlier values. MOSES provides two functions to compute the velocity kymograph depending on whether the input is a motion field or motion tracks.<ol class="npwthree"><li>Compute the velocity kymograph of the pixel motion field (Figure 12A). <br/><br/><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> scipy.io </span><span style="font-family:Courier New;color:#EE33EE;">as</span><span style="font-family:Courier New;"> spio</span><br/><span style="font-family:Courier New;color:#60D978;"># load the previously computed motion field</span><br/><span style="font-family:Courier New;"> save_optflow_mat = (</span><span style="font-family:Courier New;color:#E56600;">'optflow_'</span><span style="font-family:Courier New;">+fname).replace(</span><span style="font-family:Courier New;color:#E56600;">'.tif'</span><span style="font-family:Courier New;color:#E56600;"><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#E56600;">'</span></span><span style="font-family:Courier New;color:#E56600;">.mat'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> optflow_r = spio.loadmat(save_optflow_mat)[</span><span style="font-family:Courier New;color:#E56600;">'optflow_r'</span><span style="font-family:Courier New;">]</span><br/><span style="font-family:Courier New;"> optflow_g = spio.loadmat(save_optflow_mat)[</span><span style="font-family:Courier New;color:#E56600;">'optflow_g'</span><span style="font-family:Courier New;">]</span><br/><span style="font-family:Courier New;color:#60D978;"># construct the full motion field</span><br/><span style="font-family:Courier New;"> optflow = optflow_r + optflow_g</span><br/><span style="font-family:Courier New;color:#60D978;"># take only the 'x' component</span><br/><span style="font-family:Courier New;"> optflow_x = optflow[...,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">]</span><br/><br/><span style="font-family:Courier New;color:#60D978;"># kymograph 1: Dense optical flow. </span><br/><span style="font-family:Courier New;"> optflow_median_slice = kymograph_img(optflow_x, </span><span style="font-family:Courier New;color:#00D5FF;">axis</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">proj_fn</span><span style="font-family:Courier New;">=np.nanmedian)</span><br/><br/></li><li>Compute the velocity kymograph of the superpixel tracks following tracking of a fixed number of superpixels, here 1,000 superpixels, (Figure 12B). <br/><br/><span style="font-family:Courier New;color:#EE33EE;">from</span><span style="font-family:Courier New;"> MOSES.Visualisation_Tools.kymographs </span><span style="font-family:Courier New;color:#EE33EE;">import</span><span style="font-family:Courier New;"> construct_spatial_time_MOSES_velocity_x</span><br/><span style="font-family:Courier New;color:#60D978;"># load the previously computed superpixel tracks</span><br/><span style="font-family:Courier New;"> savetracksmat = (</span><span style="font-family:Courier New;color:#E56600;">'meantracks_'</span><span style="font-family:Courier New;">+fname).replace(</span><span style="font-family:Courier New;color:#E56600;">'.tif'</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#E56600;">'.mat'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> meantracks_r = spio.loadmat(savetracksmat)[</span><span style="font-family:Courier New;color:#E56600;">'meantracks_r'</span><span style="font-family:Courier New;">]</span><br/><span style="font-family:Courier New;"> meantracks_g = spio.loadmat(savetracksmat)[</span><span style="font-family:Courier New;color:#E56600;">'meantracks_g'</span><span style="font-family:Courier New;">]</span><br/><span style="font-family:Courier New;color:#60D978;"># kymograph 2: Superpixel tracks. (fixed superpixel number)</span><br/><span style="font-family:Courier New;"> velocity_kymograph_x_tracks_r = construct_spatial_time_MOSES_velocity_x(meantracks_r, </span><span style="font-family:Courier New;color:#00D5FF;">shape</span><span style="font-family:Courier New;">=(n_frame, n_cols), </span><span style="font-family:Courier New;color:#00D5FF;">n_samples</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">51</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">axis</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> velocity_kymograph_x_tracks_g = construct_spatial_time_MOSES_velocity_x(meantracks_g, </span><span style="font-family:Courier New;color:#00D5FF;">shape</span><span style="font-family:Courier New;">=(n_frame, n_cols), </span><span style="font-family:Courier New;color:#00D5FF;">n_samples</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">51</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">axis</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> velocity_kymograph_x_tracks = velocity_kymograph_x_tracks_r + velocity_kymograph_x_tracks_g</span><br/><br/></li><li>(Optional) Compute the velocity kymograph using the superpixel tracks extracted by dense superpixel tracking, (Figure 12C). Starting from an initial user-specified number of <em>N</em> superpixels, dense tracking continuously monitors the spatial density of superpixels frame to frame. The image area is regularly partitioned into <em>N</em> region of interests (ROI). If an ROI contains a number of superpixels less than the minimum number specified by the mindensity parameter, a new superpixel is dynamically added to the ROI and tracked in all subsequent frames. As such starting from <em>N=1000</em> superpixels, the final number of superpixel tracks is variable. It could be 2,000 for videos with relatively little movement or even 6,000 for significant movement. <br/><em>Note: Dense superpixel tracking is the preferred tracking approach when one expects the video to contain significant movement and is set by specifying dense=True.<br/></em><br/><span style="font-family:Courier New;color:#60D978;"># compute dense tracks by setting dense=True (default is False)</span><br/><span style="font-family:Courier New;"> _, meantracks_r_dense = compute_grayscale_vid_superpixel_tracks(vidstack[:,:,:,</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">], optical_flow_params, n_spixels, </span><span style="font-family:Courier New;color:#00D5FF;">dense</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#337FE5;">True</span><span style="font-family:Courier New;">, <span style="color:#00D5FF;">mindensity</span>=<span style="color:#B8D100;">1</span>)</span><br/><span style="font-family:Courier New;"> _, meantracks_g_dense = compute_grayscale_vid_superpixel_tracks(vidstack[:,:,:,</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">], optical_flow_params, n_spixels, </span><span style="font-family:Courier New;color:#00D5FF;">dense</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#337FE5;">True</span><span style="font-family:Courier New;">, <span style="color:#00D5FF;">mindensity</span>=<span style="color:#B8D100;">1</span>)</span><br/><span style="font-family:Courier New;color:#60D978;"># save the computed tracks</span><br/><span style="font-family:Courier New;"> savetracksmat = (</span><span style="font-family:Courier New;color:#E56600;">'meantracks-dense_'</span><span style="font-family:Courier New;">+fname).replace(</span><span style="font-family:Courier New;color:#E56600;">'.tif'</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#E56600;">'.mat'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> spio.savemat(savetracksmat, {</span><span style="font-family:Courier New;color:#E56600;">'meantracks_r'</span><span style="font-family:Courier New;">:meantracks_r_dense, </span><br/><span style="font-family:Courier New;color:#E56600;">'meantracks_g'</span><span style="font-family:Courier New;">:meantracks_g_dense})</span><br/><span style="font-family:Courier New;color:#60D978;"># kymograph 3: using dense superpixel tracking.</span> <br/><span style="font-family:Courier New;"> velocity_kymograph_x_tracks_r_dense = construct_spatial_time_MOSES_velocity_x(meantracks_r_dense, </span><span style="font-family:Courier New;color:#00D5FF;">shape</span><span style="font-family:Courier New;">=(n_rows, n_cols), </span><span style="font-family:Courier New;color:#00D5FF;">n_samples</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">51</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">axis</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> velocity_kymograph_x_tracks_g_dense = construct_spatial_time_MOSES_velocity_x(meantracks_g_dense, </span><span style="font-family:Courier New;color:#00D5FF;">shape</span><span style="font-family:Courier New;">=(n_rows, n_cols), </span><span style="font-family:Courier New;color:#00D5FF;">n_samples</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">51</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">axis</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> velocity_kymograph_x_tracks_dense = velocity_kymograph_x_tracks_r_dense + velocity_kymograph_x_tracks_g_dense</span><br/><br/></li><li>Visualize the velocity kymographs to compare the differences between the velocity kymographs computed from the three different inputs in a)-c) above (Figure 12). <br/><br/><span style="font-family:Courier New;">fig, ax = plt.subplots(</span><span style="font-family:Courier New;color:#00D5FF;">nrows</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">ncols</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">3</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">figsize</span><span style="font-family:Courier New;">=(</span><span style="font-family:Courier New;color:#B8D100;">15</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#B8D100;">5</span><span style="font-family:Courier New;">))</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">].set_title(</span><span style="font-family:Courier New;color:#E56600;">'Motion Field'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[0].imshow(optflow_median_slice, </span><span style="font-family:Courier New;color:#00D5FF;">cmap</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'RdBu_r'</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">vmin</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">-10</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">vmax</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">10</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">].axis(</span><span style="font-family:Courier New;color:#E56600;">'off'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">0</span><span style="font-family:Courier New;">].set_aspect(</span><span style="font-family:Courier New;color:#E56600;">'auto'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].set_title(</span><span style="font-family:Courier New;color:#E56600;">'1000 Superpixels (fixed)'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].imshow(velocity_kymograph_x_tracks, </span><span style="font-family:Courier New;color:#00D5FF;">cmap</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'RdBu_r'</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">vmin</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">-10</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#00D5FF;"> vmax</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">10</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].axis(</span><span style="font-family:Courier New;color:#E56600;">'off'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">1</span><span style="font-family:Courier New;">].set_aspect(</span><span style="font-family:Courier New;color:#E56600;">'auto'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">2</span><span style="font-family:Courier New;">].set_title(</span><span style="font-family:Courier New;color:#E56600;">'1000 Superpixels (dynamic)'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">2</span><span style="font-family:Courier New;">].imshow(velocity_kymograph_x_tracks_dense, </span><span style="font-family:Courier New;color:#00D5FF;">cmap</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#E56600;">'RdBu_r'</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">vmin</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">-10</span><span style="font-family:Courier New;">, </span><span style="font-family:Courier New;color:#00D5FF;">vmax</span><span style="font-family:Courier New;">=</span><span style="font-family:Courier New;color:#B8D100;">10</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">2</span><span style="font-family:Courier New;">].axis(</span><span style="font-family:Courier New;color:#E56600;">'off'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> ax[</span><span style="font-family:Courier New;color:#B8D100;">2</span><span style="font-family:Courier New;">].set_aspect(</span><span style="font-family:Courier New;color:#E56600;">'auto'</span><span style="font-family:Courier New;">)</span><br/><span style="font-family:Courier New;"> plt.show()</span><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918202208_7944.jpg" width="148"/><br/><strong>Figure 11. Kymograph of the video highlighting movement of the wound through time.</strong> The spatial row dimension of the 2D video was collapsed by using the maximum intensity along each pixel column. <br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918202233_2669.jpg" width="314"/><br/><strong>Figure 12. Velocity kymographs summarising the velocity with distance away from the interface. </strong>The velocity kymograph computed taking the median of column values of the pixel motion field (A), the superpixel tracks from tracking a fixed number of 1,000 superpixels (B) and when dense superpixel tracking is used (C).<br/><br/></li></ol></li><li>Locate the interface boundary line frame to frame using the extracted superpixel tracks and subsequently fit the line to a spline approximation to enable interpolation from the image y-coordinates (Figure 13).<br/><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from </span><span style="font-family:Courier New;">MOSES.Motion_Analysis.wound_statistics_tools </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> boundary_superpixel_meantracks_RGB</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><span style="font-family:Courier New;">boundary_curves, curves_lines, curve_img,boundary_line = boundary_superpixel_meantracks_RGB(vidstack, meantracks_r,meantracks_g, <span style="font-family:Courier New;color:#00B0F0;">movement_thresh</span>=<span style="font-family:Courier New;color:#CAC636;">0.2</span>, <span style="font-family:Courier New;color:#00B0F0;">t_av_motion</span>=<span style="font-family:Courier New;color:#CAC636;">5</span>, <span style="font-family:Courier New;color:#00B0F0;">robust</span>=<span style="font-family:Courier New;color:#0070C0;">False</span>, <span style="font-family:Courier New;color:#00B0F0;">lenient</span>=<span style="font-family:Courier New;color:#0070C0;">False</span>, <span style="font-family:Courier New;color:#00B0F0;">debug_visual</span>=<span style="font-family:Courier New;color:#0070C0;">False</span>, <span style="font-family:Courier New;color:#00B0F0;">max_dist</span>=<span style="font-family:Courier New;color:#CAC636;">1.5</span>, <span style="font-family:Courier New;color:#00B0F0;">y_bins</span>=<span style="font-family:Courier New;color:#CAC636;">50</span>, <span style="font-family:Courier New;color:#00B0F0;">y_frac_thresh</span>=<span style="font-family:Courier New;color:#CAC636;">0.50</span>)</span><br/><br/></li><li>Estimate the frame of gap closure by computing the distance between the boundary between both colored sheets from image segmentation. For the example you should get wound_closure_frame = 26 (Figure 14A). <br/><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from </span><span style="font-family:Courier New;">MOSES.Motion_Analysis.wound_close_sweepline_area_segmentation </span><span style="font-family:Courier New;color:#CC00CC;">import </span><span style="font-family:Courier New;">wound_sweep_area_segmentation</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">wound_closure_frame =wound_sweep_area_segmentation(vidstack, spixel_size, <span style="font-family:Courier New;color:#00B0F0;">max_frame</span>=<span style="font-family:Courier New;color:#CAC636;">50</span>, <span style="font-family:Courier New;color:#00B0F0;">n_sweeps</span>=<span style="font-family:Courier New;color:#CAC636;">50</span>, <span style="font-family:Courier New;color:#00B0F0;">n_points_keep</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>, <span style="font-family:Courier New;color:#00B0F0;">n_clusters</span>=<span style="font-family:Courier New;color:#CAC636;">2</span>, <span style="font-family:Courier New;color:#00B0F0;">p_als</span>=<span style="font-family:Courier New;color:#CAC636;">0.001</span>, <span style="font-family:Courier New;color:#00B0F0;">to_plot</span>=<span style="font-family:Courier New;color:#0070C0;">True</span>)</span> </p><span style="font-family:Courier New;color:#EDE813;">print</span><span style="font-family:Courier New;">(</span><span style="font-family:Courier New;color:#E36C0A;">'predictedgap closure frame is:</span><span style="font-family:Courier New;"> <span style='font-family:"color:#337FE5;'>%d</span><span style="font-family:Courier New;color:#E36C0A;">'</span> %(wound_closure_frame))</span><br/><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918202312_5280.jpg" width="285"/><br/><strong>Figure 13. Tracking the interface automatically using the superpixel tracks.</strong> A. Fitted cubic spline approximation of the interface boundary plotted on the last video frame (96 h). B. Maximum intensity projection of the tracked interface boundary plotted on the video kymograph.<br/><br/></li></ol></li><li>Interaction analysis<ol class="npwtwo"><li>Compute the maximum velocity cross-correlation index between red and green superpixel tracks as evidence of correlated motion of the two sheets. This measure ranges from 0 to 1 with 1 being completely correlated. For the example video, you should get a maximum velocity cross-correlation before and after gap closure of 0.022 and 0.234 suggesting increased correlation <br/>between the movement directionality of both sheets.<br/><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools</span><span style="font-family:Courier New;color:#CC00CC;"> import </span><span style="font-family:Courier New;">compute_max_vccf_cells_before_after_gap</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">(max_vccf_before, _), (max_vccf_after, _) =compute_max_vccf_cells_before_after_gap(meantracks_r, meantracks_g, <span style="font-family:Courier New;color:#00B0F0;">wound_heal_frame</span>=wound_closure_frame, <span style="font-family:Courier New;color:#00B0F0;">err_frame</span>=<span style="font-family:Courier New;color:#CAC636;">5</span>)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#EDE813;">print</span><span style="font-family:Courier New;">(<span style="font-family:Courier New;color:#E36C0A;">'max velocitycross-correlation before:</span><span style="font-family:Courier New;color:#0070C0;"> %.3f</span><span style="font-family:Courier New;color:#E36C0A;">'</span> %(max_vccf_before))</span> </p><span style="font-family:Courier New;color:#EDE813;">print</span><span style="font-family:Courier New;">(<span style="font-family:Courier New;color:#E36C0A;">'max velocitycross-correlation after:</span><span style="font-family:Courier New;color:#0070C0;"> %.3f</span><span style="font-family:Courier New;color:#E36C0A;">'</span> %(max_vccf_after))</span><br/><br/></li><li>Compute the spatial correlation index to assess on average the extent of movement correlation between superpixel tracks and by extension cellular groups in the image. Distance is measured in normalized units as the number of superpixels away. For our video, compute the spatial correlation over a distance range of 1-6 superpixels and fit an exponential decay curve with equation, <em>y=ae<sup>-xâb</sup></em> to extract the canonical distance, <em>b=2.94</em> over which motion is correlated (Figure 14B). <br/><em>Note: The computation of spatial correlation index is typically slow. Use a smaller distance range to speed up computation.</em> <br/><br/><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> compute_spatial_correlation_function<br/><br/></span> </p><p class="MsoListParagraph" style="text-indent:20.0pt;"><span style="font-family:Courier New;"></span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">spatial_corr_curve,(spatial_corr_pred, a_value, b_value, r_value) =compute_spatial_correlation_function(meantracks_r, wound_closure_frame, <span style="font-family:Courier New;color:#00B0F0;">wound_heal_err</span>=<span style="font-family:Courier New;color:#CAC636;">5</span>, <span style="font-family:Courier New;color:#00B0F0;">dist_range</span>=np.arange(<span style="font-family:Courier New;color:#CAC636;">1</span>,<span style="font-family:Courier New;color:#CAC636;">6</span>,<span style="font-family:Courier New;color:#CAC636;">1</span>))</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;"></span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># plot thecurve and the fitted curve to y=a*exp(-x/b) to get the (a,b) parameters.</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">plt.figure()</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">plt.title(</span><span style="font-family:Courier New;color:#E36C0A;">'Fitted Spatial Correlation: a=</span><span style="font-family:Courier New;color:#0070C0;">%.3f</span><span style="font-family:Courier New;color:#E36C0A;">, b=</span><span style="font-family:Courier New;color:#0070C0;">%.3f</span><span style="font-family:Courier New;color:#E36C0A;">'</span><span style="font-family:Courier New;"> %(a_value, b_value))</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">plt.plot(np.arange(<span style="font-family:Courier New;color:#CAC636;">1</span>,<span style="font-family:Courier New;color:#CAC636;">6</span><span style="font-family:Courier New;color:black;">,</span><span style="font-family:Courier New;color:#CAC636;">1</span>),spatial_corr_curve, </span><span style="font-family:Courier New;color:#E36C0A;">'ko'</span><span style="font-family:Courier New;">, <span style="font-family:Courier New;color:#00B0F0;">label</span>=</span><span style="font-family:Courier New;color:#E36C0A;">'measured'</span><span style="font-family:Courier New;">)</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">plt.plot(np.arange(<span style="font-family:Courier New;color:#CAC636;">1</span>,<span style="font-family:Courier New;color:#CAC636;">6</span>,<span style="font-family:Courier New;color:#CAC636;">1</span>), spatial_corr_pred, </span><span style="font-family:Courier New;color:#E36C0A;">'g-'</span><span style="font-family:Courier New;">, <span style="font-family:Courier New;color:#00B0F0;">label</span>=</span><span style="font-family:Courier New;color:#E36C0A;">'fitted'</span><span style="font-family:Courier New;">)</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">plt.xlabel(</span><span style="font-family:Courier New;color:#E36C0A;">'Distance (Number of Superpixels)'</span><span style="font-family:Courier New;">)</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">plt.ylabel(</span><span style="font-family:Courier New;color:#E36C0A;">'Spatial Correlation'</span><span style="font-family:Courier New;">)</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">plt.legend(<span style="font-family:Courier New;color:#00B0F0;">loc</span>=</span><span style="font-family:Courier New;color:#E36C0A;">'best'</span><span style="font-family:Courier New;">)</span> </p><p class="MsoListParagraph" style="text-indent:0cm;"><span style="font-family:Courier New;">plt.show()<br/></span> </p><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918202353_0068.jpg" width="271"/><br/><strong>Figure 14. Example distance curve for estimating the frame of gap closure and example spatial correlation curve for estimating the distance over which cellular motion is correlated.</strong> A. Plot of the separation distance normalized by the maximum separation distance between red and green boundary points as extracted by image segmentation. Blue triangle is the final predicted gap closure frame. B. Variation of mean spatial correlation between superpixel tracks for the example video as a function of the number of superpixels away as measured by multiples of the average superpixel width. Green line is the fitted exponential decay to the black data points.<br/><br/></li></ol></li><li>Motion maps<br/>One of the primary benefits of using the superpixel tracks and meshes extracted by MOSES as discussed in our previous work (Zhou <em>et al.</em>, 2019) was for the construction of a motion map that can be used to visually interrogate motion phenotypes. Here we describe the steps we used in the paper to construct a motion map by applying principal components analysis (PCA) to the MOSES mesh strain curve using a smaller dataset. The full datasets are available through Mendeley Datasets with DOI: <a href="https://dx.doi.org/10.17632/j8yrmntc7x.1" target="_blank">https://dx.doi.org/10.17632/j8yrmntc7x.1</a> and <a href="https://dx.doi.org/10.17632/vrhtsdhprr.1" target="_blank">https://dx.doi.org/10.17632/vrhtsdhprr.1</a>.<ol class="npwtwo"><li>Download all videos from the two folders, 0% FBS and 5% FBS folders in <a href="https://drive.google.com/drive/folders/0BwFVL6r9ww5BaTh6NExLR1JMUXM" target="_blank">the Google drive</a> (6 videos in total). They contain 3 examples each of the 0% and 5% serum cultured cell videos without EGF addition.</li><li>Place the downloaded videos into two subfolders, 0%_FBS and 5%_FBS under a newly created top level âMotion_Map_Videosâ folder following the structure in Figure 1 as before.</li><li>Automatically detect the two subfolders in the âMotion_Map_Videosâ folder as two separate experiment folders. The code should print a Python list with the values ['0%_FBS' '5%_FBS'].<br/><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Utility_Functions.file_io </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> detect_experiments</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># detect experimentfolders as subfolders under a top-level directory.</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">rootfolder = </span><span style="font-family:Courier New;color:#E36C0A;">'../Data/Motion_Map_Videos'</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">expt_folders =detect_experiments(rootfolder, <span style="font-family:Courier New;color:#00B0F0;">exclude</span>=[</span><span style="font-family:Courier New;color:#E36C0A;">'meantracks'</span><span style="font-family:Courier New;">,</span><span style="font-family:Courier New;color:#E36C0A;">'optflow'</span><span style="font-family:Courier New;">], <span style="font-family:Courier New;color:#00B0F0;">level1</span>=<span style="font-family:Courier New;color:#0070C0;">False</span>)</span> </p><span style="font-family:Courier New;">print(expt_folders) <span style="font-family:Courier New;color:#92D050;">#print the detected folder names.</span></span><br/><br/></li><li>Use the in-built Python glob library to detect all video files using their â.tifâ extension in each experiment (subfolder), loading individual file paths into a single NumPy array. Subsequently create a separate integer array based on the detected files to denote if the video file came from either the â0%_FBSâ or â5%_FBSâ subfolder assigned integers â0â and â1â respectively.<br/><br/><p class="MsoListParagraph" style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> glob</span> </p><p class="MsoListParagraph" style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> numpy </span><span style="font-family:Courier New;color:#CC00CC;">as</span><span style="font-family:Courier New;"> np </span> </p><p class="MsoListParagraph" style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># detecteach .tif file in each folder.</span><span> </span> </p><p class="MsoListParagraph" style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;"> videofiles =[glob.glob(os.path.join(rootfolder, expt_folder,</span><span style="font-family:Courier New;color:#E36C0A;">'*.tif'</span><span style="font-family:Courier New;">)) </span><span style="font-family:Courier New;color:#CC00CC;">for </span><span><span style="font-family:Courier New;">expt_folder</span> <span style="font-family:Courier New;color:#0070C0;">in</span><span style="font-family:Courier New;"> expt_folders]</span></span> </p><p class="MsoListParagraph" style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># shouldgive now [[0,0,0],[1,1,1]]</span><span></span> </p><p class="MsoListParagraph" style="text-align:justify;text-indent:0cm;"><span><span style="font-family:Courier New;">labels = [[i]*</span><span style="font-family:Courier New;color:#EDE813;">len</span>(<span style="font-family:Courier New;">videofiles[i]</span>) </span><span style="font-family:Courier New;color:#CC00CC;">for </span><span>i <span style="font-family:Courier New;color:#0070C0;">in</span> <span style="font-family:Courier New;color:#EDE813;">range</span>(<span style="font-family:Courier New;color:#EDE813;">len</span><span style="font-family:Courier New;">(videofiles))</span>]<span>  </span></span> </p><p class="MsoListParagraph" style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># flatteneverything into single array</span><span></span> </p><p class="MsoListParagraph" style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">videofiles =np.hstack(videofiles)</span> </p><p class="MsoListParagraph" style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">labels =np.hstack(labels)</span><span style="font-family:Courier New;"> </span> </p></li><br/><li>Extract superpixel tracks and compute the MOSES mesh strain curves for each video. Then concatenate the mesh strain curves of each video into one NumPy array. This constructs a feature matrix of size <em>n<sub>samples</sub>Ãd<sub>features</sub></em> required for PCA. <br/><em>Note: Augment the MOSES mesh strain curve features with image-based features such as the mean pixel intensity and texture features of the superpixel image patch to additionally describe appearance.<br/></em><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Utility_Functions.file_io </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> read_multiimg_PIL</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#CC00CC;">import </span><span style="font-family:Courier New;">construct_MOSES_mesh, compute_MOSES_mesh_strain_curve</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># set motion extractionparameters.</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">n_spixels = <span style="font-family:Courier New;color:#CAC636;">1000</span></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">optical_flow_params = <span style="font-family:Courier New;color:#00B050;">dict</span>(<span style="font-family:Courier New;color:#00B0F0;">pyr_scale</span>=<span style="font-family:Courier New;color:#CAC636;">0.5</span>, <span style="font-family:Courier New;color:#00B0F0;">levels</span>=<span style="font-family:Courier New;color:#CAC636;">3</span>, <span style="font-family:Courier New;color:#00B0F0;">winsize</span>=<span style="font-family:Courier New;color:#CAC636;">15</span>, <span style="font-family:Courier New;color:#00B0F0;">iterations</span>=<span style="font-family:Courier New;color:#CAC636;">3</span>, <span style="font-family:Courier New;color:#00B0F0;">poly_n</span>=<span style="font-family:Courier New;color:#CAC636;">5</span>, <span style="font-family:Courier New;color:#00B0F0;">poly_sigma</span>=<span style="font-family:Courier New;color:#CAC636;">1.2</span>, <span style="font-family:Courier New;color:#00B0F0;">flags</span>=<span style="font-family:Courier New;color:#CAC636;">0</span>)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">n_videos = <span style="font-family:Courier New;color:#EDE813;">len</span>(videofiles)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># initialise arrays tosave computed data</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">mesh_strain_all = []</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">for </span><span style="font-family:Courier New;">ii <span style="font-family:Courier New;color:#0070C0;">in</span> <span style="font-family:Courier New;color:#EDE813;">range</span>(n_videos):</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">videofile = videofiles[ii]</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#EDE813;">print</span><span style="font-family:Courier New;">(ii, videofile)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">vidstack =read_multiimg_PIL(videofile)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#92D050;"># 1. compute superpixeltracks</span><span style="font-family:Courier New;"> </span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">_, meantracks_r =<span>  </span>compute_grayscale_vid_superpixel_tracks(vidstack[:,:,:,0],optical_flow_params, n_spixels)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">_, meantracks_g =<span>  </span>compute_grayscale_vid_superpixel_tracks(vidstack[:,:,:,1],optical_flow_params, n_spixels)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">spixel_size = meantracks_r[<span style="font-family:Courier New;color:#CAC636;">1</span>,<span style="font-family:Courier New;color:#CAC636;">0</span>,<span style="font-family:Courier New;color:#CAC636;">1</span>] - meantracks_r[<span style="font-family:Courier New;color:#CAC636;">1</span>,<span style="font-family:Courier New;color:#CAC636;">0</span>,<span style="font-family:Courier New;color:#CAC636;">0</span>]</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#92D050;"># 2a. compute MOSESmesh.</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">MOSES_mesh_strain_time_r,MOSES_mesh_neighborlist_r = construct_MOSES_mesh(meantracks_r, <span style="font-family:Courier New;color:#00B0F0;">dist_thresh</span>=<span style="font-family:Courier New;color:#CAC636;">1.2</span>, <span style="font-family:Courier New;color:#00B0F0;">spixel_size</span>=spixel_size)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">MOSES_mesh_strain_time_g, MOSES_mesh_neighborlist_g= construct_MOSES_mesh(meantracks_g, <span style="font-family:Courier New;color:#00B0F0;">dist_thresh</span>=<span style="font-family:Courier New;color:#CAC636;">1.2</span>, <span style="font-family:Courier New;color:#00B0F0;">spixel_size</span>=spixel_size)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#92D050;"># 2b. compute the MOSESmesh strain curve for the video.</span><span style="font-family:Courier New;"> </span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">mesh_strain_r =compute_MOSES_mesh_strain_curve(MOSES_mesh_strain_time_r, <span style="font-family:Courier New;color:#00B0F0;">normalise</span>=<span style="font-family:Courier New;color:#0070C0;">False</span>)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">mesh_strain_g =compute_MOSES_mesh_strain_curve(MOSES_mesh_strain_time_g, <span style="font-family:Courier New;color:#00B0F0;">normalise</span>=<span style="font-family:Courier New;color:#0070C0;">False</span>)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">mesh_strain_curve_video =.5*(mesh_strain_r+mesh_strain_g)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#92D050;"># (optionalnormalization)</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">normalised_mesh_strain_curve_video =mesh_strain_curve_video/ np.max(mesh_strain_curve_video)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#92D050;"># 3. append the computedmesh strain curves.</span><span style="font-family:Courier New;"> </span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">mesh_strain_all.append(normalised_mesh_strain_curve_video)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;"> </span> </p><p style="margin-left:0cm;text-indent:-.5pt;"><span style="font-family:Courier New;"><span>      </span><span style="font-family:Courier New;color:#92D050;"><span> </span># stack all the mesh strain curves into one</span></span> </p><span style="font-family:Courier New;">mesh_strain_all = np.vstack(mesh_strain_all)</span><br/><br/></li><li>Apply PCA to the mesh strain curves of the 5% FBS videos only to set the two principal components for mapping. <br/><em>Note: 0% serum videos could also have been used. Generally to learn the data variation it is recommended to use the larger dataset.<br/></em><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> sklearn.decomposition </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> PCA</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># initialise the PCAmodel</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">pca_model = PCA(<span style="font-family:Courier New;color:#00B0F0;">n_components</span>=<span style="font-family:Courier New;color:#CAC636;">2</span>, <span style="font-family:Courier New;color:#00B0F0;">random_state</span>=<span style="font-family:Courier New;color:#CAC636;">0</span>)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># 1. learn the PCA usingonly the 5% FBS a.k.a label=1</span><span style="font-family:Courier New;"></span> </p><span style="font-family:Courier New;">pca_5_percent_mesh =pca_model.fit_transform(mesh_strain_all[labels==1])</span><br/><br/></li><li>Project the mesh strain curves of the 0% FBS videos using the principal components defined by the 5% FBS videos.<br/><br/><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">pca_0_percent_mesh =pca_model.transform(mesh_strain_all[labels==<span style="font-family:Courier New;color:#CAC636;">0</span>])<br/><br/></span> </p></li><li>Visualize the projected PCA components on a 2D x-y axis plotting the first principal components (x-axis) vs the second principal component (y-axis) (Figure 15). <br/><em>Note: The resulting PCA plot should clearly highlight the distinct separation of motion behavior between 0% FBS and 5% FBS. The exact numerical values may differ depending on installed library versions of scikit-learn, OS and random number generation settings.<br/></em><br/><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">fig, ax = plt.subplots(<span style="font-family:Courier New;color:#00B0F0;">figsize</span>=(<span style="font-family:Courier New;color:#CAC636;">3</span>,<span style="font-family:Courier New;color:#CAC636;">3</span>))</span> </p><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">ax.plot(pca_5_percent_mesh[:,<span style="font-family:Courier New;color:#CAC636;">0</span>], pca_5_percent_mesh[:,<span style="font-family:Courier New;color:#CAC636;">1</span>], </span><span style="font-family:Courier New;color:#E36C0A;">'o'</span><span style="font-family:Courier New;">, <span style="font-family:Courier New;color:#00B0F0;">ms</span>=<span style="font-family:Courier New;color:#CAC636;">10</span>, <span style="font-family:Courier New;color:#00B0F0;">color</span>=</span><span style="font-family:Courier New;color:#E36C0A;">'g'</span><span style="font-family:Courier New;">, <span style="font-family:Courier New;color:#00B0F0;">label</span>=</span><span style="font-family:Courier New;color:#E36C0A;">'5</span><span style="font-family:Courier New;color:#0070C0;">%</span><span style="font-family:Courier New;"> <span style="font-family:Courier New;color:#00B0F0;">F</span></span><span style="font-family:Courier New;color:#E36C0A;">BS'</span><span style="font-family:Courier New;">)</span> </p><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">ax.plot(pca_0_percent_mesh[:,<span style="font-family:Courier New;color:#CAC636;">0</span>], pca_0_percent_mesh[:,<span style="font-family:Courier New;color:#CAC636;">1</span>], </span><span style="font-family:Courier New;color:#E36C0A;">'o'</span><span style="font-family:Courier New;">, ms=<span style="font-family:Courier New;color:#CAC636;">10</span>, color=</span><span style="font-family:Courier New;color:#E36C0A;">'r'</span><span style="font-family:Courier New;">, label=</span><span style="font-family:Courier New;color:#E36C0A;">'0</span><span style="font-family:Courier New;color:#0070C0;">%</span><span style="font-family:Courier New;"> <span style="font-family:Courier New;color:#00B0F0;">F</span></span><span style="font-family:Courier New;color:#E36C0A;">BS'</span><span style="font-family:Courier New;">)</span> </p><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">ax.set_xlim([<span style="font-family:Courier New;color:#CAC636;">-2</span>,<span style="font-family:Courier New;color:#CAC636;">2</span>])</span> </p><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">ax.set_ylim([<span style="font-family:Courier New;color:#CAC636;">-2</span>,<span style="font-family:Courier New;color:#CAC636;">2</span>])</span> </p><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">plt.legend(<span style="font-family:Courier New;color:#00B0F0;">loc</span>=</span><span style="font-family:Courier New;color:#E36C0A;">'best'</span><span style="font-family:Courier New;">)</span> </p><span style="font-family:Courier New;">plt.show()</span><br/><br/><img alt="" class="layerphoto" height="101" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918202603_3250.jpg" width="100"/><br/><strong>Figure 15. Motion map analysis of a reduced set of 0% and 5% serum two color epithelial cell videos</strong><br/><br/></li></ol></li><li>Superpixel track cleaning for two color cell populations<br/>Fluorescent dyes are imperfect. Despite best efforts there will often be a degree of cross-contamination across acquired color channels. This can lead to noise in the extracted motion tracks, namely green channel motion tracks may exhibit some movement when theoretically there should be none due to bleed-through from the red channel. Post-processing of the tracks can help âcleanâ up the unspecific motion and retain only the motion of the specific superpixel tracks relevant to each initial object of interest in the respective colored channels. In doing so, one can improve the accuracy and sensitivity of analysis. One general method for cleaning is image segmentation of individual objects and retaining only the tracks that cover the segmented objects (see demo Analysis 1: Single Cell Tracking). In our paper, (Zhou <em>et al.</em>, 2019) we instead implemented a more robust segmentation-free method that exploits motion information for colored two cell populations.<br/><br/><ol class="npwtwo"><li>Jointly clean red and green superpixel tracks by considering the connectivity between superpixel tracks that move between the initial frame 0 and the frame specified by frame2. The resulting filtered tracks, meantracks_r_filt, meantracks_g_filt can now be used instead of meantracks_r, meantracks_g in any of the given steps for the analysis of two cell populations.<br/><em>Note: Our implementation is specific for two color videos, however the principle of motion and connectivity it is based on is generalizable.<br/></em><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Track_Filtering.filter_meantracks_superpixels </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> filter_red_green_tracks</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><span style="font-family:Courier New;">meantracks_r_filt,meantracks_g_filt = filter_red_green_tracks(meantracks_r, meantracks_g, <span style="font-family:Courier New;color:#00B0F0;">img_shape</span>=(n_rows, n_cols), <span style="font-family:Courier New;color:#00B0F0;">frame2</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>)</span><br/><br/></li></ol></li></ol><p class="ppzz"><strong> Analysis 3: Analysis of Drosophila Motion in Development</strong> (SiMView lightsheet Microscopy) (<a href="https://os.bio-protocol.org/attached/file/20190616/Supplementary Script Files.zip" target="_blank">Supplementary files</a>)<br/>To demonstrate the ability of MOSES to analyze global tissue and local cellular motion patterns jointly we analyze the supplementary videos of drosophila development published by Amat <em>et al.</em>, 2014. In addition this analysis illustrates i) how one can handle larger videos that contain a lot of temporal frames or have large video frames to speed up processing, ii) how to cluster tracks to reveal local spatial patterns and iii) how to work with general video formats such as .avi, mp4 and .mov.</p><div><ol class="npwtwo"><li>Download supplementary movie 1 (ânmeth.3036-sv1.aviâ) of Amat <em>et al.</em>, 2014, entitled âSiMView imaging of <em>Drosophila</em> embryogenesisâ.</li><li>Construct a function to read the .avi video using the moviepy library with optional rescaling of video frame dimensions through the resize parameter. For more information using moviepy please refer to <a href="https://zulko.github.io/moviepy/" target="_blank">https://zulko.github.io/moviepy/</a>.<br/><p style="text-indent:0cm;"><span style="font-family:Courier New;">def <span style="font-family:Courier New;color:#EDE813;">read_movie</span>(<span style="font-family:Courier New;color:#00B0F0;">moviefile</span><span style="font-family:Courier New;color:black;">,</span><span style="font-family:Courier New;color:#00B0F0;"> resize</span>=1.):</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> moviepy.editor </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> VideoFileClip</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> tqdm </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> tqdm </span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#CC00CC;">from </span><span style="font-family:Courier New;">skimage.transform </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> rescale</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> numpy </span><span style="font-family:Courier New;color:#CC00CC;">as</span><span style="font-family:Courier New;"> np </span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">vidframes = []</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">clip = VideoFileClip(moviefile)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">count = <span style="font-family:Courier New;color:#CAC636;">0</span></span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#7030A0;">for</span><span style="font-family:Courier New;"> frame <span style="font-family:Courier New;color:#0070C0;">in</span> tqdm(clip.iter_frames()):</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;"><span>     </span>vidframes.append(np.uint8(rescale(frame, 1./resize, <span style="font-family:Courier New;color:#00B0F0;">preserve_range</span>=<span style="font-family:Courier New;color:#0070C0;">True</span>)))</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;"><span>    </span>count+=<span style="font-family:Courier New;color:#CAC636;">1</span></span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">vidframes = np.array(vidframes)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;"><span>    </span></span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#7030A0;">return</span><span style="font-family:Courier New;"> vidframes</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;"> </span> </p><p style="margin-left:0cm;text-indent:-.5pt;"><span style="font-family:Courier New;"><span>                  </span><span>       </span>moviefile = </span><span style="font-family:Courier New;color:#E36C0A;">'../Data/Videos/nmeth.3036-sv1.avi'</span><span style="font-family:Courier New;"></span> </p><p style="margin-left:35.4pt;text-indent:-35.9pt;"><span style="font-family:Courier New;"><span>      </span><span style="font-family:Courier New;color:#92D050;"><span>      </span># read in the movie, downsampling framesby 4.</span></span> </p><p style="margin-left:35.4pt;text-indent:-35.9pt;"><span style="font-family:Courier New;"><span>      </span>movie = read_movie(moviefile, <span style="font-family:Courier New;color:#00B0F0;">resize</span>=4.)</span> </p><p style="margin-left:35.4pt;text-indent:-35.9pt;"><span style="font-family:Courier New;"> </span> </p><p style="margin-left:35.4pt;text-indent:-35.9pt;"><span style="font-family:Courier New;"><span>      </span>n_frame, n_rows, n_cols, n_channels =movie.shape</span> </p><span style="font-family:Courier New;color:#EDE813;">print</span><span style="font-family:Courier New;">(</span><span style="font-family:Courier New;color:#E36C0A;">'Sizeof video:</span><span style="font-family:Courier New;"> </span><span style="font-family:Courier New;color:#E36C0A;">(</span><span style="font-family:Courier New;color:#0070C0;">%d</span><span style="font-family:Courier New;color:#E36C0A;">,</span><span style="font-family:Courier New;color:#0070C0;">%d</span><span style="font-family:Courier New;color:#E36C0A;">,</span><span style="font-family:Courier New;color:#0070C0;">%d</span><span style="font-family:Courier New;color:#E36C0A;">,</span><span style="font-family:Courier New;color:#0070C0;">%d</span><span style="font-family:Courier New;color:#E36C0A;"><span style="font-family:Courier New;color:#E56600;">)</span>'</span><span style="font-family:Courier New;"> %(n_frame,n_rows,n_cols,n_channels))</span><br/><br/></li><li>Set motion parameters as before and extract forward and backward superpixel tracks using dense superpixel tracking.<br/><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Optical_Flow_Tracking.superpixel_track </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> compute_grayscale_vid_superpixel_tracks_FB</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># motion extractionparameters.</span><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">optical_flow_params = <span style="font-family:Courier New;color:#00B050;">dict</span>(<span style="font-family:Courier New;color:#00B0F0;">pyr_scale</span>=<span style="font-family:Courier New;color:#CAC636;">0.5</span>, <span style="font-family:Courier New;color:#00B0F0;">levels</span>=<span style="font-family:Courier New;color:#CAC636;">5</span>, <span style="font-family:Courier New;color:#00B0F0;">winsize</span>=<span style="font-family:Courier New;color:#CAC636;">21</span>, <span style="font-family:Courier New;color:#00B0F0;">iterations</span>=<span style="font-family:Courier New;color:#CAC636;">5</span>, <span style="font-family:Courier New;color:#00B0F0;">poly_n</span>=<span style="font-family:Courier New;color:#CAC636;">5</span>, <span style="font-family:Courier New;color:#00B0F0;">poly_sigma</span>=<span style="font-family:Courier New;color:#CAC636;">1.2</span>, <span style="font-family:Courier New;color:#00B0F0;">flags</span>=<span style="font-family:Courier New;color:#CAC636;">0</span>)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># number of superpixels</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">n_spixels = <span style="font-family:Courier New;color:#CAC636;">1000</span></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># extract forward andbackward tracks.</span><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">optflow, meantracks_F, meantracks_B =compute_grayscale_vid_superpixel_tracks_FB(movie[:,:,:,1], optical_flow_params,n_spixels, <span style="font-family:Courier New;color:#00B0F0;">dense</span>=<span style="font-family:Courier New;color:#0070C0;">True</span>)</span> </p><br/></li><li>Cluster superpixels according to track similarity to group together similar tracks. This requires the construction of a feature matrix for each superpixel track. <ol class="npwthree"><li>Construct the track feature, <em>f</em><sub> <em>i</em></sub>for superpixel track i by concatenating the (<em>x,y</em>) coordinates at each time frame up to frame <em>T</em> such that <em>f=[x_1,x_2,â¦,x_(T-1),x_T,y_1,y_2,â¦,y_(T-1),y_T ]</em>. For this example, the final feature matrix, X is a matrix of 2628 x 1104.<br/><br/><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> numpy </span><span style="font-family:Courier New;color:#CC00CC;">as</span><span style="font-family:Courier New;"> np</span> </p><span style="font-family:Courier New;">X = np.hstack([meantracks_F[:,:,<span style="font-family:Courier New;color:#CAC636;">0</span>], meantracks_F[:,:,<span style="font-family:Courier New;color:#CAC636;">1</span>]])</span><br/><br/></li><li>Reduce dimensionality of feature matrix, X using principal components analysis (PCA) to compress features and improve clustering.<br/><br/><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> sklearn.decomposition </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> PCA</span> </p><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">pca_model = PCA(<span style="font-family:Courier New;color:#00B0F0;">n_components</span> = <span style="font-family:Courier New;color:#CAC636;">3</span>, <span style="font-family:Courier New;color:#00B0F0;">whiten</span>=<span style="font-family:Courier New;color:#0070C0;">True</span>, <span style="font-family:Courier New;color:#00B0F0;">random_state</span>=<span style="font-family:Courier New;color:#CAC636;">0</span>)</span> </p><span style="font-family:Courier New;">X_pca = pca_model.fit_transform(X)</span><br/><br/></li><li>Cluster tracks using the PCA reduced features using a Gaussian mixture model (GMM) specifying 10 clusters. The result is given as a vector array, track_labels specifying using unique integer values the group that each superpixel track has been assigned to by the GMM model. Note colors will be different for different runs of the algorithm due to randomness in the setting of the GMM algorithm. <br/><em>Note: Any other clustering algorithm operating on a matrix can be used such as hierarchical clustering, K-means clustering and density based clustering.<br/></em><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> sklearn </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> mixture</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">n_clusters = <span style="font-family:Courier New;color:#CAC636;">10</span></span> </p><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">gmm = mixture.GaussianMixture(<span style="font-family:Courier New;color:#00B0F0;">n_components</span>=n_clusters, <span style="font-family:Courier New;color:#00B0F0;">covariance_type</span>=</span><span style="font-family:Courier New;color:#E36C0A;">'full'</span><span style="font-family:Courier New;">, <span style="font-family:Courier New;color:#00B0F0;">random_state</span>=<span style="font-family:Courier New;color:#CAC636;">0</span>)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">gmm.fit(X_pca)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># get the labels</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">track_labels = gmm.predict(X_pca)</span> </p><br/></li></ol></li><li>Visualize the clustered superpixel tracks coloring each unique group with a different color (Figure 16). <br/><em>Note: We confirmed differences in GMM clustering results between different OS and scikit-learn library versions with the same code. The reported figure was obtained for Windows 10, scikit-</em><br/><em> learn version 0.21.2. <br/></em><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Visualisation_Tools.track_plotting </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> plot_tracks</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> seaborn </span><span style="font-family:Courier New;color:#CC00CC;">as </span><span style="font-family:Courier New;">sns</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> pylab </span><span style="font-family:Courier New;color:#CC00CC;">as</span><span style="font-family:Courier New;"> plt </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># Generate colours foreach unique cluster.</span><span style="font-family:Courier New;"></span> </p><p style="text-align:justify;text-indent:0cm;"><span style="font-family:Courier New;">cluster_colors = sns.color_palette(</span><span style="font-family:Courier New;color:#E36C0A;">'hls'</span><span style="font-family:Courier New;">, n_clusters)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># overlay cluster tracksand clustered superpixels</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">fig, ax = plt.subplots(<span style="font-family:Courier New;color:#00B0F0;">nrows</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>,<span style="font-family:Courier New;color:#00B0F0;">ncols</span>=<span style="font-family:Courier New;color:#CAC636;">3</span>, <span style="font-family:Courier New;color:#00B0F0;">figsize</span>=(<span style="font-family:Courier New;color:#CAC636;">15</span>,<span style="font-family:Courier New;color:#CAC636;">15</span>))</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">ax[<span style="font-family:Courier New;color:#CAC636;">0</span>].imshow(movie[<span style="font-family:Courier New;color:#CAC636;">0</span>]); ax[<span style="font-family:Courier New;color:#CAC636;">0</span>].grid(<span style="font-family:Courier New;color:#E36C0A;">'off'</span>);ax[<span style="font-family:Courier New;color:#CAC636;">0</span>].axis(<span style="font-family:Courier New;color:#E36C0A;">'off'</span>); ax[<span style="font-family:Courier New;color:#CAC636;">0</span>].set_title(<span style="font-family:Courier New;color:#E36C0A;">'Initial Points'</span>)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">ax[<span style="font-family:Courier New;color:#CAC636;">1</span>].imshow(movie[<span style="font-family:Courier New;color:#CAC636;">-1</span>]); ax[<span style="font-family:Courier New;color:#CAC636;">1</span>].grid(<span style="font-family:Courier New;color:#E36C0A;">'off'</span>);ax[<span style="font-family:Courier New;color:#CAC636;">1</span>].axis(<span style="font-family:Courier New;color:#E36C0A;">'off'</span>); ax[<span style="font-family:Courier New;color:#CAC636;">1</span>].set_title(<span style="font-family:Courier New;color:#E36C0A;">'Final Points'</span>)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">ax[<span style="font-family:Courier New;color:#CAC636;">2</span>].imshow(movie[<span style="font-family:Courier New;color:#CAC636;">0</span>]); ax[<span style="font-family:Courier New;color:#CAC636;">2</span>].grid(<span style="font-family:Courier New;color:#E36C0A;">'off'</span>);ax[<span style="font-family:Courier New;color:#CAC636;">2</span>].axis(<span style="font-family:Courier New;color:#E36C0A;">'off'</span>); ax[<span style="font-family:Courier New;color:#CAC636;">2</span>].set_title(<span style="font-family:Courier New;color:#E36C0A;">'Clustered Tracks'</span>)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">for</span><span style="font-family:Courier New;"> ii, lab <span style="font-family:Courier New;color:#0070C0;">in</span> <span style="font-family:Courier New;color:#EDE813;">enumerate</span>(np.unique(track_labels)):</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#92D050;"># plot coloured initialpoints</span><span style="font-family:Courier New;"> </span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">ax[<span style="font-family:Courier New;color:#CAC636;">0</span>].plot(meantracks_F[track_labels==lab,<span style="font-family:Courier New;color:#CAC636;">0</span>,<span style="font-family:Courier New;color:#CAC636;">1</span>], </span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;"><span>    </span><span>           </span><span>     </span><span>    </span>meantracks_F[track_labels==lab,<span style="font-family:Courier New;color:#CAC636;">0</span>,<span style="font-family:Courier New;color:#CAC636;">0</span>], <span style="font-family:Courier New;color:#E36C0A;">'o'</span>, <span style="font-family:Courier New;color:#00B0F0;">color</span>=cluster_colors[ii], <span style="font-family:Courier New;color:#00B0F0;">alpha</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#92D050;"># plot coloured finalpoints</span><span style="font-family:Courier New;"> </span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">ax[<span style="font-family:Courier New;color:#CAC636;">1</span>].plot(meantracks_F[track_labels==lab,<span style="font-family:Courier New;color:#CAC636;">-1</span>,<span style="font-family:Courier New;color:#CAC636;">1</span>], </span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;"><span>         </span><span>    </span>meantracks_F[track_labels==lab,<span style="font-family:Courier New;color:#CAC636;">-1</span>,<span style="font-family:Courier New;color:#CAC636;">0</span>], <span style="font-family:Courier New;color:#E36C0A;">'o'</span>, <span style="font-family:Courier New;color:#00B0F0;">color</span>=cluster_colors[ii], <span style="font-family:Courier New;color:#00B0F0;">alpha</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>)</span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;color:#92D050;"># plot coloured tracks</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:20.0pt;"><span style="font-family:Courier New;">plot_tracks(meantracks_F[track_labels==lab],ax[<span style="font-family:Courier New;color:#CAC636;">2</span>], <span style="font-family:Courier New;color:#00B0F0;">color</span>=cluster_colors[ii], <span style="font-family:Courier New;color:#00B0F0;">lw</span>=<span style="font-family:Courier New;color:#CAC636;">1.0</span>, <span style="font-family:Courier New;color:#00B0F0;">alpha</span>=<span style="font-family:Courier New;color:#CAC636;">0.7</span>)</span> </p><span style="font-family:Courier New;">plt.show()</span><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918202839_4641.jpg" width="363"/><br/><strong>Figure 16. Unsupervised clustering of superpixel tracks to group local motion during <em>Drosophila</em> embryogenesis.</strong> Initial (A) and final (B) centroid positions of superpixels plotted as a dot and colored by assigned group using Gaussian mixture model for clustering. Corresponding superpixel tracks colored by cluster (C). <br/><br/></li><li>Compute the motion saliency map of the forward and backward tracks to find motion sources and sinks (Figure 17).<br/><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> compute_motion_saliency_map</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> skimage.exposure </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> equalize_hist</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> skimage.filters </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> Gaussian</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># specify a large thresholdto capture long-distances.</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">dist_thresh = <span style="font-family:Courier New;color:#CAC636;">20</span></span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">spixel_size = meantracks[<span style="font-family:Courier New;color:#CAC636;">1</span>,<span style="font-family:Courier New;color:#CAC636;">0</span>,<span style="font-family:Courier New;color:#CAC636;">1</span>]-meantracks[<span style="font-family:Courier New;color:#CAC636;">1</span>,<span style="font-family:Courier New;color:#CAC636;">0</span>,<span style="font-family:Courier New;color:#CAC636;">0</span>]</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">motion_saliency_F,motion_saliency_spatial_time_F = compute_motion_saliency_map(meantracks, <span style="font-family:Courier New;color:#00B0F0;">dist_thresh</span>=dist_thresh, <span style="font-family:Courier New;color:#00B0F0;">shape</span>=movie.shape[<span style="font-family:Courier New;color:#CAC636;">1</span>:<span style="font-family:Courier New;color:#CAC636;">-1</span>], <span style="font-family:Courier New;color:#00B0F0;">max_frame</span>=<span style="font-family:Courier New;color:#0070C0;">None</span>, <span style="font-family:Courier New;color:#00B0F0;">filt</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>, <span style="font-family:Courier New;color:#00B0F0;">filt_size</span>=spixel_size)</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">motion_saliency_B,motion_saliency_spatial_time_B = compute_motion_saliency_map(meantracks_B, <span style="font-family:Courier New;color:#00B0F0;">dist_thresh</span>=dist_thresh,<span>                                                                   </span><span style="font-family:Courier New;color:#00B0F0;">shape</span>=movie.shape[<span style="font-family:Courier New;color:#CAC636;">1</span>:<span style="font-family:Courier New;color:#CAC636;">-1</span>], <span style="font-family:Courier New;color:#00B0F0;">max_frame</span>=<span style="font-family:Courier New;color:#0070C0;">None</span>, <span style="font-family:Courier New;color:#00B0F0;">filt</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>, <span style="font-family:Courier New;color:#00B0F0;">filt_size</span>=spixel_size)</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># smooth the discretelooking motion saliency maps.</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">motion_saliency_F_smooth =gaussian(motion_saliency_F, spixel_size/2.)</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">motion_saliency_B_smooth =gaussian(motion_saliency_B, spixel_size/2.)</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># visualise the computedresults.</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">fig, ax = plt.subplots(<span style="font-family:Courier New;color:#00B0F0;">nrows</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>, <span style="font-family:Courier New;color:#00B0F0;">ncols</span>=<span style="font-family:Courier New;color:#CAC636;">2</span>, <span style="font-family:Courier New;color:#00B0F0;">figsize</span>=(<span style="font-family:Courier New;color:#CAC636;">15</span>,<span style="font-family:Courier New;color:#CAC636;">15</span>))</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">ax[<span style="font-family:Courier New;color:#CAC636;">0</span>].imshow(movie[<span style="font-family:Courier New;color:#CAC636;">0</span>], <span style="font-family:Courier New;color:#00B0F0;">cmap</span>=<span style="font-family:Courier New;color:#E36C0A;">'gray'</span>);ax[<span style="font-family:Courier New;color:#CAC636;">0</span>].grid(<span style="font-family:Courier New;color:#E36C0A;">'off'</span>); ax[<span style="font-family:Courier New;color:#CAC636;">0</span>].axis(<span style="font-family:Courier New;color:#E36C0A;">'off'</span>)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">ax[<span style="font-family:Courier New;color:#CAC636;">1</span>].imshow(movie[<span style="font-family:Courier New;color:#CAC636;">0</span>], <span style="font-family:Courier New;color:#00B0F0;">cmap</span>=<span style="font-family:Courier New;color:#E36C0A;">'gray'</span>);ax[<span style="font-family:Courier New;color:#CAC636;">1</span>].grid(<span style="font-family:Courier New;color:#E36C0A;">'off'</span>); ax[<span style="font-family:Courier New;color:#CAC636;">1</span>].axis(<span style="font-family:Courier New;color:#E36C0A;">'off'</span>)</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">ax[<span style="font-family:Courier New;color:#CAC636;">0</span>].set_title(<span style="font-family:Courier New;color:#E36C0A;">'Motion Sinks'</span>);ax[<span style="font-family:Courier New;color:#CAC636;">1</span>].set_title(<span style="font-family:Courier New;color:#E36C0A;">'Motion Sources'</span>)</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">ax[<span style="font-family:Courier New;color:#CAC636;">0</span>].imshow(equalize_hist(motion_saliency_F_smooth), <span style="font-family:Courier New;color:#00B0F0;">cmap</span>=<span style="font-family:Courier New;color:#E36C0A;">'coolwarm'</span>, <span style="font-family:Courier New;color:#00B0F0;">alpha</span>=<span style="font-family:Courier New;color:#CAC636;">0.5</span>, <span style="font-family:Courier New;color:#00B0F0;">vmin</span>=<span style="font-family:Courier New;color:#CAC636;">0</span>, <span style="font-family:Courier New;color:#00B0F0;">vmax</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>)</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">ax[<span style="font-family:Courier New;color:#CAC636;">1</span>].imshow(equalize_hist(motion_saliency_B_smooth), <span style="font-family:Courier New;color:#00B0F0;">cmap</span>=<span style="font-family:Courier New;color:#E36C0A;">'coolwarm'</span>, <span style="font-family:Courier New;color:#00B0F0;">alpha</span>=<span style="font-family:Courier New;color:#CAC636;">0.5</span>, <span style="font-family:Courier New;color:#00B0F0;">vmin</span>=<span style="font-family:Courier New;color:#CAC636;">0</span>, <span style="font-family:Courier New;color:#00B0F0;">vmax</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>)</span><span style="font-family:Courier New;"></span> </p><span style="font-family:Courier New;">plt.show()</span><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918202914_9456.jpg" width="252"/><br/><strong>Figure 17. Motion saliency map to highlight spatial areas of motion sinks (A) and sources (B) during Drosophila embryogenesis</strong><br/><div><br/></div></li></ol></div><p class="ppzz"><strong>Analysis 4: Intra-vital Imaging Analysis</strong> (Multiphoton Microscopy) (<a href="https://os.bio-protocol.org/attached/file/20190616/Supplementary Script Files.zip" target="_blank">Supplementary files</a>)<br/>Intra-vital imaging has enabled direct <em>in-vivo</em> imaging of the movement of fluorescently tagged cells in their native microenvironment. A common application is the study of immune cell behavior with respect to the local vasculature and extracellular matrix in tissue (Li <em>et al.</em>, 2012). Typically it is desired to extract the global motion patterns of individual cell population despite their stochastic individual motion. Using automatic single-cell tracking approaches is frequently unreliable due to the lower imaging magnification and poorer spatial resolution of the acquired images compared to <em>in-vitro</em> imaging. For example, it is difficult for humans to manually distinguish between individually migrating fluorescent immune cells. Here we demonstrate how to use MOSES to nevertheless extract the global motion pattern of individual neutrophil cells to a laser-induced wound site for quantitative analysis.</p><div><ol class="npwtwo"><li>Download supplementary movie 1 of Li <em>et al.</em>, 2012. </li><li>Read the movie using the example read_movie function defined in Analysis 3 above. As the video is short and we want to retain high spatial fidelity, the native pixel resolution of image frames is used without downsampling (resize=1.). <br/><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:windowtext;">moviefile = </span><span style="font-family:Courier New;color:#E36C0A;">'../Data/Videos/nprot.2011.438-S5.mov'</span><span style="font-family:Courier New;color:windowtext;"></span> </p><span style="font-family:Courier New;">movie = read_movie(moviefile, <span style="font-family:Courier New;color:#00B0F0;">resize</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>.)</span><br/><br/></li><li>Set the motion extraction parameters and extract both forward and backward superpixel tracks using 1,000 superpixels. Optionally set dense=True. <br/><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Optical_Flow_Tracking.superpixel_track </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> compute_grayscale_vid_superpixel_tracks_FB</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># motion extractionparameters.</span><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">optical_flow_params = <span style="font-family:Courier New;color:#00B050;">dict</span>(<span style="font-family:Courier New;color:#00B0F0;">pyr_scale</span>=<span style="font-family:Courier New;color:#CAC636;">0.5</span>, <span style="font-family:Courier New;color:#00B0F0;">levels</span>=<span style="font-family:Courier New;color:#CAC636;">5</span>, <span style="font-family:Courier New;color:#00B0F0;">winsize</span>=<span style="font-family:Courier New;color:#CAC636;">21</span>, <span style="font-family:Courier New;color:#00B0F0;">iterations</span>=<span style="font-family:Courier New;color:#CAC636;">5</span>, <span style="font-family:Courier New;color:#00B0F0;">poly_n</span>=<span style="font-family:Courier New;color:#CAC636;">5</span>, <span style="font-family:Courier New;color:#00B0F0;">poly_sigma</span>=<span style="font-family:Courier New;color:#CAC636;">1.2</span>, <span style="font-family:Courier New;color:#00B0F0;">flags</span>=<span style="font-family:Courier New;color:#CAC636;">0</span>)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># number of superpixels</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">n_spixels = 1000</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># extract superpixeltracks for the 2nd or 'green' GFP+ cell channel</span><span style="font-family:Courier New;"></span> </p><span style="font-family:Courier New;">optflow, meantracks_F, meantracks_B =compute_grayscale_vid_superpixel_tracks_FB(movie[:,:,:,1], optical_flow_params,n_spixels, <span style="font-family:Courier New;color:#00B0F0;">dense</span>=<span style="font-family:Courier New;color:#0070C0;">True</span>)</span><br/><br/></li><li>Compute the mean temporal optical flow to summarize the mean motion of image pixels over the imaged duration. Through averaging, stochastic motion is removed and globally consistent trends are reinforced. Color map the computed mean optical flow according to the directionality of motion using an HSV color scheme to visualize the average global motion pattern of GFP+ neutrophil cells (Figure 18A).<br/><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from </span><span style="font-family:Courier New;">MOSES.Visualisation_Tools.motion_field_visualisation </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> view_ang_flow</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> numpy </span><span style="font-family:Courier New;color:#CC00CC;">as </span><span style="font-family:Courier New;">np</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">mean_opt_flow = np.mean(optflow, <span style="font-family:Courier New;color:#00B0F0;">axis</span>=<span style="font-family:Courier New;color:#CAC636;">0</span>)</span> </p><span style="font-family:Courier New;">mean_colored_flow = view_ang_flow(mean_opt_flow)</span><br/><br/></li><li>Compute the average velocity of individual superpixel tracks and the mean temporal (<em>x,y</em>) coordinates of superpixel tracks as the MOSES superpixel track equivalent to Step 4 above (Figure 18B).<br/><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.tracks_statistics_tools </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> average_displacement_tracks</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">mean_disps_tracks =average_displacement_tracks(meantracks)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># parse out the mean(u,v) velocities of tracks</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">U_tra = mean_disps_tracks[:,<span style="font-family:Courier New;color:#CAC636;">1</span>] </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># this is negative toconvert image coordinates to proper (x,y) used in matplotlib quiverplot.</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">V_tra = -mean_disps_tracks[:,<span style="font-family:Courier New;color:#CAC636;">0</span>] </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">Mag_tra = np.hypot(U_tra, V_tra)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;"> </span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># compute the mean (x,y)position of tracks</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">X_mean = np.mean(meantracks[:,:,<span style="font-family:Courier New;color:#CAC636;">1</span>], <span style="font-family:Courier New;color:#00B0F0;">axis</span>=<span style="font-family:Courier New;color:#CAC636;">-1</span>)</span> </p><span style="font-family:Courier New;">Y_mean = np.mean(meantracks[:,:,<span style="font-family:Courier New;color:#CAC636;">0</span>], <span style="font-family:Courier New;color:#00B0F0;">axis</span>=<span style="font-family:Courier New;color:#CAC636;">-1</span>)</span><br/><br/></li><li>Compute the forward and backward motion saliency maps using the forward and backward superpixel tracks to reveal motion âsinksâ and âsourcesâ respectively (Figure 18B). <br/><br/><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> MOSES.Motion_Analysis.mesh_statistics_tools </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> compute_motion_saliency_map</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from</span><span style="font-family:Courier New;"> skimage.exposure </span><span style="font-family:Courier New;color:#CC00CC;">import</span><span style="font-family:Courier New;"> equalize_hist</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#CC00CC;">from </span><span style="font-family:Courier New;">skimage.filters</span><span style="font-family:Courier New;color:#CC00CC;"> import </span><span style="font-family:Courier New;">Gaussian</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># specify a largethreshold to capture long-distances.</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">dist_thresh = <span style="font-family:Courier New;color:#CAC636;">5</span></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">spixel_size = meantracks[<span style="font-family:Courier New;color:#CAC636;">1</span>,<span style="font-family:Courier New;color:#CAC636;">0</span>,<span style="font-family:Courier New;color:#CAC636;">1</span>]-meantracks[<span style="font-family:Courier New;color:#CAC636;">1</span>,<span style="font-family:Courier New;color:#CAC636;">0</span>,<span style="font-family:Courier New;color:#CAC636;">0</span>]</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># compute the forwardand backward motion saliency maps.</span><span style="font-family:Courier New;"></span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">motion_saliency_F,motion_saliency_spatial_time_F = compute_motion_saliency_map(meantracks, <span style="font-family:Courier New;color:#00B0F0;">dist_thresh</span>=dist_thresh, <span style="font-family:Courier New;color:#00B0F0;">shape</span>=movie.shape[<span style="font-family:Courier New;color:#CAC636;">1</span>:<span style="font-family:Courier New;color:#CAC636;">-1</span>], <span style="font-family:Courier New;color:#00B0F0;">max_frame</span>=<span style="font-family:Courier New;color:#0070C0;">None</span>, <span style="font-family:Courier New;color:#00B0F0;">filt</span>=<span style="font-family:Courier New;color:#CAC636;">1</span>, <span style="font-family:Courier New;color:#00B0F0;">filt_size</span>=spixel_size)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">motion_saliency_B,motion_saliency_spatial_time_B = compute_motion_saliency_map(meantracks_B, <span style="font-family:Courier New;color:#00B0F0;">dist_thresh</span>=dist_thresh, <span>                                                               </span><span style="font-family:Courier New;color:#00B0F0;">shape</span>=movie.shape[<span style="font-family:Courier New;color:#CAC636;">1</span>:<span style="font-family:Courier New;color:#CAC636;">-1</span>], <span style="font-family:Courier New;color:#00B0F0;">max_frame</span>=<span style="font-family:Courier New;color:#0070C0;">None</span>, <span style="font-family:Courier New;color:#00B0F0;">filt</span>=1, <span style="font-family:Courier New;color:#00B0F0;">filt_size</span>=spixel_size)</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;color:#92D050;"># smooth the discretelooking motion saliency maps.</span> </p><p style="text-indent:0cm;"><span style="font-family:Courier New;">motion_saliency_F_smooth =gaussian(motion_saliency_F, spixel_size/2.)</span> </p><span style="font-family:Courier New;">motion_saliency_B_smooth =gaussian(motion_saliency_B, spixel_size/2.)</span><br/><br/><img alt="" class="layerphoto" height="100" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20190918/20190918203112_1021.jpg" width="209"/><br/><strong>Figure 18. MOSES analysis unbiasedly uncovers the migration of GFP+ neutrophil cells to site of laser injury.</strong> A. Mean motion field after averaging over all time points. Direction of motion is colored according to the inset color wheel. Colour intensity represents the magnitude of the velocity. B. Overlay of the mean superpixel track velocities represented as green arrows plotted on top of the first video frame. Additionally, the computed forward and backward motion saliency maps are shown as red and green heatmaps revealing local motion sinks and sources respectively. Square box in the middle indicates the induced laser injury site. </li></ol></div><p class="pptt" id="biaoti29647">### Notes</p><p class="ppzz">We highlight key common considerations that arise when conducting a MOSES analysis to extract superpixel tracks, computing the motion saliency map and constructing motion maps. In general, MOSES is reproducible, produces consistent and interpretable results for all types of imaging as long as its primary modeling assumptions are satisfied.</p><ol class="npwtwo"><li>Key analysis assumptions of MOSESâtwo general key principles govern the behavior and accuracy of MOSES<ol class="npwthree"><li><em>MOSES implicitly assumes that the motion of interest is the most dominant contributor of motion in the video.</em> This is the most important assumption of MOSES. Given a video many factors may influence the motion of the image pixels for example camera movement and stage movement cause global shifts in the field of view and cell division induce local motion. MOSES does not explicitly disentangle the contribution to the global measured motion from different sources. If multiple sources of motion are present with similar magnitudes such as the deformation of the extra-cellular matrix and cellular migration in <em>intra-vital</em> images, non-rigid image registration should be applied first to remove the extra-cellular deformations before running MOSES to analyze only the cellular motion component.<br/></li><li><em>MOSES superpixel tracks extract the movement trajectory that follows the most dominant local motion pattern.</em> Individual superpixels are updated through time according to the average (mean or median) velocity of individual pixels within it. Should bimodality exist in the local directionality, MOSES would update the superpixel position according to the more dominant direction. This may cause the superpixels to no longer follow the same moving entity. Thus single MOSES tracks are not guaranteed to follow any individual cell or cell group however the extraction of dominant global and local motion patterns and the analysis of motion source and sinks becomes very natural. Given no restriction on the movement of superpixels as they are updated over time, should dominant local motion patterns exist then they will naturally aggregate together surrounding superpixels and statistically upvote these image regions. By exploiting these phenomena, the salient motion patterns within a video can be efficiently and unbiasedly uncovered and encoded into âsignaturesâ for phenotyping.</li></ol></li><li>Setting the number of superpixels<br/>The number of superpixels directly determines the size of the region of interest (ROI) being tracked. Less superpixels or larger ROI capture coarse motion patterns that affect larger areas but lose resolution in the motion information due to computing the average over a larger spatial area. Conversely more superpixels or smaller ROI better capture finer motion patterns but velocities may be more subject to outliers. Finally, there is a speed consideration. More superpixels take longer to track. Typically the number of superpixels used should be the minimum necessary to capture the spatial scale of the desired motion pattern. As a guide start with 1,000 superpixels. If too fine try 100 superpixels, if too coarse try 10,000 superpixels.</li><li>Setting the optical flow motion extraction parameters<br/>Optical flow algorithms aim to estimate the local motion field by finding the optimal set of displacements (Î<em>x</em>,Î<em>y</em>) that minimize the difference of the pixel intensities between two frames separated by a small time Ît. Mathematically this solves for the following equality<br/><br/>I(x,y,t)=I(x+Îx,y+Îy,t+Ît)<br/><br/>where <em>I(x,y,t)</em> is the pixel intensity values of the video frame at time t. The OpenCV FarnebÃ¤ck optical flow algorithm used in MOSES solves this problem using local image patches of a fixed user-specified size similar to particle image velocimetry. To capture larger displacements than the fixed window size (given by the number of pixels), the original image is first downsampled and smoothed multiple times resulting in an image pyramid. The optimization problem is then solved progressively starting from the lowest level of the image pyramid with the most downsampled image and ending at the topmost level of the image pyramid, the original image to yield the final set of displacements. In this manner, the same fixed window size in lower pyramid levels corresponds to increasingly larger areas at the original image scale. The main consideration when setting the parameters for optical flow estimation is choosing a set of parameters that best captures any long, discontinuous displacements between successive video frames. This type of motion is very common for particle-like objects and cells undergoing single-cell motion. To better capture large, discontinuous displacements one can increase the window size (<span style="font-family:Courier New;">winsize</span>), increase the number of levels in the pyramid (<span style="font-family:Courier New;">levels</span>) or decrease the scaling factor (<span style="font-family:Courier New;">pyr_scale</span>) to create smaller images per pyramid level. Note the number of pyramid levels and pyramid scale is related as the upper limit of the number of pyramid levels is bounded by the original image size and the scaling factor. In practice changing the number of levels is easier to tune. The optimization process is iterative thus increasing the number of <span style="font-family:Courier New;">iterations</span> leads to more accurate results. Adjustment of these parameters typically requires longer computation times per video frame. We recommended starting parameters of <span style="font-family:Courier New;">pyr_scale=0.5, levels=3, winsize=15, iterations=3</span> for confluent cell motion similar to those in epithelial sheets.</li><li>Rescaling image intensity before optical flow extraction<br/>It is important to rescale image intensities prior to motion extraction with optical flow. Ideally all video frames should be of the same brightness and well contrasted. If this is not the case it is recommended to rescale the image intensities of each video frame to their respective minimum and maximum values. Alternatively one can correct for the brightness variation using a known mathematical model for example an exponential decay model for fluorescence microscopy.</li><li>Setting the distance threshold in the mesh construction and motion saliency map computation<br/>Similar to the number of superpixels, the distance threshold should be set according to the spatial range of the phenomena to be captured. Larger distance thresholds capture more neighboring superpixel tracks and give more information regarding events that act on longer spatial scales such as boundary formation. Conversely smaller distance thresholds are more useful when considering phenomena that occur over a very localized region such as neutrophil migration to local wound sites. We recommend experimenting with different values for the distance threshold. It should be noted that results are generally stable over a wide range of distance thresholds. </li><li>Feature construction for use in motion map construction<br/>The interested reader should refer to the supplementary information of the original MOSES paper (Zhou <em>et al.</em>, 2019) where we discussed in detail how to construct informative features for more general datasets. In brief, there is no one method fits all approach. Users should construct a set of features that best capture the appearance and movement variation exhibited by moving entities in the video. For epithelial sheets where individual cell morphology is not readily visible, the use of only motion-based features like the proposed mesh strain curve should be sufficient. For sparsely plated single cells that exhibit morphological changes over time, the incorporation of appearance features is also important. For large datasets, one might consider training deep learning feature extractors. The more informative the features used, the less sophisticated the algorithm required for projecting the features when constructing a 2D or 3D motion map.</li></ol><p class="pptt" id="biaoti29648">### Acknowledgments</p><p class="ppzz">This work is an accompaniment to our original methods paper published in eLife (Zhou <em>et al.</em>, 2019) and extends the original work to showcase more the practical use of MOSES on a wide variety of imaging datasets. We thank Prof. Hiroshi Nakagawa for the generous donation of EPC2 cells originally used in the study of Harada <em>et al.</em>, 2013. We thank Mark Shipman for technical assistance with timelapse microscopy in the collection of the two cell population dataset. This work was mainly funded by the Ludwig Institute for Cancer Research (LICR) with additional support from a CRUK grant to XL (C9720/A18513). FYZ is funded through the EPSRC Life Sciences Interface Doctoral Training Centre EP/F500394/1 and LICR, CRP and XL are funded by LICR, RPO is supported by LICR, the Oxford Health Services Research Committee and Oxford University Clinical Academic Graduate School supported by the National Institute for Health Research (NIHR) Biomedical Research Centre based at the Oxford University Hospitals Trust, Oxford, MJW is supported by CRUK (C5255/A19498, through an Oxford Cancer Research Centre Clinical Research Training Fellowship), and JR is funded by LICR and the EPSRC SeeBiByte Programme Grant (EP/M013774/1). The views expressed herein are those of the authors and not necessarily those of the NHS, the NIHR or the Department of Health.</p><p class="pptt" id="biaoti29649">### Competing interests</p><p class="ppzz">A patent is pending for MOSES (UK application no. GB1716893.1, International application no. PCT/GB2018/052935). MOSES is available open-source and free for all academic and non-profit users under a Ludwig academic and non-profit license.</p><p class="pptt" id="biaoti29650">### References</p><ol class="npwtwok"><li>Amat, F., Lemon, W., Mossing, D. P., McDole, K., Wan, Y., Branson, K., Myers, E. W. and Keller, P. J. (2014). <a href="http://www.ncbi.nlm.nih.gov/pubmed/25042785" target="_blank">Fast, accurate reconstruction of cell lineages from large-scale fluorescence microscopy data.</a> <em>Nat Methods </em>11(9): 951-958. </li><li>FarnebÃ¤ck, G. (2003). <a href="https://link.springer.com/chapter/10.1007%2F3-540-45103-X_50" target="_blank">Two-frame motion estimation based on polynomial expansion.</a> In: Bigun, J. and Gustavsson, T. (Eds.). Image Analysis. SCIA 2003. Lecture Notes in Computer Science, vol 2749. Springer, Berlin, Heidelberg.</li><li>Harada, H., Nakagawa, H., Oyama, K., Takaoka, M., Andl, C.D., Jacobmeier, B., von Werder, A., Enders, G.H., Opitz, O.G. and Rustgi, A.K. (2003). <a href="http://www.ncbi.nlm.nih.gov/pubmed/12939398" target="_blank">Telomerase induces immortalization of human esophageal keratinocytes without p16INK4a inactivation.</a> <em>Molecular Cancer Research</em>, 1(10): 729-738.</li><li>Li, J. L., Goh, C. C., Keeble, J. L., Qin, J. S., Roediger, B., Jain, R., Wang, Y., Chew, W. K., Weninger, W. and Ng, L. G. (2012). <a href="http://www.ncbi.nlm.nih.gov/pubmed/22240584" target="_blank">Intravital multiphoton imaging of immune responses in the mouse ear skin.</a> <em>Nat Protoc</em> 7(2): 221-234.</li><li>MaÅ¡ka, M., Ulman, V., Svoboda, D., Matula, P., Matula, P., Ederra, C., Urbiola, A., Espana, T., Venkatesan, S., Balak, D. M., Karas, P., Bolckova, T., Streitova, M., Carthel, C., Coraluppi, S., Harder, N., Rohr, K., Magnusson, K. E., Jalden, J., Blau, H. M., Dzyubachyk, O., Krizek, P., Hagen, G. M., Pastor-Escuredo, D., Jimenez-Carretero, D., Ledesma-Carbayo, M. J., Munoz-Barrutia, A., Meijering, E., Kozubek, M. and Ortiz-de-Solorzano, C. (2014). <a href="http://www.ncbi.nlm.nih.gov/pubmed/24526711" target="_blank">A benchmark for comparison of cell tracking algorithms.</a> <em>Bioinformatics</em> 30(11): 1609-1617.</li><li>Meijering, E., Dzyubachyk, O. and Smal, I. (2012). <a href="http://www.ncbi.nlm.nih.gov/pubmed/22264535" target="_blank">Methods for cell and particle tracking.</a> <em>Methods Enzymol</em> 504: 183-200.</li><li>Milde, F., Franco, D., Ferrari, A., Kurtcuoglu, V., Poulikakos, D. and Koumoutsakos, P. (2012). <a href="http://www.ncbi.nlm.nih.gov/pubmed/23047374" target="_blank">Cell Image Velocimetry (CIV): boosting the automated quantification of cell migration in wound healing assays.</a> <em>Integr Biol (Camb)</em> 4(11): 1437-1447.</li><li>Neumann, B., Held, M., Liebel, U., Erfle, H., Rogers, P., Pepperkok, R. and Ellenberg, J. (2006). <a href="http://www.ncbi.nlm.nih.gov/pubmed/16628209" target="_blank">High-throughput RNAi screening by time-lapse imaging of live human cells.</a> <em>Nat Methods </em>3(5): 385-390.</li><li>Nketia, T. A., Sailem, H., Rohde, G., Machiraju, R. and Rittscher, J. (2017). <a href="http://www.ncbi.nlm.nih.gov/pubmed/28242295" target="_blank">Analysis of live cell images: Methods, tools and opportunities.</a> <em>Methods</em> 115: 65-79.</li><li>Padfield, D., Rittscher, J. and Roysam, B. (2011). <a href="http://www.ncbi.nlm.nih.gov/pubmed/20864383" target="_blank">Coupled minimum-cost flow cell tracking for high-throughput quantitative analysis.</a> <em>Med Image Anal</em> 15(4): 650-668.</li><li>Petitjean, L., Reffay, M., Grasland-Mongrain, E., Poujade, M., Ladoux, B., Buguin, A. and Silberzan, P. (2010). <a href="http://www.ncbi.nlm.nih.gov/pubmed/20441742" target="_blank">Velocity fields in a collectively migrating epithelium.</a> <em>Biophys J</em> 98(9): 1790-1800.</li><li>Schiegg, M., Hanslovsky, P., Haubold, C., Koethe, U., Hufnagel, L. and Hamprecht, F. A. (2015). <a href="http://www.ncbi.nlm.nih.gov/pubmed/25406328" target="_blank">Graphical model for joint segmentation and tracking of multiple dividing cells. </a><em>Bioinformatics</em> 31(6): 948-956.</li><li>SzabÃ³, B., SzÃ¶llÃ¶si, G. J., GÃ¶nci, B., JurÃ¡nyi, Z., Selmeczi, D. and Vicsek, T. (2006). <a href="http://www.ncbi.nlm.nih.gov/pubmed/17280097" target="_blank">Phase transition in the collective migration of tissue cells: experiment and model.</a> <em>Phys Rev E Stat Nonlin Soft Matter Phys</em> 74(6 Pt 1): 061908.</li><li>Zaritsky, A., Natan, S., Ben-Jacob, E. and Tsarfaty, I. (2012). <a href="http://www.ncbi.nlm.nih.gov/pubmed/22970283" target="_blank">Emergence of HGF/SF-induced coordinated cellular motility.</a> <em>PLoS One</em> 7(9): e44671.</li><li>Zaritsky, A., Kaplan, D., Hecht, I., Natan, S., Wolf, L., Gov, N. S., Ben-Jacob, E. and Tsarfaty, I. (2014). <a href="http://www.ncbi.nlm.nih.gov/pubmed/25058592" target="_blank">Propagating waves of directionality and coordination orchestrate collective cell migration.</a> <em>PLoS Comput Biol</em> 10(7): e1003747.</li><li>Zaritsky, A., Welf, E. S., Tseng, Y. Y., Angeles Rabadan, M., Serra-Picamal, X., Trepat, X. and Danuser, G. (2015). <a href="http://www.ncbi.nlm.nih.gov/pubmed/26682808" target="_blank">Seeds of locally aligned motion and stress coordinate a collective cell migration.</a> <em>Biophys J</em> 109(12): 2492-2500.</li><li>Zaritsky, A., Tseng, Y. Y., Rabadan, M. A., Krishna, S., Overholtzer, M., Danuser, G. and Hall, A. (2017). <a href="http://www.ncbi.nlm.nih.gov/pubmed/28512143" target="_blank">Diverse roles of guanine nucleotide exchange factors in regulating collective cell migration.</a><em> J Cell Biol</em> 216(6): 1543-1556.</li><li>Zhou, F. Y., Ruiz-Puig, C., Owen, R. P., White, M. J., Rittscher, J. and Lu, X. (2019). <a href="http://www.ncbi.nlm.nih.gov/pubmed/30803483" target="_blank">Motion sensing superpixels (MOSES) is a systematic computational framework to quantify and discover cellular motion phenotypes.</a> <em>Elife</em> 8: pii: e40162.<br/></li></ol>