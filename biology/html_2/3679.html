<body>
            <h1>HoSeIn: A Workflow for Integrating Various Homology Search Results from Metagenomic and Metatranscriptomic Sequence Datasets</h1>
            <p><strong>Authors:</strong> Gaston Rozadilla, Jorgelina  Moreiras Clemente, Christina B. McCarthy</p>
            <h2>Abstract</h2>
            <p>Data generated by metagenomic and metatranscriptomic experiments is both enormous and inherently noisy. When using taxonomy-dependent alignment-based methods to classify and label reads, the first step consists in performing homology searches against sequence databases. To obtain the most information from the samples, nucleotide sequences are usually compared to various databases (nucleotide and protein) using local sequence aligners such as BLASTN and BLASTX. Nevertheless, the analysis and integration of these results can be problematic because the outputs from these searches usually show inconsistencies, which can be notorious when working with RNA-seq. Moreover, and to the best of our knowledge, existing tools do not criss-cross and integrate information from the different homology searches, but provide the results of each analysis separately. We developed the HoSeIn workflow to intersect the information from these homology searches, and then determine the taxonomic and functional profile of the sample using this integrated information. The workflow is based on the assumption that the sequences that correspond to a certain taxon are composed of:<br/>1)sequences that were assigned to the same taxon by both homology searches;<br/>2)sequences that were assigned to that taxon by one of the homology searches but returned no hits in the other one.</p>
            <p><strong>Keywords:</strong> Metagenomics, Metatranscriptomics, Next Generation Sequencing, Homology Search, Taxonomic Profile, Functional Profile</p>
            <h2>Background</h2><p>The microbiome can be characterised and its potential function inferred using metagenomics, whereas metatranscriptomics provides a snapshot of the active functional (and taxonomic) profile of the microbial community by analysing the collection of expressed RNAs through high-throughput sequencing of the corresponding cDNAs (Marchesi and Ravel, 2015). Data generated by metagenomic and metatranscriptomic experiments is both enormous and inherently noisy (Wooley <em>et al.</em>, 2010). The pipelines used to analyse this kind of data normally include three main steps: (1) pre-processing and (2) processing of the reads, and (3) downstream analyses (Aguiar-Pulido <em>et al.</em>, 2016). Pre-processing mainly involves removing adapters, filtering by quality and length, and preparing data for subsequent analysis (Aguiar-Pulido <em>et al.</em>, 2016). After pre-processing the reads, the next step (processing) consists in classifying each read according to the organism with the highest probability of being the origin of that read. This classification and labelling can be either taxonomy-dependent or independent. Taxonomy-dependent methods use reference databases, and these can be further classified as alignment-based, composition-based, or hybrid. Alignment-based methods usually give the highest accuracy but are limited by the reference database and the alignment parameters used, and are generally computation and memory intensive. Composition-based methods have not yet achieved the accuracy of alignment-based approaches, but require fewer computational resources because they use compact models instead of whole genomes (Aguiar-Pulido <em>et al.</em>, 2016). Taxonomy-independent methods do not require <em>a priori</em> knowledge because they separate reads based on certain properties (distance, k-mers, abundance levels, and frequencies) (Aguiar-Pulido <em>et al.</em>, 2016).<br/> <br/>Once the reads have been classified or labelled as best as possible, downstream analyses (step 3) attempt to extract useful knowledge from the data, such as the potential (metagenomics) or active (metatranscriptomics) functional profile. There are various useful resources for the functional annotation of the genes to which the reads are mapped, such as functional databasesâgene ontology (GO) (Ashburner <em>et al.</em>, 2000; Blake <em>et al.</em>, 2015), Kyoto Encyclopaedia of Genes and Genomes (KEGG) (Ogata <em>et al.</em>, 1999; Kotera <em>et al.</em>, 2015), Clusters of Orthologous Groups (COG) (Tatusov, 2000), InterPRO (Finn <em>et al.</em>, 2017), SPARCLE (Marchler-Bauer <em>et al.</em>, 2017), and SEED (Overbeek <em>et al.</em>, 2014)âand other tools that can also be used to obtain functional profiles. Among the latter, some are web-based, such as MG-RAST (Glass and Meyer, 2011) and IMG/M (Markowitz <em>et al.</em>, 2012), and others are standalone programs, like MEGAN (Huson <em>et al.</em>, 2007). MEGAN uses the NCBI taxonomy to classify the results from the homology searches, and uses reference InterPRO (Finn <em>et al.</em>, 2017), EggNOG (Powell <em>et al.</em>, 2012), KEGG (Ogata <em>et al.</em>, 1999) and SEED (Overbeek <em>et al.</em>, 2014) databases to perform functional assignment.<br/> <br/>The same suite of tools can be used to perform taxonomic assignments of metagenomic and metatranscriptomic data. Nevertheless, in both cases the same limitations are encountered, including algorithms that have to process large volumes of data (short reads), and the paucity of reference sequences in the databases. Additionally, most of these tools only use a subset of available genomes or focus on certain organisms, and many do not include eukaryotes. On the other hand, there are major differences in how each workflow determines the taxonomic profile, because some perform searches against protein databases, whereas others do so in a nucleotide space (a review can be found in Shakya <em>et al.</em>, 2019). Our HoSeIn workflow (from <em><u>Ho</u></em>mology <em><u>Se</u></em>arch <em><u>In</u></em>tegration) centres on the processing and downstream analyses steps, and we developed it for using with taxonomy-dependent alignment-based methods (Video 1). As we already mentioned, the latter use homology searches against sequence databases as the first step to classify and label reads. To obtain as much information as possible from the samples, the nucleotide datasets are compared to nucleotide and protein databases using local sequence aligners such as BLAST (Altschul <em>et al.</em>, 1990) or FASTA (Pearson, 2004). Nevertheless, once the homology searches are complete, the analysis and integration of these results can be problematic because the outputs from these searches usually show differences and inconsistencies, which can be particularly notorious when working with RNA-seq (Video 1 and Figure 1). On one hand, amino acid- based searches can detect organisms distantly related to those in the reference database but are prone to false discovery. In contrast, nucleotide searches are more specific but are unable to identify insufficiently conserved sequences. Consequently, taxonomic and functional profiles should be carefully interpreted when they are assigned using one or the other. For example, assignments using searches against nucleotide databases, especially for protein coding genes, are likely to be less effective if no near neighbours exist in the reference databases. In this respect, and to the best of our knowledge, existing tools do not intersect information from the different homology searches to integrate the different results, but provide the results of each analysis separately. We developed the HoSeIn workflow to criss-cross the information from both homology search results (nucleotide and protein) and then perform final assignments on the basis of this integrated information. Sequences are assigned to a certain taxon if they were assigned to that taxon by both homology searches, and if they were assigned to that taxon by one of the homology searches but returned no hits in the other one (Video 1 and Figure 1). Specifically, our workflow extracts all the available information for each sequence from the different tools that were used to process the dataset (homology searches and whatever method was used to classify and label the sequences, for example MEGAN [Huson <em>et al.</em>, 2007]), and uses it to build a local database. The data for each sequence is then intersected to define the taxonomic profile of the sample following the above-mentioned criteria. Consequently, the main novelty of our workflow is that final assignments integrate results from both homology searches, capitalising on their strengths and thus making them more robust and reliable (Video 1). For metatranscriptomics in particular, where results are difficult to interpret, this represents a very useful tool.</p>
        </body>

<p class="ppzz"><br/><!--video3679-1å¼å§--></p><div class="videodiv" id="vd3679-1" style="height:480px;"></div><div class="videophoto" id="vp3679-1"><a class="newapic" href="javascript:;" onclick="openvideo(1)" style="background:url('https://en-cdn.bio-protocol.org/video/3679/3679-1s.jpg') no-repeat center center #000 !important;"> <img class="videopic" src="https://en-cdn.bio-protocol.org/imagesUP/indexCover/videopalybtn.png" style="cursor:pointer !important;"/> </a> </div><div class="videostrong"><strong>Video 1. <em><u>Ho</u></em>mology <em><u>Se</u></em>arch <em><u>In</u></em>tegration (HoSeIn) workflow abstract video:</strong> This 6 min teaser gives a quick overview of the background context and <em>modus operandi</em> of the HoSeIn workflow.</div><!--video3679-1ç»æ--><br/><p><br/></p><img alt="" class="layerphoto" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200712/20200712224630_0073.jpg" width="300"/> <br/><p class="ppzz"><strong>Figure 1. Rationale behind the HoSeIn workflow.</strong> A. There are various methods for determining the taxonomic profile of a microbiome in a sequencing-based analysis, and these can be taxonomy dependent or independent (see text for details). B. When using taxonomy-dependent alignment-based methods to analyse metagenomic or metatranscriptomic datasets (1), these are usually compared to nucleotide and protein databases using local sequence aligners such as BLAST (Altschul <em>et al.</em>, 1990) or FASTA (Pearson, 2004) (2). Nevertheless, the analysis and integration of these results can be problematic because the outputs from these searches usually show inconsistencies (3). C. The HoSeIn workflow intersects the information from both homology search results and final assignments are determined on the basis of this integrated information. In this way, sequences are assigned to a certain taxon if they were assigned to that taxon by both homology searches (1), and if they were assigned to that taxon by one of the homology searches but returned no hits in the other one (2 and 3).</p><p class="pptt" id="biaoti34709">### Equipment</p><ol class="npwtwok"><li>Desktop computer with an Intel Core i7 2600 processor (3,40 Ghz, 8 Mb, 4 Cores, 8 Threads, video and Turboboost); Intel DH67BL Motherboard, LGA 1155 socket; with 7.1 + 2 sound; 1 Gb network; RAID 0,1,5 y 10; and four Kingston 1.333 Mhz DDR3 4 GB memories</li></ol><p class="pptt" id="biaoti34710">### Software</p><ol class="npwtwok"><li>Ubuntu 18.04.3 LTS (Ubuntu, <a href="https://ubuntu.com/#download" target="_blank">https://ubuntu.com/#download</a>), last accessed on 11/9/2019 </li><li>BLAST (<a href="ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/" target="_blank">ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/</a>), blast-2.2.25+ last accessed 2/7/2013<br/><em>Note: FASTA programs (FASTA DNA:DNA and FASTX) can also be used for the homology searches. Nevertheless, BLAST and FASTA programs represent a major computational bottleneck when aligning high-throughput datasets against protein databases, and different tools have recently been developed to improve performance. In particular, DIAMOND is an open-source sequence aligner for protein and translated DNA searches which performs at 500x-20,000x the speed of BLAST, is suitable for running on standard desktops and laptops, and offers various output formats as well as taxonomic classification (Buchfink et al., 2015). Thus, when aligning large datasets against protein databases with limited computational resources, we recommend using Diamond.</em> </li><li>MEGAN6 (<a href="http://ab.inf.uni-tuebingen.de/software/megan6/" target="_blank">http://ab.inf.uni-tuebingen.de/software/megan6/</a>); MEGAN_Community_windows-x64_6_17_0 version last accessed on 18/9/2019<br/>In this tutorial MEGAN is used to process the homology search output files and then extract the taxonomic and functional information. For downloading and installing this software:<br/><ol class="npwthree"><li>Go to the MEGAN website (<a href="http://ab.inf.uni-tuebingen.de/software/megan6/" target="_blank">http://ab.inf.uni-tuebingen.de/software/megan6</a>) and download the MEGAN6 version that matches your Operating System, as well as the corresponding mapping files<br/></li><li>Run the installer</li></ol></li><li>DB Browser for SQLite (DB4S) (<a href="https://sqlitebrowser.org/" target="_blank">https://sqlitebrowser.org/</a>); DB.Browser.for.SQLite-3.11.2-win64 version last accessed on 5/9/2019<br/>DB Browser for SQLite (DB4S) is a high quality, visual, open source tool used to create, design, and edit database files compatible with SQLite. It uses a familiar spreadsheet-like interface, and does not require learning complicated SQL commands. In our workflow we use DB4S to create a local database that includes all the available information for each sequence from the dataset. All this data is then used to define the taxonomic and functional profile of the sample. For downloading and installing this software:<br/><ol class="npwthree"><li>Download the DB4S version that matches your Operating System from the website (<a href="https://sqlitebrowser.org/" target="_blank">https://sqlitebrowser.org/</a>)<br/></li><li>Run the installer</li></ol></li></ol><p class="pptt" id="biaoti34711">### Procedure</p><p class="ppzz"><em>Note: This tutorial describes the global procedure for analysing high-throughput metatranscriptomic sequences from an environmental sample, and focuses on how to define its taxonomic and functional profile in a robust and reliable way.</em><br/>  It does not include a detailed description of the pre-processing of high-throughput sequences obtained from an environmental sample (for this, see Kim <em>et al.</em>, 2013; Aguiar-Pulido <em>et al.</em>, 2016), nor on how to use MEGAN (for this, see Huson <em>et al.</em> [2007 and 2011] and the MEGAN user manual).<br/>  Below we provide a detailed tutorial to show how HoSeIn works, exemplifying with one of our samples, a sequence dataset obtained from the gut of a lepidopteran larva. The analysis of the metatranscriptomic part of this dataset was recently accepted for publication (Rozadilla <em>et al.</em>, 2020). As this type of analysis is often dictated by the goals of the experiment (Shakya <em>et al.</em>, 2019), a few remarks follow to explain certain distinctive features of this particular sample and its subsequent analysis. <em>Spodoptera frugiperda</em> (Lepidoptera: Noctuidae) is an economically important agricultural pest native to the American continent. The purpose for analysing this pest was to describe the taxonomic and functional profile of the larval gut transcriptome and associated metatranscriptome to identify new pest control targets. For this, total RNA was extracted from fifth instar larval guts, submitted to a one-step reverse transcription and PCR sequence-independent amplification procedure, and then pyrosequenced (McCarthy <em>et al.</em>, 2015); the high-throughput reads were later assembled into contigs (Rozadilla <em>et al.</em>, 2020). As we were interested in identifying, differentiating and characterising both the host (<em>S. frugiperda</em>) gut transcriptome and its associated metatranscriptome, we downloaded the following NCBI databases to perform the homology searches locally (<a href="ftp://ftp.ncbi.nlm.nih.gov/blast/db/" target="_blank">ftp://ftp.ncbi.nlm.nih.gov/blast/db/</a>) (<em>download_db.mp4</em>, a video tutorial that shows how to download different types of database files from NCBI, and <em>download_db.sh</em>, a bash script that automatically downloads these database files one by one, are provided as <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 1.zip" target="_blank">Supplementary Material 1</a>):</p><div class="media media-x cnautokh cnautokh1"><div class="float-left">1)</div><div class="media-body">Nucleotide:<br/><p class="ppzz" style="margin-top:-0.5px;">ââNon-redundantâ nucleotide sequence (nt)</p><p class="ppzz" style="margin-top:-0.5px;">â16S rRNA gene (16S)</p><p class="ppzz" style="margin-top:-0.5px;">âLepidopteran whole genome shotgun (Lep) projects completed at the time of the analysis.</p><p class="ppzz" style="margin-top:-0.5px;">Sequences from nt, 16S and Lep, were then combined in a single database (DB:nt16SLep) using the appropriate BLAST+ applications (<a href="ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/" target="_blank">ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/</a>) (<em>blast_tutorial.mp4</em>, a video tutorial that shows how to build and combine different databases and how to run a homology search locally with BLAST, and <em>blast_commands.txt</em>, which contains the commands used in the tutorial, are provided as <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 2.zip" target="_blank">Supplementary Material 2</a>). The Lep sequences in the combined nucleotide database simplified the identification of host sequences (which represented the majority), and the nt and 16S databases enabled the identification of the associated metatranscriptome (and of host sequences).</p></div></div><div class="media media-x cnautokh cnautokh2"><div class="float-left">2)</div><div class="media-body">Protein:<br/><p class="ppzz" style="margin-top:-0.5px;">ânon-redundant protein sequence (nr)</p><br/></div></div>Below follows an outline of the main steps included in our workflow (Figure 2; see the tutorial for details):<br/><ol class="npwfour"><li><u>Analyse sequences with local sequence aligners</u>: Contigs are compared locally to the combined nucleotide database (nt16SLep) using BLASTN (Altschul <em>et al.</em>, 1990) with a 1e-50 cutoff E-value, and to the protein database (nr) using BLASTX (Altschul <em>et al.</em>, 1990) with a 1e-17 cutoff E-value (<a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 2.zip" target="_blank">Supplementary Material 2</a>).<br/><em>Note: Here we use BLASTX because the dataset we are querying is small (the aforementioned assembled reads, namely 737 contigs); but for large datasets and limited computational resources we recommend using Diamond (Buchfink </em><em>et al.</em><em>, 2015).</em><br/></li><li><u>Process the homology search results:</u><br/><strong>S</strong><strong>tep A</strong> (the <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step A.zip" target="_blank"><em>stepA.mp4</em></a> video tutorial guides you through step-by-step): The output files from both homology searches are then processed with MEGAN, a software which performs taxonomic binning and assigns sequences to taxa using the Lowest Common Ancestor (LCA)-assignment algorithm (Huson <em>et al.</em>, 2007). Taxonomic and functional assignments performed by MEGAN for each contig are then exported using a MEGAN functionality.<br/><em>Note: MEGAN computes a âspecies profileâ by finding the lowest node in the NCBI taxonomy that encompasses the set of hit taxa and assigns the sequence to the taxon represented by that lowest node. With this approach, every sequence is assigned to some taxon; if the sequence aligns very specifically only to a single taxon, then it is assigned to that taxon; the less specifically a sequence hits taxa, the higher up in the taxonomy it is placed (see the âMEGAN User Manualâ for a detailed explanation). We chose MEGAN because this software uses the LCA-assignment algorithm and has a straightforward functionality for exporting the taxonomic and functional information for each sequence from the dataset (i.e., the âspecies profileâ for each sequence can easily be accessed and downloaded). Nevertheless, any other tool or platform that provides this same functionality (i.e.,</em><em> exporting the taxonomic/functional assignment for each sequence from the dataset) can also be used.</em><br/><strong>Step B</strong> (the <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step B.zip" target="_blank"><em>stepB.mp4</em></a> video tutorial guides you through step-by-step): The output files from both homology searches are also processed with a custom bash script. This script parses the homology search output files and generates two files (one for each homology search) containing the name of each contig, its best hit (or no hit) and the corresponding E-value.<br/></li><li><u>Create local databas</u><u>e</u>: <strong>Step C</strong> (the <em>stepC.mp4</em> video tutorial found in <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step C.zip" target="_blank">Supplementary Material Step C</a> guides you through step-by-step): All this information (from the exported MEGAN files and from the bash script output files) is then used to create a local SQLite database which includes all the available information for each contig (from both homology searches).</li><li><u>Analyse the local database</u>: <strong>Step D</strong> (the <em>stepD.mp4</em> video tutorial found in <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step D.zip" target="_blank">Supplementary Material Step D</a> guides you through step-by-step): Final taxonomic assignments are then performed by criss-crossing and comparing all this information using different SQLite commands. <strong>Step E</strong> (the <em>stepE.mp4</em> video tutorial found in <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step E.zip" target="_blank">Supplementary Material Step E</a> guides you through step-by-step): Transcript assignment is achieved by executing certain SQLite commands to group transcripts that correspond to mRNA, rRNA, those that cannot be assigned (not assigned), and those that have to be revised manually (Revise). <strong>Step F</strong> (the <em>stepF.mp4</em> video tutorial found in <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step F.zip" target="_blank">Supplementary Material Step F</a> guides you through step-by-step): Finally, functional assignments of transcripts that were classified by the functional databases are integrated in a single column by executing certain SQLite commands. Only transcripts in the âmRNAâ and âReviseâ categories can putatively be classified by the functional databases, but because the information in these reference databases is still considerably limited, only around a third of these are assigned a function. Functional assignment of the rest of these transcripts can be done manually on the basis of the homology search results (which are included in the local SQLite database) (see <em>Data analysis</em>).<br/><br/><img alt="" class="layerphoto" height="450" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200712/20200712234708_1870.jpg" width="300"/><br/><strong>Figure 2. HoSeIn (<em><u>Ho</u></em>mology <em><u>Se</u></em>arch <em><u>I</u></em><em><u>n</u></em>tegration) workflow.</strong> This figure shows an overview of the main steps that make up the workflow (see the tutorial for details): <u>I. Analyse sequences with local sequence aligners</u>: Sequences are submitted to homology searches against nucleotide (nt16SLep) and protein (nr) databases. <u>I</u><u>I. Process results</u>: Results from both homology searches are processed with MEGAN and with a custom bash script. <strong>Step A</strong>: Files containing the MEGAN taxonomic and functional assignments are exported using a MEGAN functionality. <strong>Step B</strong>: The custom bash script generates files containing the name of each sequence, its best hit (or no hit) and the corresponding E-value, for both homology searches. <u>III. Create local database</u>: <strong>Step C</strong>: The MEGAN and bash script files are then used to create a local SQLite database which includes all available data for each sequence. <u>IV. Analyse local database</u>: Final taxonomic and functional assignments are then performed by criss-crossing and comparing all this information using different SQLite commands. <strong>Step D</strong>: Taxonomic assignment is defined by using certain criteria and filters: 1) The âhost filterâ determines which sequences correspond to the <em>S. frugiperda</em> gut transcriptome; 2) the âE-value = 0 filterâ for nt16SLep hits, groups those unequivocal hits; 3) the âLowest Common Ancestor criterionâ for sequences with nt16SLep hits showing E-value â  0, defines the identity of the rest of the contigs by criss-crossing the results from both homology searches and retaining the lowest common ancestor assignments. <strong>Step E</strong>: Transcript assignment is achieved by searching for certain keywords in the hit description. In this way, it is possible to group transcripts that correspond to mRNA, rRNA, those that cannot be assigned (not assigned), and those that have to be revised manually (revise). Step F: Finally, functional annotation of all the sequences that correspond to mRNA (or âReviseâ) is then integrated in a single column. N.A., Not assigned.</li></ol><br/><p class="ppzz">We provide various files as Supplementary Material for the reader to be able to go through the tutorial and reproduce the same results we show below:<br/>âA FASTA file containing the assembled sequences (<em>Sf_TV_contigs.fasta</em>) and a text file (<em>coverage.csv</em>) containing the assembly information for each contig (<em>i.e.</em>, contig name, number of reads used to assemble each contig, read length and contig coverage), are provided as <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 3.zip" target="_blank">Supplementary Material 3</a>;<br/>âThe output files from both homology searches in BLAST pairwise format (<em>blastn_nt16SLep_total-contigs_Sf-TV.txt</em> and <em>blastx_nr_total-contigs_Sf-TV.txt</em>) are provided as <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 4.zip" target="_blank">Supplementary Material 4</a>;<br/>âTwo custom scripts written in bash that process the homology search results (<em>search_parser.sh and analyser_blast.sh</em>) are provided as <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 5.zip" target="_blank">Supplementary Material 5</a>;<br/>âThe "RMA" files generated by MEGAN6 after processing the homology search output files (<em>blastn_nt16sLep_total-contigs.rma6</em> and <em>b</em><em>lastx_nr_total-contigs.rma6</em>) are provided as <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 6.zip" target="_blank">Supplementary Material 6</a>;<br/>âtext files containing different commands to intersect, assign and analyse the data in the local SQLite database: <em>step_C_creating_taxonomy.txt found in </em><a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step C.zip" target="_blank"><em>Supplementary Material Step C</em></a>, <em>step_D_crisscrossing_taxonomy.txt found in </em><a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step D.zip" target="_blank"><em>Supplementary Material Step D</em></a>, <em>step_E_assigning transcripts.txt found in </em><a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step E.zip" target="_blank"><em>Supplementary Material Step E</em></a>, <em>step_F_functional_assignment.txt found in </em><a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step F.zip" target="_blank"><em>Supplementary Material Step F</em></a>, and <a href="https://os.bio-protocol.org/attached/file/20200525/analysing taxonomy.txt" target="_blank"><em>analysing_taxonomy.txt</em></a><em>.</em> </p>â<br/><strong>HoSeIn Tutorial</strong> (also see Figure 2):<br/><br/><p class="ppzz"><em>I. Analyse sequences with local sequence aligners:</em> As mentioned previously, homology searches were performed locally using BLASTN and BLASTX (Altschul <em>et al.</em>, 1990) against the combined nucleotide (nt16SLep) and protein (nr) databases with 1e-50 and 1e-17 cutoff E-values, respectively. The homology search results are found in the <em>blastn_nt16SLe</em><em>p_total-contigs_Sf-TV.txt</em> and <em>blastx_nr_total-contigs_Sf-TV.txt</em> files (<a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 4.zip" target="_blank">Supplementary Material 4</a>). The video tutorial <em>download_db.mp4</em> shows how to download different types of database files from NCBI, and the bash script <em>download_db.sh</em> automatically downloads these database files one by one (<a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 1.zip" target="_blank">Supplementary Material 1</a>). The video tutorial <em>bla</em><em>st_tutorial.mp4</em> shows how to build and combine different databases, and how to run a homology search locally with BLAST; the commands used in this video can be found in <em>blast_commands.txt</em> (<a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 2.zip" target="_blank">Supplementary Material 2</a>).<br/><em>II. Process the homology search results:</em> The output files from both homology searches were processed with MEGAN and saved as <em>blastn_nt16sLep_total-contigs.rma6</em> and <em>blastx_nr_total-contigs.rma6</em> (<a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 6.zip" target="_blank">Supplementary Material 6</a>).</p><ol class="npwone"><li>Export the taxonomic and functional assignments performed by MEGAN for both homology searches (Figures 3-9, <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step A.zip" target="_blank"><em>S</em><em>tepA.mp</em><em>4</em></a> video tutorial and <a href="https://os.bio-protocol.org/attached/file/20200616/3679 Supplementary Figures.docx" target="_blank">Supplementary Figure S1</a>):<ol class="npwtwo"><li>Use MEGAN to open the provided RMA files (<em>blastn_nt16sLep_total-contigs.rma6</em> and <em>blastx_nr_total-contigs.rma</em><em>6</em><em> found in </em><a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 6.zip" target="_blank"><em>Supplementary Material 6</em></a>). To open the RMA files, select File &gt; Open and then browse to the desired file (Figure 3). The main window is used to display the taxonomy and to control the program using the main menus. Once a dataset has been processed, the taxonomy induced by that dataset is shown. The size of the nodes indicates the number of sequences that have been assigned to the nodes (see âMEGAN User Manualâ for a detailed explanation).</li><li>To extract the taxonomic information from MEGAN, the taxonomic tree must be progressively expanded from Domain to species, selecting all the leaves, and extracting the text files in csv (comma-separated values) format. Choose the taxonomic level that you wish to extract (from Domain to Species): âTreeâ &gt; âRankâ (Figure 4).</li><li>To select the leaves: âSelectâ &gt; âAll Leavesâ (Figure 5).</li><li>Without deselecting the leaves, export the file to csv format: âFileâ &gt; âExportâ &gt; âCSV Formatâ (Figure 6).</li><li>Choose what data you want to export and in what way it will be tabbed in the csv file (choose âsummarizedâ so it exports the sequences contained in the chosen taxonomic level as well as all the lower levels) (Figure 7). We recommend naming the file with a representative name indicating the type of homology search and the taxonomic level, for example ânucl_domainâ. </li><li>In this way a csv text file is obtained (which can be viewed in a basic word processor such as WordPad). Each of these files has two fields, one with the sequence name and another with the corresponding assigned taxonomic level (Domain, Phylum, <em>etc.</em>) (Figure 8).</li><li>Repeat this procedure for each taxonomic level, and for the other homology search. In this way, 14 files are obtained (7 files for each homology search), each one corresponding to a particular taxonomic level (Figure 9). </li><li>The procedure for extracting the functional information is very similar (see <a href="https://os.bio-protocol.org/attached/file/20200616/3679 Supplementary Figures.docx" target="_blank">Supplementary Figure S1</a> and <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step A.zip" target="_blank"><em>StepA.mp4</em></a> video tutorial): 1) Choose the functional tree you want to visualise, <em>e.g.</em>, InterPro2GO (Figure S1A.1); 2) Uncollapse all nodes: âTreeâ &gt; âUncollapse Allâ (Figure S1A.2); 3) âSelectâ &gt; âAll Leavesâ (Figure S1A.3); 4) Without deselecting the leaves, export the file to csv format: âFileâ &gt; âExportâ &gt; âCSV Formatâ (Figure S1A.4); 5) Choose what data will be exported: âreadName_to_interpro2goPathâ (Figure S1A.5). Repeat the procedure for all the functional trees you want to include in the final analysis; for this tutorial we also exported the EggNOG assignments (Figure S1B).<br/><br/><img alt="" class="layerphoto" height="484" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235518_5021.jpg" width="300"/><br/><strong>Figure 3. Opening the provided .rma6 files in MEGAN.</strong> A. Select âOpenâ from the âFileâ leaf (red rectangle). B. Select one of the provided .rma6 files from the location where you saved it (<em>blastn_nt16sLep_total-contigs.rma6</em> was selected here; red rectangle). C. Appearance of <em>blastn_nt16sLep_total-contigs.rma6</em> collapsed to âspeciesâ taxonomic rank.<br/><br/><img alt="" class="layerphoto" height="319" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235546_6152.jpg" width="300"/><br/><strong>Figure 4. Selecting a taxonomic rank.</strong> A. Select âRankâ from the âTreeâ leaf (red rectangle). B. Tick the desired rank from the dropdown menu (the red arrow indicates that âDomainâ was selected here).<br/><br/><img alt="" class="layerphoto" height="161" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235622_6264.jpg" width="300"/><br/><strong>Figure 5. Selecting all the leaves from the chosen taxonomic rank.</strong> Select âAll Leavesâ from the âSelectâ leaf (red rectangle).<br/><br/><img alt="" class="layerphoto" height="161" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235653_7241.jpg" width="300"/><br/><strong>Figure 6. Exporting in csv format.</strong> Select âExportâ from the âFileâ leaf, and choose âText (CSV) formatâ from the dropdown menu (red rectangle).<br/><br/><img alt="" class="layerphoto" height="161" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235730_8298.jpg" width="300"/><br/><strong>Figure 7. Selecting the way in which data will be exported.</strong> Select âreadName_to_taxonNameâ from the âChoose data to exportâ dropdown menu, âsummarizedâ from the âChoose count to useâ dropdown menu, and âtabâ from the âChoose separator to useâ dropdown menu (red rectangle).<br/><br/><img alt="" class="layerphoto" height="298" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235801_8461.jpg" width="300"/><br/><strong>Figure 8. Partial view of the exported ânucl_domain.csvâ file.</strong> The first column contains the sequence name (<em>e.g.</em>, Contig479), and the second column the taxonomic rank assigned to each sequence (in this figure âDomainâ, <em>e.g.</em>, âBacteriaâ).<br/><br/><img alt="" class="layerphoto" height="279" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200712/20200712235842_3357.jpg" width="300"/><br/><strong>Figure 9. Exported MEGAN files.</strong> Folder containing all 14 files exported from MEGAN, named according to the corresponding homology search and taxonomic level (red rectangle).<br/><br/></li></ol></li><li>Parse the output files from the homology searches (Figure 10 and Supplementary Material <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step B.zip" target="_blank"><em>stepB.mp4</em></a> video tutorial):<br/>This step must be carried out in a Linux Operating System because the scripts that parse the homology search results were written in bash. The scripts process the FASTA file (containing the query sequences) and the homology search output files:<br/><ol class="npwtwo"><li>The provided scripts (<em>search_parser.sh</em> and <em><em>analyser_b</em><em>last.sh</em></em><em> from </em><a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 5.zip" target="_blank"><em>Supplementary Material 5</em></a>), FASTA file (<em>Sf_TV_contigs.fasta from </em><a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 3.zip" target="_blank"><em>Supplementary Material 3</em></a>) and output files from the homology searches (<em>blastn_nt16SLep_total-contigs_Sf-TV.txt</em> and <em>blastx_nr_total-contigs_Sf-TV.txt from </em><a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 4.zip" target="_blank"><em>Supplementary Material 4</em></a>), must all be placed in the same folder (Figure 10A).</li><li>Of the two bash scripts we provide, only execute <em>search_p</em><em>arser.sh</em>. This script works by executing various <em>analyser_blast.sh</em> scripts simultaneously to speed up the process. Open a terminal in the same folder that contains the files and execute the <em>search_parser.sh</em> bash script strictly in the following order (also see example below and Figures 10B-10C):<br/><em>ba</em><em>sh</em> <em>s</em><em>earch_par</em><em>ser.sh</em><em> (name and file extension of the query fasta) (name and file extension of the homology search result) (chosen name and file extension for the output file)</em><br/><br/>bash search_parser.sh Sf_TV_contigs.fasta blastn_nt16Slep_total-contigs.txt nucl_hits.csv<br/><br/><img alt="" class="layerphoto" height="240" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000030_9931.jpg" width="300"/><br/><strong>Figure 10. Using the bash script.</strong> A. The pale blue rectangle indicates the folder containing all the necessary files for the scripts to work correctly. B. The red rectangle indicates how to execute the script to process the BLASTN output file (homology search against the nucleotide database). C. The image shows the messages that appear in the terminal after processing the output files from the BLASTN homology search (1 and 2) and from the BLASTX homology search (3 and 4).<br/><br/></li><li>The script generates a csv file with three fields separated by â%â: the first one shows the name of each sequence, the second shows its best hit (or nothing if there is no hit), and the third its corresponding E-value (or nothing if there is no hit) (Figure 11).<br/><br/><img alt="" class="layerphoto" height="175" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000052_0223.jpg" width="300"/><br/><strong>Figure 11. Partial images of the csv files generated by the script.</strong> Files showing the listed BLASTN (A) and BLASTX hits (B). In both files, fields showing the sequence name, its best hit and the corresponding E-value, are separated by â%â.<br/><br/></li></ol></li><li>Create the database in DB4S (Figures 12-18, and <em>step_C_creating_taxonomy.txt</em> and <em>stepC.mp4 </em>video tutorial found in <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step C.zip" target="_blank">Supplementary Material Step C</a>):<br/>The file containing all the information for the assembled reads (<em>coverage.csv</em> found in <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Material 3.zip" target="_blank">Supplementary Material 3</a>; includes contig name, number of reads used to assemble each contig, read length, and contig coverage), the exported MEGAN files (14 taxonomic files and 2 functional files from Step A) and the bash script output files (2 files from Step B), will now be used to create a local database with DB4S which will include all the available information for each contig (from both homology searches, BLASTN and BLASTX). To do this, first each csv file must be imported individually to DB4S: <br/><ol class="npwtwo"><li>Create a new database clicking on âNew Databaseâ and choosing where to save it (Figure 12).</li><li>Individually import the csv files that were exported from MEGAN (16 files), those that were created by the bash script (2 files), and the file containing the assembly information for the contigs (1 file): âFileâ &gt; âImportâ &gt; âTable from CSV fileâ (Figure 13).</li><li>Choose a name for the table and indicate field separator (for the files imported from MEGAN, Tab; for the files generated by the bash script, Other &gt; %) (Figure 14). Only for <em>coverage.csv</em>, check the âColumn names in first lineâ box, which will automatically give the columns their correct name (Figure 14C).</li><li>We recommend renaming table columns with representative names as indicated in Figure 15 to be able to use the commands we provide for Steps C6, D, E and F (and also to simplify interpretation of the commands and avoid mistakes). </li><li>Figure 16 shows what the list of tables should look like after renaming them.</li><li>The next step consists in integrating the information from all the imported files in a single new table, as indicated in Figures 17 and 18. The set of commands in <em>step_C_creating_taxonomy.txt</em> from <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step C.zip" target="_blank">Supplementary Material Step C</a>, creates a new table named âtaxonomyâ that unifies the columns from all the imported csv files, and adds empty columns (final_domain, final_phylum, <em>etc.</em>) to be filled with the result of the subsequent taxonomic criss-crossing (Step D). It also adds auxiliary columns âstate_taxoâ (to indicate if the contig was taxonomically assigned or not and to avoid multiple assignments; Step D), ârna_typeâ (to indicate if the transcripts correspond to mRNA or rRNA; Step E), âstate_functionâ (to indicate whether the transcripts were assigned or need to be revised; Step E), and âfunction_typeâ (to integrate the functional assignment of those transcripts that were classified by the functional databases; Step F).<br/><br/><img alt="" class="layerphoto" height="209" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000228_4545.jpg" width="300"/><br/><strong>Figure 12. Creating a new database in DB4S.</strong> A. Click on âNew Databaseâ (red arrow). B. A window will appear requesting you to choose a filename and location to save the new database (red rectangle).<br/><br/><img alt="" class="layerphoto" height="198" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000251_6866.jpg" width="300"/><br/><strong>Figure 13. Importing the csv files.</strong> A. Click on the âFileâ leaf (red arrow) and select âImportâ and âTable from CSV fileâ from the dropdown menus (red rectangle). B. Select the csv file that you want to import (ânucl_domain.txtâ in the figure; red rectangle).<br/><br/><img alt="" class="layerphoto" height="474" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000313_6720.jpg" width="300"/><br/><strong>Figure 14. Naming the imported tables.</strong> Once you have selected a csv file, a new window will appear in which you have to name the table and indicate the field separator. A. For files imported from MEGAN the field separator is âTabâ; this table was named ânucl_domainâ (red rectangle). B. For files generated by the bash script, the field separator is âOtherâ &gt; â%â; this table was named ânucl_hitâ (red rectangle). C. For the âcoverageâ file, check the âColumn names in first lineâ box (indicated by the red arrow) and choose âTabâ as field separator; the pale blue rectangle indicates the assigned column names.<br/><br/><img alt="" class="layerphoto" height="329" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000402_4148.jpg" width="300"/><br/><strong>Figure 15. Renaming table columns.</strong> A. In the main window, select the table that you want to modify with the mouseÂ´s right button, and click on âModify tableâ (red rectangle). B. A new window will open where the fields (which correspond to the column names) appear; double click on each to rename. For the tables obtained from the MEGAN files, rename âfield1â as âsequenceâ, name the table and âfield2â according to the database which was used for the homology search (nucl or prot) followed by the appropriate taxonomic rank (<em>e.g.</em>, domain); in the figure, ânucl_domainâ (red rectangles). C. The tables obtained from the files generated by the bash script have three columns: rename âfield1â as âsequenceâ; rename âfield2â as ânucl_hitâ for the BLASTN hits, and as âprot_hitâ for the BLASTX hits; rename âfield3â as ânucl_Evalueâ for the BLASTN hits, and as âprot_Evalueâ for the BLASTX hits (red rectangles). <br/><em>Note: Columns from the âcoverageâ file were named in the previous step so they do not need to be modified.</em><br/><br/><img alt="" class="layerphoto" height="181" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000429_9983.jpg" width="300"/><br/><strong>Figure 16. âDatabase Structureâ window in DB4S listing all the imported and renamed tables</strong><br/><br/><img alt="" class="layerphoto" height="119" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000512_7897.jpg" width="300"/><br/><strong>Figure 17. Unifying the information from all the imported files to create a single table.</strong> 1) In the âExecute SQLâ leaf, 2) paste the commands contained in <em>step_C_creating_taxonomy.txt</em> and 3) execute them with âPlayâ; 4) the lower panel indicates if the commands were executed successfully.<br/><br/><img alt="" class="layerphoto" height="272" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000537_0090.jpg" width="300"/><br/><strong>Figure 18. View of the âtaxonomyâ table created in the previous step.</strong> A. In the âDatabase Structureâ leaf (red arrow) a new âtaxonomyâ table will appear (red rectangle). B. To browse the new âtaxonomyâ table, select it from the dropdown menu in the âBrowse Dataâ leaf (indicated by the red arrow and rectangle); the light blue rectangle shows a partial view of the columns that were created in âtaxonomyâ.<br/><br/></li></ol></li><li>Determining the taxonomic profile (Figure 19, and <em>step_D_crisscrossing_taxonomy.txt</em> and <em>stepD.mp4</em> video tutorial found in <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step D.zip" target="_blank">Supplementary Material Step D</a>):<br/>The next step consists in intersecting all the information contained in the âtaxonomyâ table to elucidate the taxonomic profile of the sample, based on the following criteria:<br/><ol class="npwtwo"><li>Contigs that were assigned to Arthropoda in at least one of the homology searches are assigned to the host transcriptome.</li><li>Contigs that have hits with E-value = 0 in the nt16SLep search, are directly assigned to that taxon.</li><li>The rest of the contigs are assigned by comparing the MEGAN assignments from both homology searches according to the LCA logic; <em>i.e.</em>, the level of taxonomic assignment for a contig is the one found in common for both results, or for the only result if it returns no hits in the other homology search.</li><li>Contigs that were not assigned to any taxon by MEGAN in any of the homology searches are considered as ânot assignedâ; contigs that returned no hits in both homology searches are considered as âno hitsâ.<br/>These assignments are carried out by executing the commands in <em>step_D_crisscrossing_taxonomy.txt</em> in DB4S (Figure 19 and <em>stepD.mp4</em> video tutorial from <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step D.zip" target="_blank">Supplementary Material Step D</a>).<br/><br/><img alt="" class="layerphoto" height="271" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000647_3771.jpg" width="300"/><br/><strong>Figure 19. Determining final taxonomic assignments in the âtaxonomyâ table.</strong> A. To perform these assignments: 1) in the âExecute SQLâ leaf, 2) paste the commands contained in <em>step_D_crisscrossing_taxonomy.txt</em> and 3) execute them with âPlayâ; 4) the lower panel indicates if the commands were executed successfully. B. To view the updated âtaxonomyâ table, select it from the dropdown menu in the âBrowse Dataâ leaf (indicated by the red arrow and rectangle); the light blue rectangle indicates the columns with the final taxonomic assignments after criss-crossing the taxonomic information from both homology searches (final_domain, final_phylum, <em>etc.</em>).<br/><br/></li></ol></li><li>Classifying the transcripts (Figure 20, and <em>step_E_assigning transcripts.txt</em> and <em>stepE.mp4</em> video tutorial found in <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step E.zip" target="_blank">Supplementary Material Step E</a>):<br/>As this sample was obtained from total RNA, the sequences can be further classified as either messenger or ribosomal RNA using the information contained in the hit description from the homology searches (ânucl_hitâ and âprot_hitâ columns), based on the following criteria:<br/><ol class="npwtwo"><li>Contigs are assigned to mRNA if they show the word âmRNAâ in the ânucl_hitâ column.</li><li>Contigs are assigned to rRNA if they show the words ârRNA/ribosomal RNAâ in the ânucl_hitâ column.</li><li>Contigs are considered as functionally âNot assignedâ if they show the words "genome/chromosome/scaffold/contig" or "uncharacterized/hypothetical/unknown/ncRNA" in the ânucl_hitâ and âprot_hitâ columns, respectively.</li><li>All the rest of the contigs are included in a âReviseâ category to be manually revised.<br/>These assignments are carried out by executing the commands found in <em>step_E_assigning transcripts.txt</em> in DB4S (Figure 20 and <em>stepE.mp4</em> video tutorial from <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step E.zip" target="_blank">Supplementary Material Step E</a>).<br/><br/><img alt="" class="layerphoto" height="285" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000755_3615.jpg" width="300"/><br/><strong>Figure 20. Determining transcript assignments in the âtaxonomyâ table.</strong> A. To perform these assignments: 1) in the âExecute SQLâ leaf, 2) paste the commands contained in <em>step_E_assigning transcripts.txt</em> and 3) execute them with âPlayâ; 4) the lower panel indicates if the commands were executed successfully. B. To view the updated âtaxonomyâ table, select it from the dropdown menu in the âBrowse Dataâ leaf (indicated by the red arrow and rectangle); the light blue rectangle indicates the columns with the final transcript assignments: ârna_typeâ and âstate_functionâ. The ârna_typeâ column indicates what category the transcript was assigned to (<em>i.</em><em>e.</em>, âmRNAâ, ârRNAâ, âNot assignedâ or âReviseâ). An âAssignedâ status in the âstate_functionâ column appears when the transcripts are assigned to either âmRNAâ, ârRNAâ or âNot assignedâ; if the transcript was included in a âReviseâ category, it is âNULLâ.<br/><br/></li></ol></li><li>Functional assignment (Figure 21, and <em>step_F_functional assignment.txt</em> and <em>s</em><em>tepF.mp4</em> video tutorial found in <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step F.zip" target="_blank">Supplementary Material Step F</a>):<br/>This step integrates all the functional assignments of those transcripts that were classified by the functional databases in a single column (âfunction_typeâ). This is done by executing the commands found in <em>step_F_functional assignment.txt</em> in DB4S (Figure 21 and <em>stepF.mp4</em> video tutorial from <a href="https://os.bio-protocol.org/attached/file/20200525/Supplementary Step F.zip" target="_blank">Supplementary Material Step F</a>). As can be deduced from the previous step, only transcripts in the âmRNAâ and âReviseâ categories can putatively be classified by the functional databases. Nevertheless, only about a third are assigned a function because the information in these reference databases is still considerably limited (see âData analysisâ).<br/><br/><img alt="" class="layerphoto" height="321" loading="lazy" src="https://en-cdn.bio-protocol.org/attached/image/20200713/20200713000956_4823.jpg" width="300"/><br/><strong>Figure 21. Integrating functional assignments in the âtaxonomyâ table.</strong> A. 1) in the âExecute SQLâ leaf, 2) paste the commands contained in <em>step_F_functional assignment.txt</em> and 3) execute them with âPlayâ; 4) the lower panel indicates if the commands were executed successfully. B. To view the updated âtaxonomyâ table, select it from the dropdown menu in the âBrowse Dataâ leaf (indicated by the red arrow and rectangle); the light blue rectangle indicates the âfunction_typeâ column showing the integrated functional assignments. Transcripts that were not classified by the functional databases appear as âNULLâ.</li></ol><p class="pptt" id="biaoti34712">### Data analysis</p><p class="ppzz"><strong>Browsing the âtaxonomyâ table</strong> (<a href="https://os.bio-protocol.org/attached/file/20200616/3679 Supplementary Figures.docx" target="_blank">Supplementary Figures S2-S5</a> and <a href="https://os.bio-protocol.org/attached/file/20200525/analysing taxonomy.txt" target="_blank"><em>analysing_taxonomy.txt</em></a>):<br/>    We are finally ready to browse and analyse the updated âtaxonomyâ table in the âBrowse Dataâ leaf. One or more filters can be applied to facilitate data analysis. Further, some commands can be executed to visualise, for example, the taxonomic distribution of the sample (Supplementary Figure S2), the distribution by transcript type (<a href="https://os.bio-protocol.org/attached/file/20200616/3679 Supplementary Figures.docx" target="_blank">Supplementary Figure S3</a>), or a non-redundant list of the hits obtained in the homology searches (<a href="https://os.bio-protocol.org/attached/file/20200616/3679 Supplementary Figures.docx" target="_blank">Supplementary Figure S4</a>).<br/>    To analyse the functional profile in more detail, all the âmRNAâ and âReviseâ transcripts that were classified by the functional databases, and those that were not, can be listed (<a href="https://os.bio-protocol.org/attached/file/20200616/3679 Supplementary Figures.docx" target="_blank">Supplementary Figure S5</a>). As we mentioned before, because the reference databases are not comprehensive, we found that only around 30% of all the transcripts that could putatively be classified by the functional databases (âmRNAâ and âReviseâ categories), were actually classified (49 contigs; Supplementary Figure S5A). To determine the functional profile of the remaining 70% (122 contigs; Supplementary Figure S5B), functional assignment of these transcripts can be determined individually on the basis of the homology search results and then entered manually in the database. To determine an order of priorities and help reduce this considerable workload, contigs can be viewed according to coverage (Supplementary Figure S5B).<br/>    All these commands are included in <a href="https://os.bio-protocol.org/attached/file/20200525/analysing taxonomy.txt" target="_blank"><em>analysing_taxonomy.txt</em></a> and can be adapted to cover other interests.</p><p class="pptt" id="biaoti34713">### Notes</p><ol class="npwtwok"><li>Due to a question of file size we exemplified the use of our workflow with the assembled reads (737 contigs), but we have also used HoSeIn to analyse our reads (~300,000) and it works seamlessly.</li><li>This workflow was originally developed to analyse high-throughput metatranscriptomic sequences, but we have also used it to analyse high-throughput metagenomic sequences. Moreover, we validated our workflow by analysing a mock metagenome (BMock12) (Sevim <em>et al.</em>, 2019) and comparing the results we obtained with those reported for the synthetic metagenome (Sevim <em>et al.</em>, 2019). This validation was included in the study in which we presented the analysis of the dataset used for this tutorial, which was recently accepted for publication (Rozadilla <em>et al.</em>, 2020), and is included here as a Supplementary Analysis (<a href="https://os.bio-protocol.org/attached/file/20200330/Supplementary Analysis mock metagenome.docx" target="_blank"><em>Supplementary Analysis_mock metagenome.docx</em></a>). In summary, we contrasted our results with those reported by Sevim <em>et al.</em> (2019) (<a href="https://os.bio-protocol.org/attached/file/20200616/Supplementary Table S1.docx" target="_blank">Table S1</a>) and found that our workflow not only identified all the members of the mock metagenome, but also that the number of contigs that we identified per community member was greater (or the same, but never lower) than what the authors reported (<a href="https://os.bio-protocol.org/attached/file/20200616/Supplementary Table S1.docx" target="_blank">Table S1</a>). In conclusion, our workflow enabled us to identify all the community members of the mock metagenome with greater sensitivity than what was previously reported.</li><li>Even though our workflow has quite a few manual steps, these are comparable to the number of steps used by taxonomy-dependent alignment-based methods to classify and label reads from metatranscriptomic/metagenomic datasets. There are bioinformatic workflows for metatranscriptomic datasets which aim to streamline some of this complexity by connecting multiple individual tools into a workflow that can take raw sequencing reads, process them and provide data files with taxonomic identities, functional genes, and/or differentially expressed transcripts (Shakya <em>et al.</em>, 2019). Nevertheless, to define the taxonomic and functional assignments, these platforms perform their sequence-based searches against either protein or nucleotide databases, not both (Shakya <em>et al.</em>, 2019). As has already been mentioned, searches against protein databases enable the detection of distantly related organisms but are liable to false discovery, whereas searches against nucleotide databases are more specific but are unable to identify insufficiently conserved sequences. For this reason, analyses of metatranscriptomes using these streamlined workflows must be carefully interpreted. Another major drawback is that several of these workflows assign taxonomy by searching against databases that are designed for functional characterisation (Shakya <em>et al.</em>, 2019).</li><li>Summary of the unique innovations in the HoSeIn workflow:<br/><ol class="npwthree"><li>All the available information for each sequence is assembled and integrated in a local database, from both homology searches and from whatever method was used to classify and label the sequences, and it can be easily viewed and analysed. <br/></li><li>The taxonomic profile of the sample is defined by comparing the taxonomic assignments from both homology searches for each sequence following the LCA logic; <em>i.e.</em>, the taxonomic assignment level of a sequence is the one found in common for both homology search results, or for the only result if it returns no hits in the other homology search.<br/></li><li>Consequently, the novelty of our workflow is that final assignments integrate results from both homology searches, capitalising on their strengths, and thus making them more robust and reliable. For metatranscriptomics in particular, where results are difficult to interpret, this represents a very useful tool.<br/></li><li>The functional profile is defined by first assigning transcripts and then integrating all the functional information in a single column (in the local database). What we have observed is that functional databases currently are only able to classify ~30% of all the transcripts that can putatively be functionally classified. To the best of our knowledge, the functional information for the remaining two thirds of those transcripts remains unresolved in other existing tools. In contrast, with our workflow the functional assignment of these transcripts can be determined based on the homology search results (which are included in the local database), thus providing a much more complete and detailed functional profile.</li></ol></li></ol><p class="pptt" id="biaoti34714">### Acknowledgments</p><p class="ppzz">This research was supported by Agencia Nacional de PromociÃ³n CientÃ­fica y TecnolÃ³gica (PICT PRH 112 and PICT CABBIO 3632), and Consejo Nacional de Investigaciones CientÃ­ficas y TÃ©cnicas (CONICET) (PIP 0294) grants to CBM. CBM is a member of the CONICET research career. GR and JMC are the recipients of CONICET fellowships. This paper was derived from McCarthy <em>et al.</em> (2013) and Rozadilla <em>et al.</em> (2020).</p><p class="pptt" id="biaoti34715">### Competing interests</p><p class="ppzz">The authors declare no competing interests.</p><p class="pptt" id="biaoti34716">### References</p><ol class="npwtwok"><li>Aguiar-Pulido, V., Huang, W., Suarez-Ulloa, V., Cickovski, T., Mathee, K. and Narasimhan, G. (2016). <a href="http://www.ncbi.nlm.nih.gov/pubmed/27199545" target="_blank">Metagenomics, metatranscriptomics, and metabolomics approaches for microbiome analysis.</a> <em>Evol Bioinform Online</em> 12(Suppl 1): 5-16.</li><li>Altschul, S. F., Gish, W., Miller, W., Myers, E. W. and Lipman, D. J. (1990). <a href="http://www.ncbi.nlm.nih.gov/pubmed/2231712" target="_blank">Basic local alignment search tool.</a> <em>J Mol Biol</em> 215(3): 403-410.</li><li>Ashburner, M., Ball, C. A., Blake, J. A., Botstein, D., Butler, H., Cherry, J. M., Davis, A. P., Dolinski, K., Dwight, S. S., Eppig, J. T., Harris, M. A., Hill, D. P., Issel-Tarver, L., Kasarskis, A., Lewis, S., Matese, J. C., Richardson, J. E., Ringwald, M., Rubin, G. M. and Sherlock, G. (2000). <a href="http://www.ncbi.nlm.nih.gov/pubmed/10802651" target="_blank">Gene ontology: tool for the unification of biology. The Gene Ontology Consortium.</a> <em>Nat Genet</em> 25(1): 25-29.</li><li>Blake, J. A., Christie, K. R., Dolan, M. E., Drabkin, H. J., Hill, D. P., Ni, L., Sitnikov, D., <em>et al.</em> (2015). <a href="http://www.ncbi.nlm.nih.gov/pubmed/25428369" target="_blank">Gene Ontology Consortium: going forward.</a> <em>Nucleic Acids Re</em><em>s</em> 43(Database issue): D1049-1056.</li><li>Buchfink, B., Xie, C. and Huson, D. H. (2015). <a href="https://pubmed.ncbi.nlm.nih.gov/25402007/" target="_blank">Fast and sensitive protein alignment using DIAMOND.</a> <em>Nature Methods</em> 12(1): 59-60.</li><li>Finn, R. D., Attwood, T. K., Babbitt, P. C., Bateman, A., Bork, P., Bridge, A. J., Chang, H. Y., Dosztanyi, Z., El-Gebali, S., Fraser, M., Gough, J., Haft, D., Holliday, G. L., Huang, H., Huang, X., Letunic, I., Lopez, R., Lu, S., Marchler-Bauer, A., Mi, H., Mistry, J., Natale, D. A., Necci, M., Nuka, G., Orengo, C. A., Park, Y., Pesseat, S., Piovesan, D., Potter, S. C., Rawlings, N. D., Redaschi, N., Richardson, L., Rivoire, C., Sangrador-Vegas, A., Sigrist, C., Sillitoe, I., Smithers, B., Squizzato, S., Sutton, G., Thanki, N., Thomas, P. D., Tosatto, S. C., Wu, C. H., Xenarios, I., Yeh, L. S., Young, S. Y. and Mitchell, A. L. (2017). <a href="http://www.ncbi.nlm.nih.gov/pubmed/27899635" target="_blank">InterPro in 2017-beyond protein family and domain annotations.</a> <em>Nucleic Acids Res</em> 45(D1): D190-D199.</li><li>Glass, E.M. and Meyer, F. (2011). <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118010518.ch37" target="_blank">The metagenomics RAST server: A public resource for the automatic phylogenetic and functional analysis of metagenomes.</a> In: <em>Handbook of Molecular Microbial Ecology I: Metagenomics and Complementary Approaches, BioMed Central</em> 9(1): 325-331.</li><li>Huson, D. H., Auch, A. F., Qi, J. and Schuster, S. C. (2007). <a href="http://www.ncbi.nlm.nih.gov/pubmed/17255551" target="_blank">MEGAN analysis of metagenomic data.</a> <em>Genome Res</em> 17(3): 377-386.</li><li>Huson, D. H., Mitra, S., Ruscheweyh, H. J., Weber, N. and Schuster, S. C. (2011). <a href="http://www.ncbi.nlm.nih.gov/pubmed/21690186" target="_blank">Integrative analysis of environmental sequences using MEGAN4.</a> <em>Genome Res</em> 21(9): 1552-1560.</li><li>Kim, M., Lee, K. H., Yoon, S. W., Kim, B. S., Chun, J. and Yi, H. (2013). <a href="http://www.ncbi.nlm.nih.gov/pubmed/24124405" target="_blank">Analytical tools and databases for metagenomics in the next-generation sequencing era.</a> <em>Genomics Inform</em> 11(3): 102-113.</li><li>Kotera, M., Moriya, Y., Tokimatsu, T., Kanehisa, M. and Goto, S. (2015). <span id="__kindeditor_bookmark_start_394__" style="display:none;"></span><a href="https://citations.springer.com/item?doi=10.1007/978-1-4899-7478-5_694" target="_blank">KEGG and GenomeNet, New Developments, Metagenomic Analysis.</a> In: <em>Encyclopedia of Metagenomics: Genes, Genomes and Metagenomes: Basics, Methods, Databases and Tools.</em> Nelson. K. E. (Ed.). Boston, MA, Springer US: 329-339.</li><li>Marchesi, J. R. and Ravel, J. (2015). <a href="http://www.ncbi.nlm.nih.gov/pubmed/26229597" target="_blank">The vocabulary of microbiome research: a proposal.</a> <em>Microbiome</em> 3: 31.</li><li>Marchler-Bauer, A., Bo, Y., Han, L., He, J., Lanczycki, C. J., Lu, S., Chitsaz, F., Derbyshire, M. K., Geer, R. C., Gonzales, N. R., Gwadz, M., Hurwitz, D. I., Lu, F., Marchler, G. H., Song, J. S., Thanki, N., Wang, Z., Yamashita, R. A., Zhang, D., Zheng, C., Geer, L. Y. and Bryant, S. H. (2017). <a href="http://www.ncbi.nlm.nih.gov/pubmed/27899674" target="_blank">CDD/SPARCLE: functional classification of proteins via subfamily domain architectures.</a> <em>Nucleic Acids Res</em> 45(D1): D200-D203.</li><li>Markowitz, V. M., Chen, I. M., Palaniappan, K., Chu, K., Szeto, E., Grechkin, Y., Ratner, A., Jacob, B., Huang, J., Williams, P., Huntemann, M., Anderson, I., Mavromatis, K., Ivanova, N. N. and Kyrpides, N. C. (2012). <a href="http://www.ncbi.nlm.nih.gov/pubmed/22194640" target="_blank">IMG: the Integrated Microbial Genomes database and comparative analysis system.</a> <em>Nucleic Acids Res</em> 40(Database issue): D115-122.</li><li>McCarthy, C. B., Santini, M. S., Pimenta, P. F. and Diambra, L. A. (2013). <a href="http://www.ncbi.nlm.nih.gov/pubmed/23554910" target="_blank">First comparative transcriptomic analysis of wild adult male and female Lutzomyia longipalpis, vector of visceral leishmaniasis.</a> <em>PLoS One</em> 8(3): e58645.</li><li>McCarthy, C. B., Cabrera, N. A. and Virla, E. G. (2015). <a href="http://www.ncbi.nlm.nih.gov/pubmed/26184938" target="_blank">Metatranscriptomic Analysis of Larval Guts from Field-Collected and Laboratory-Reared <em>Spodoptera frugiperda</em> from the South American Subtropical Region.</a> <em>Genome Announc</em> 3(4): e00777-15.</li><li>Ogata, H., Goto, S., Sato, K., Fujibuchi, W., Bono, H. and Kanehisa, M. (1999). <a href="http://www.ncbi.nlm.nih.gov/pubmed/9847135" target="_blank">KEGG: Kyoto Encyclopedia of Genes and Genomes.</a> Nucleic Acids Res 27(1): 29-34.</li><li>Overbeek, R., Olson, R., Pusch, G. D., Olsen, G. J., Davis, J. J., Disz, T., Edwards, R. A., Gerdes, S., Parrello, B., Shukla, M., Vonstein, V., Wattam, A. R., Xia, F. and Stevens, R. (2014). <a href="http://www.ncbi.nlm.nih.gov/pubmed/24293654" target="_blank">The SEED and the Rapid Annotation of microbial genomes using Subsystems Technology (RAST).</a> <em>Nucleic Acids Res</em> 42(Database issue): D206-214.</li><li>Pearson, W. (2004). <a href="http://www.ncbi.nlm.nih.gov/pubmed/18428723" target="_blank">Finding protein and nucleotide similarities with FASTA.</a> <em>Curr Protoc Bioinformatics</em> Chapter 3: Unit3 9.</li><li>Powell, S., Szklarczyk, D., Trachana, K., Roth, A., Kuhn, M., Muller, J., Arnold, R., Rattei, T., Letunic, I., Doerks, T., Jensen, L. J., von Mering, C. and Bork, P. (2012). <a href="http://www.ncbi.nlm.nih.gov/pubmed/22096231" target="_blank">eggNOG v3.0: orthologous groups covering 1133 organisms at 41 different taxonomic ranges.</a> <em>Nucleic Acids Res</em> 40(Database issue): D284-289.</li><li>Rozadilla, G., Cabrera, N. A., Virla, E. G., Greco, N. M. and McCarthy, C. B. (2020). <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/jen.12742" target="_blank">Gut microbiota of Spodoptera frugiperda (J.E. Smith) larvae as revealed by metatranscriptomic analysis.</a> <em>Journal of Applied Entomology</em> n/a(n/a). doi.org/10.1111/jen.12742.</li><li>Sevim, V., Lee, J., Egan, R., Clum, A., Hundley, H., Lee, J., Everroad, R. C., Detweiler, A. M., Bebout, B. M., Pett-Ridge, J., Goker, M., Murray, A. E., Lindemann, S. R., Klenk, H. P., O'Malley, R., Zane, M., Cheng, J. F., Copeland, A., Daum, C., Singer, E. and Woyke, T. (2019). <a href="http://www.ncbi.nlm.nih.gov/pubmed/31772173" target="_blank">Shotgun metagenome data of a defined mock community using Oxford Nanopore, PacBio and Illumina technologies.</a> <em>Sci Data</em> 6(1): 285.</li><li>Shakya, M., Lo, C. C. and Chain, P. S. G. (2019). <a href="http://www.ncbi.nlm.nih.gov/pubmed/31608125" target="_blank">Advances and challenges in metatranscriptomic analysis.</a> <em>Front Genet</em> 10: 904.</li><li>Tatusov, R. L., Galperin, M. Y., Natale, D. A. and Koonin, E. V. (2000). <a href="http://www.ncbi.nlm.nih.gov/pubmed/10592175" target="_blank">The COG database: a tool for genome-scale analysis of protein functions and evolution.</a> <em>Nucleic Acids Res</em> 28(1): 33-36.</li><li>Wooley, J. C., Godzik, A. and Friedberg, I. (2010). <a href="http://www.ncbi.nlm.nih.gov/pubmed/20195499" target="_blank">A primer on metagenomics.</a> <em>PLoS Comput Biol</em> 6(2): e1000667.<br/></li></ol>