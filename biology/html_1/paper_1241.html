<html><head><title>The Global Adaptation Mapping Initiative (GAMI): Part 2 – Screening protocol</title></head><body><h1>The Global Adaptation Mapping Initiative (GAMI): Part 2 – Screening protocol</h1>Authors: A. Paige Fischer, Max Callaghan, Lea Berrang-Ford, Miriam Nielsen, Garry Sotnik, Ivan Villaverde Canosa, Neal Haddaway, Robbert Biesbroek, Sherilee Harper, Jan Minx, Erin Coughlan de Perez, Diana Reckien, Maarten Van Aalst<br>Abstract: <p><em>Context</em>: It is now widely accepted that the climate is changing, and that societal response will need to be rapid and comprehensive to prevent the most severe impacts. A key milestone in global climate governance is to assess progress on adaptation. To-date, however, there has been negligible robust, systematic synthesis of progress on adaptation or adaptation-relevant responses globally.&nbsp;</p><p><em>Aim: </em>The purpose of this review protocol is to outline the methods used by the Global Adaptation Mapping Initiative (GAMI) to <strong><em>systematically review human adaptation responses to climate-related changes that have been documented globally since 2013 in the scientific literature</em></strong>.<strong><em> </em></strong>The broad question underpinning this review is: <em>Are we adapting to climate change?</em><strong><em> </em></strong>More specifically, we ask ‘<em>what is the evidence relating to human adaptation-related responses that can (or are) directly reducing risk, exposure, and/or vulnerability to climate change</em>?’&nbsp;</p><p><em>Methods: </em>We review scientific literature 2013-2019 to identify documents empirically reporting on observed adaptation-related responses to climate change in human systems that can directly reduce risk. We exclude non-empirical (theoretical &amp; conceptual) literature and adaptation in natural systems that occurs without human intervention. Included documents were coded across a set of questions focused on: Who is responding? What responses are documented? What is the extent of the adaptation-related response? What is the evidence that&nbsp; adaptation-related responses reduce risk, exposure and/or vulnerability? Once articles are coded, we conduct a quality appraisal of the coding and develop ‘evidence packages’ for regions and sectors. We supplement this systematic mapping with an expert elicitation exercise, undertaken to assess bias and validity of insights from included/coded literature <em>vis a vis </em>perceptions of real-world adaptation for global regions and sectors, with associated confidence assessments.&nbsp;</p><p><em>Related protocols: </em>This protocol represents Part 2 of a 5-part series outlining the phases of methods for this initiative. Part 2 outlines the methods used to conduct keyword searches and implement machine-assisted screening of documents based on inclusion and exclusion criteria. See Figures 1 and 2.</p><br>Keywords: climate change, adaptation, resilience, resilient, risk management, global warming, systematic review, evidence synthesis, machine learning, climate, stocktake<br><h2>Introduction</h2><p>The Paris Agreement and Katowice Climate Package articulated a clear mandate to document and assess adaptation progress towards the Global Goal on Adaptation. This includes regularly scheduled stocktaking exercises to summarize and synthesis progress on adaptation. The Global Stocktake (GST) thus underpins the global mandate to track collective progress on how human and natural systems are responding to climatic changes. Despite this, there has to-date been negligible systematic assessment or synthesis of adaptation responses globally. There is, however, a proliferation of documents reporting on adaptation-related efforts and experiences across different sectors, systems, and populations. This review seeks to systematically synthesize this growing literature to summarize diverse forms of evidence documenting global adaptation progress across sectors, systems, and populations.&nbsp;</p><p><br></p><p><em>Stakeholder Engagement</em></p><p>This review responds to the mandate of the IPCC’s AR6 outline, which highlights the need to document and synthesize observed responses to climate change (<a href="http://www.ipcc.ch/site/assets/uploads/2018/03/AR6_WGII_outlines_P46.pdf" rel="noopener noreferrer" target="_blank">http://www.ipcc.ch/site/assets/uploads/2018/03/AR6_WGII_outlines_P46.pdf</a> and <a href="http://www.ipcc.ch/site/assets/uploads/2018/09/220520170356-Doc.-2-Chair-Vision-Paper-.pdf" rel="noopener noreferrer" target="_blank">http://www.ipcc.ch/site/assets/uploads/2018/09/220520170356-Doc.-2-Chair-Vision-Paper-.pdf</a>).&nbsp;</p><p>The approved outline of the IPCC’s AR6 Working Group II report reflects an extensive consultatory process that includes climate change experts from across disciplines, users of the IPCC reports, and representatives from governments: (<a href="https://www.ipcc.ch/site/assets/uploads/2018/03/AR6_WGII_outlines_P46.pdf" rel="noopener noreferrer" target="_blank">https://www.ipcc.ch/site/assets/uploads/2018/03/AR6_WGII_outlines_P46.pdf</a>) .&nbsp;</p><p>Throughout this protocol, we draw on the foci, categorization, and priorities outlined in the IPCC AR6 WGII outline as a reflection of stakeholder framing for this review. To maximize potential impact of outputs, the timeline for this review has additionally been aligned with the publication schedule and publication cut-offs to inform the AR6 assessment process (<a href="https://www.ipcc.ch/site/assets/uploads/2018/12/Timeline_WGIIAR6.pdf" rel="noopener noreferrer" target="_blank">https://www.ipcc.ch/site/assets/uploads/2018/12/Timeline_WGIIAR6.pdf</a>)</p><p><br></p><p><em>Reporting standards</em></p><p>This protocol follows guidance for systematic review mapping (e.g. James et al. 2016) and general guidelines for evidence synthesis (Cochrane, Campbell, CEE). We follow the ROSES established reporting standards (Haddaway et al. 2018).&nbsp;</p><p><br></p><p><em>Funding</em></p><p>The Global Adaptation Mapping Initiative has no formal funding, and is supported by a network of researchers around the world who have contributed their in-kind time to this initiative.&nbsp;</p><p><br></p><p><em>Objective of the review</em></p><p>We frame the review using standards for formulating research questions and searches in systematic reviews, using a PICoST approach: population/problem (P), interest (I), context (Co), and Time (T) and Scope (S) (Table 1).&nbsp;</p><p><br></p><p>The activity of interest (I) is adaptation-related responses. Due to the lack of scientifically-robust literature assessing the potential effectiveness of responses, we use the term ‘adaptation-related responses’ rather than the more common ‘adaptations’ to avoid the implication that all responses (or adaptations) are actually adaptive (i.e. reduce vulnerability and/or risk); some responses labelled as ‘adaptations’ might in fact be maladaptive. To be included, responses must be initiated by humans. This includes human-assisted responses within natural systems, as well as responses taken by governments, the private sector, civil society, communities, households, and individuals, whether intentional/planned or unintentional/autonomous. While unintentional/autonomous responses are included, these are likely to be under-represented unless labelled as adaptation and documented as a response to climate change due to the infeasibility of capturing potential adaptive activities not identified as adaptations. We exclude responses in natural systems that are not human-assisted; these are sometimes referred to as evolutionary adaptations or autonomous natural systems adaptations. While important, autonomous adaptation in natural systems is distinct from adaptations initiated by humans; this review focuses on responses by humans to observed or projected climate change risk. We include any human responses to climate change impacts that are, or could, decrease vulnerability or exposure to climate-related hazards, as well as anticipatory measures in response to expected impacts.&nbsp;</p><p>This review focuses on adaptation only, and excludes mitigation (responses involving the reduction of greenhouse gas (GHG) concentrations). We consider adaptation responses across contexts (Co) globally, and focus only on adaptation activities that are directly intended to reduce risk, exposure, or vulnerability, even if later identified as maladaptation. To reflect publications since AR5 and prior to the AR6 publication cut-off, we focus on literature published in the time period (T) between 2013 and 2020.&nbsp;</p><p>This review focuses on the scientific literature only, and excludes grey literature and other sources of Indigenous and Local Knowledge (IKLK).&nbsp;</p><p><br></p><p><br></p><h2>Procedure</h2><p>This protocol represents Part 2 of a 5-part series outlining the phases of methods for this initiative. Part 2 outlines the methods used to conduct keyword searches and implement machine-assisted screening of documents based on inclusion and exclusion criteria. See Figure 1.</p><p><br></p><p><strong>1.0&nbsp;Objective</strong></p><p>Screening focused on identification of documents that meet our PICoST search criteria (see Introduction).&nbsp;</p><p>The goal if the screening phase was to identify documents that met the PICoST search criteria:&nbsp;</p><p>* Population (P): Global human or natural systems of importance to humans that are impacted by climate change</p><p>* Interest (I): Observed/documented adaptation responses to climate change within human systems (or human-assisted in natural systems) in the scientific literature</p><p>* Context (Co): Any empirically documented/observed adaptation response by humans</p><p>* Time &amp; Scope (T/S): Published between 2013 and 2020 in the scientific literature</p><p><br></p><p><br></p><p><strong>2.0&nbsp;Scoping</strong></p><p>To ensure we capture relevant documents, we conducted initial scoping to identify appropriate search terms. A list of 10 <em>a priori </em>identified publications were used to construct search terms and refine the search string (Table 1). We did not replicate the search strings of review articles within this list, but rather used the papers to identify potential search terms and better understand the range of terminology used in this field. This informed the development of unique search strings for this protocol.</p><p><br></p><p><br></p><p><strong>3.0&nbsp;Search String</strong></p><p>Search strings were developed for each bibliographic database as shown below (Table 3). The searches focus on documents combining two concepts: climate change, and adaptation or response. Given the huge number of publications referring to environment and resilience, we restricted our search string to documents including reference to climate change or global warming in their titles, abstracts, or keywords; articles referring to weather, environmental variability, or meteorological variables without explicit reference to climate change are thus not captured. We included terms such as ‘resilience’ and ‘risk management’ to reflect the breadth of literature relevant to climate adaptation that is indexed using these terms. We use natural language terms only since Scopus and Web of Science do not employ controlled vocabulary (e.g. MeSH terms).&nbsp;</p><p>Documents retrieved from searches will be uploaded to a customized platform, MCC-APSIS for management and screening.</p><p><br></p><p><strong>3.1&nbsp;Languages</strong></p><p>Database search — including bibliographic databases, organizational websites, and web-based search engines — will be conducted in English only, but screening will not exclude by language. This means that documents written in any language are eligible for inclusion as long as they are indexed in English within selected databases. Given the global scope of this review, it is not considered feasible to search in all global languages. In addition, the bibliographic databases that we will search typically catalogue records using translated English titles and abstracts: non-English searches are thus not largely necessary for these resources. We did retrieve and include a number of non-English documents in this review.</p><p><br></p><p><strong>3.2&nbsp;Estimating the comprehensiveness of the search</strong></p><p>The search involved screening a large volume of literature (casting a wide net) to identify a much lower number of relevant documents (&lt;5,000). We anticipated that the major screening restriction will be the requirement that there is <em>empirical</em> documentation of activities that are <em>directly linked to potential risk/vulnerability reduction</em>. Yet much literature relevant to adaptation remains either unreported, not labelled or tagged as adaptation or climate-related, or reported in forms or platforms inaccessible within a global review.&nbsp;</p><p><br></p><p>In particular, the review includes scientific literature only, excluding important sources of adaptation action in grey literature and other sources of Indigenous Knowledge and Local Knowledge (IKLK). Our initial protocol intended to include grey literature and web-based IKLK sources by including documents retrieved via Google searches. This was found to be infeasible for two reasons: 1) grey literature documents and links frequently do not include abstracts or summaries, and were thus not able to be screened and prioritized by our machine learning methods; 2) the volume of scientific literature was already substantial and exceeded initial available resources. We thus chose to focus on scientific literature only for this first GAMI initiative, recognizing that our results will not reflect all relevant adaptation actions.</p><p><br></p><p><strong>4.0&nbsp;Article Screening and Study Inclusion Criteria</strong></p><p><br></p><p><strong>4.1&nbsp;Screening strategy</strong></p><p>Screening entailed manual (human) and machine-learning to review the title and/or abstract or summary of each potentially relevant document to determine whether it could be included in a database of recent empirical research on human adaptation to climate change. Screening involved working with a huge volume of literature (close to 50,000 documents). We thus leveraged machine learning methods to automate part of the process so that the screening team could focus on tasks that required human judgment.&nbsp;</p><p><br></p><p><strong>4.2&nbsp;Inclusion &amp; exclusion criteria</strong></p><p>The goal of the screening team was to assemble a database of papers published between 2013-2019 on actions undertaken by people in response to climate change or environmental conditions, events and processes that were attributed or theorized to be linked, at least in part, to climate change. The focus was on adaptation; documents focusing on mitigation responses (i.e. reducing greenhouse gas emissions) were excluded. Adaptation actions could take place at any level of social organization (individual, household, community, institution, government). Adaptation responses to perceived climate change impacts were eligible for inclusion. Documents synthesizing climate change impacts on populations, without explicit and primary emphasis on <em>adaptation responses</em> were also excluded except when climate <em>responses </em>were synonymous with climate <em>impacts</em> (e.g. human migration or species shifts). Documents whose contributions are primarily conceptual or theoretical were treated as non-empirical and therefore excluded. We focused on documents that reported on responses that constituted adaptation based on a strict definition of the term: behaviors that directly aimed to reduce risk or vulnerability. Documents presenting empirical syntheses of vulnerability or adaptive capacity without primary or substantive focus on tangible adaptation responses (reactive or proactive) were excluded. Documents were considered eligible for inclusion if they explicitly documented adaptation actions that were theorized or conceptually linked to risk or vulnerability reduction. This excluded assessments of <em>potential</em> adaptation, <em>intentions/plans</em> to adapt, and discussion of adaptation constraints or barriers in the absence of documented actions that might reduce risk, exposure, or vulnerability.&nbsp;&nbsp;</p><p><br></p><p>Documents published between 2013 and 2019 were considered, including documents reporting on adaptations undertaken prior to 2013. Documents were not excluded from screening based on language as long as they are indexed in English. Documents were not excluded by geographical region, population, ecosystem, species, or sector. Grey literature was not included.</p><p><br></p><p>The screening team evaluated the suitability of each paper using a set of seven&nbsp;inclusion and exclusion criteria (Table 3).&nbsp;</p><p><br></p><p>These criteria were converted to a set of decision steps to facilitate efficient screening decisions and inter-screener reliability:</p><p><br></p><p>1. Does the paper have anything to do with <strong><em>climate change</em></strong>?&nbsp;If the paper does not explicitly or implicitly draw connections between the objectives, methods, or findings and global climate change, global warming, global change, or changes that are driven by global atmospheric variables, then the answer is no. If the answer is yes proceed to criterion number 2.&nbsp;</p><p><br></p><p>2. Does the paper report on analyses of <strong><em>empirical</em></strong> data (i.e., data derived from observation or experience; not theoretical or simulated) or a systematic review of empirical research?&nbsp;If the paper presents concepts and theories not grounded in empirical research, puts forth propositions without clear descriptions of methods, or the results of simulations that are not based on empirical data, then the answer is no. If the answer is yes, proceed to criterion number 3:</p><p><br></p><p>3. Does the paper report on findings about changes in human systems OR human-assisted changes in natural systems intended for adaptation in human systems (i.e., what <strong><em>people</em></strong> think&nbsp;and do)? If the paper reports on biological/ecological conditions and processes then the answer is no)? If the answer is yes, proceed to criterion number 4:</p><p><br></p><p>4. Does the paper report on how people <strong><em>respond</em></strong> to environmental change, including factors that influence how people respond? If the paper reports the results of an assessment of&nbsp;vulnerability or impacts from climate change, the answer is no)? If the answer is yes, proceed to criterion number 5.</p><p><br></p><p>5. Do the responses have to do with <strong><em>adaptation</em></strong> through reduction of risk or impacts, or improvements in well-being or suitability to the environment beyond mitigation? If the paper only reports on efforts to prevent, slow or reverse climate change, the answer is no. If the answer is yes, proceed to criterion 6:</p><p><br></p><p>6. Is the timeframe of the research current (e.g. within the past 10yrs) or<strong><em> recent</em></strong>? If the timeframe was prehistoric or historic, the answer is no. If the answer is yes, proceed to criterion 7:</p><p><br></p><p>7. Does the paper report on <strong><em>tangible/observed behavioral responses</em></strong> (e.g., actions, practices, improved knowledge, altered social structure) that people <strong><em>have undertaken</em></strong> and that could arguably <strong><em>reduce risk</em></strong> to people or&nbsp;<strong><em>improve people's ability to cope with/adapt to</em></strong> environmental change? If the paper reports on planned or recommended behavior change, the answer is no. If the answer is yes, the article should be included in the sample.&nbsp;</p><p><br></p><p><strong>4.3&nbsp;Machine learning contributions to screening</strong></p><p>Given the large volume of documents requiring screening, we used machine learning techniques to filter and prioritize screening of documents that were most likely to meet inclusion criteria. To identify relevant documents within the larger set of retrieved documents, we used supervised machine learning. This approach involves manually screening (human coding) a subset of documents to ‘teach’ an automated classifier which documents are relevant according to a set of pre-defined criteria, and then use this trained classifier to predict the ‘most likely to be relevant’ literature (see for example: <a href="https://systematicreviewsjournal.biomedcentral.com/articles/10.1186/2046-4053-4-5" rel="noopener noreferrer" target="_blank">O’Mara-Eves et al., 2015</a>). To be labelled as relevant, documents needed to meet inclusion and exclusion criteria (Table 3) based on their title, abstract, and keywords.&nbsp;</p><p><br></p><p>All searches were performed within a bespoke platform developed by the APSIS group at the Mercator Research Institute on Global Commons and Climate Change (https://github.com/mcallaghan/tmv), and duplicates were removed.</p><p><br></p><p><em>Initial manual screening: </em>We first screened a random sample of documents retrieved via the search strings. This sample of documents was reviewed by multiple team members; the documents that were labelled differently by different team members were then discussed until consensus was reached, to reduce bias and ensure consistency between team members. This initial phase created the first of several training samples used to train the machine-learning algorithm to predict relevant documents.&nbsp;</p><p><br></p><p><em>Iterative screening and training of algorithm: </em>This sample of manually screened documents was used to train a machine learning classifier to predict the relevance of remaining documents. The algorithm generated a ‘probability of relevance’ for all un-screened documents, allowing the screening team to prioritize screening of documents most likely to be relevant. Batches of documents with the highest predicted probability of relevance were then screened by hand, with iterative re-training of the classifier after each batch to continuously improve prediction. All documents identified by the algorithm as potentially highly relevant were manually screened by the screening team, with these results acting to improve the algorithm’s prediction of relevance with each manually screened batch.</p><p><br></p><p><em>Assessment of ‘borderline’ documents: </em>This iterative process continued until the classifier stopped predicting new relevant documents, and most documents being identified were only borderline relevant. While not all documents had been manually screened by the screening team at this stage, none of the documents being identified by the algorithm as ‘likely to be most relevant’ were deemed by the screening team to be highly relevant. Further manual screening of documents identified by the algorithm found increasingly borderline and irrelevant documents, suggesting that the majority of relevant documents had already been identified and screened.</p><p><br></p><p><em>Estimating proportion of relevant documents retrieved through machine-learning.</em> We used a random sample of the remaining un-screened documents to estimate how many of these documents might still be relevant. In total, 43,462 documents were not screened. Based on a sample of 200 of these documents, we found 3 potentially relevant documents, all of which were deemed as marginally relevant only. From these results, we can predict that the chance that we achieved a recall of less than 68% is less than 50%, and the chance that we achieved a recall of less than 50% is less than 5%. We feel these numbers are conservative, as the three relevant documents in the sample were only of marginal relevance. We therefore concluded that the returns of additional screening would be low.</p><p><br></p><p>All documents deemed eligible in the final database were manually screened by the screening team. The machine learning component of this review means that the screening team did not, however, screen 100% of documents retrieved via the search strings. Instead, the screening team screened a non-random sample of the documents predicted to be the most relevant to inclusion criteria, as predicted by the machine learning classifier. There will therefore be some relevant documents missed by this process. These will be cases where the classifier was unable to recognize that the document met inclusion criteria. In most cases, these were borderline-relevant documents.&nbsp;</p><p><br></p><p><strong>4.4&nbsp;Inter-screener reliability</strong></p><p>To ensure consistent interpretation of the screening criteria between screeners, the members of the screening team each screened the same initial set of 50 documents and then compared and contrasted our application of the inclusion and exclusion criteria. After refining our collective interpretation of the criteria, we repeated this process with 100 documents, at which point we were confident that we were able to apply the criteria in a similar fashion.</p><p><br></p><p>Screeners were given the option of responding ‘Maybe’ to inclusion/exclusion where there was uncertainty regarding inclusion criteria, or where inclusion was borderline. In these cases, the Screening Coordinator (PF) double-screened the document.</p><p><br></p><p><strong>4.5&nbsp;Sample size</strong></p><p>Of a total of 48,816 documents retrieved following duplicate removal, the screening team manually screened 4500 documents through an iterative screening process detailed in Table 4.&nbsp;Batches 1 and 3 were small batches of 100 documents each, and were used to train screeners and conduct consistency checking and ensure quality control of screening across team members. Batch 2 was conducted on a random sample of documents, and was used as the primary training batch for the machine classifier.&nbsp;From Batch 3 onwards, each screened batch represented a non-random sample of documents, selecting documents identified by the classifier as the most likely to be relevant. After each batch, the classifier was re-run to improve prediction performance. As the sample of manually screened documents increases, the classifier is increasingly able to differentiate relevance of documents to inclusion and exclusion criteria.&nbsp;</p><p><br></p><p>In later batches, the proportion of relevant documents decreases as the screeners have increasingly already screened the most relevant documents. Beginning with Batch 10, therefore, small batches were screened to iteratively assess the number of remaining relevant documents. Once this was determined to be minimized, Batches 12 and 13 were conducted on random samples of literature. These random samples of remaining documents allowed us to estimate the proportion of relevant documents remaining that had not yet been manually screened.&nbsp;</p><p><br></p><p>Performance statistics generated by the machine learning classifier showed negligible potential to increase recall further, meaning that the remaining un-screened documents were likely to be: a) not relevant and would be excluded if screened manually, or b) if relevant, would be borderline or marginally relevant, or c) relevant but include limited reference to key climate adaptation vocabulary (Figure 3). A total of 347 borderline or unclear documents were double-screened by the Screening Coordinator.&nbsp;</p><p><br></p><p><br></p><p><strong>5.0&nbsp;Coding of meta-data</strong></p><p>Although the majority of data extraction was collected during a separate coding phase, we did extract some data during screening. This included:</p><p><br></p><p>1. Reason for exclusion</p><p>2. Sector (multiple answers allowed)</p><p>3. Region (multiple answers allowed)</p><p><br></p><p>Data on sector and region were collected only for documents meeting inclusion criteria for either database, and were designed to: a) allowed sorting of relevant documents by sector and region, and b) allow assignment of documents to coders with relevant expertise. Our extraction form also collected data on cross-cutting themes, though these were found to be unreliable and difficult to determine from the title and abstract only, and were thus not used for further coding or analysis.</p><p><br></p><p><strong>6.0&nbsp;Critical Appraisal</strong></p><p>Critical appraisal was not used for article inclusion or exclusion since this review includes literature with a range of methods. Quality appraisal was, however, undertaken on all documents/studies meeting inclusion criteria, and was part of the assessment of confidence in evidence. Details are thus summarized in Protocol 3 (Data extraction).</p><h2>Time Taken</h2><p>The full GAMI work, including all stages, was undertaken over a period of approximately 12-18 months (2019-20).</p><h2>Anticipated Results</h2><p>The results of this initiative comprise a database and a set of evidence packages documenting key insights from scientific literature documenting global human adaptation to climate change. These data have been provided to author teams leading the Intergovernmental Panel on Climate Change (IPCC) 6th Assessment Report (AR6), Working Group II, to support their climate assessments. The database is also the basis for a number of secondary analyses and publications, focusing on particular regions, sectors, or aspects of adaptation. Publications are forthcoming.</p></body></html>